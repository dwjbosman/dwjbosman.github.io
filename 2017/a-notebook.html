<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# fb: https://www.facebook.com/2008/fbml">
<head>
    <title>A notebook - Dinne Bosman's proffesional blog</title>
    <!-- Using the latest rendering mode for IE -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">



<link rel="canonical" href="https://dwjbosman.github.io/2017/a-notebook.html">

        <meta name="author" content="Dinne Bosman" />
        <meta name="description" content="import numpy as np import tensorflow as tf import matplotlib.pyplot as plt num_epochs = 100 total_series_length = 50000 truncated_backprop_length = 15 state_size = 4 num_classes = 2 echo_step = 3 batch_size = 5 num_batches = total_series_length//batch_size//truncated_backprop_length def generateData(): x = np.array(np.random.choice(2, total_series_length, p=[0.5, 0.5])) y = np.roll(x, echo_step) y[0:echo_step] = 0 x = x.reshape((batch_size, -1)) # The first index changing slowest, subseries as rows #print(x.shape) y = y.reshape((batch_size, -1)) return (x, y) tmp=generateData() (5, 10000) batchX_placeholder = tf.placeholder(tf.float32, [batch_size, truncated_backprop_length]) batchY_placeholder = tf.placeholder(tf.int32, [batch_size, truncated_backprop_length]) init_state = tf.placeholder(tf.float32, [batch_size, state_size]) W = tf.Variable(np.random.rand(state_size+1, state_size), dtype=tf.float32) b = tf.Variable(np.zeros((1,state_size)), dtype=tf.float32) W2 …" />

        <meta property="og:site_name" content="Dinne Bosman's proffesional blog" />
        <meta property="og:type" content="article"/>
        <meta property="og:title" content="A notebook"/>
        <meta property="og:url" content="https://dwjbosman.github.io/2017/a-notebook.html"/>
        <meta property="og:description" content="import numpy as np import tensorflow as tf import matplotlib.pyplot as plt num_epochs = 100 total_series_length = 50000 truncated_backprop_length = 15 state_size = 4 num_classes = 2 echo_step = 3 batch_size = 5 num_batches = total_series_length//batch_size//truncated_backprop_length def generateData(): x = np.array(np.random.choice(2, total_series_length, p=[0.5, 0.5])) y = np.roll(x, echo_step) y[0:echo_step] = 0 x = x.reshape((batch_size, -1)) # The first index changing slowest, subseries as rows #print(x.shape) y = y.reshape((batch_size, -1)) return (x, y) tmp=generateData() (5, 10000) batchX_placeholder = tf.placeholder(tf.float32, [batch_size, truncated_backprop_length]) batchY_placeholder = tf.placeholder(tf.int32, [batch_size, truncated_backprop_length]) init_state = tf.placeholder(tf.float32, [batch_size, state_size]) W = tf.Variable(np.random.rand(state_size+1, state_size), dtype=tf.float32) b = tf.Variable(np.zeros((1,state_size)), dtype=tf.float32) W2 …"/>
        <meta property="article:published_time" content="2017-11-19" />
            <meta property="article:section" content="articles" />
            <meta property="article:author" content="Dinne Bosman" />



    <!-- Bootstrap -->
        <link rel="stylesheet" href="https://dwjbosman.github.io/theme/css/bootstrap.united.min.css" type="text/css"/>
    <link href="https://dwjbosman.github.io/theme/css/font-awesome.min.css" rel="stylesheet">

    <link href="https://dwjbosman.github.io/theme/css/pygments/native.css" rel="stylesheet">
    <link rel="stylesheet" href="https://dwjbosman.github.io/theme/css/style.css" type="text/css"/>

        <link href="https://dwjbosman.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate"
              title="Dinne Bosman's proffesional blog ATOM Feed"/>




</head>
<body>

<div class="navbar navbar-default navbar-fixed-top" role="navigation">
	<div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a href="https://dwjbosman.github.io/" class="navbar-brand">
Dinne Bosman's proffesional blog            </a>
        </div>
        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav">
                        <li class="active">
                            <a href="https://dwjbosman.github.io/category/articles.html">Articles</a>
                        </li>
            </ul>
            <ul class="nav navbar-nav navbar-right">
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
</div> <!-- /.navbar -->
<!-- Banner -->
<style>
	#banner{
	    background-image:url("https://dwjbosman.github.io//images/photo_hack_1920.jpg");
	}
</style>

<div id="banner">
	<div class="container">
		<div class="copy">
			<h1>Dinne Bosman's proffesional blog</h1>
				<p class="intro">Instruments, Communities, Values</p>
		</div>
	</div>
</div><!-- End Banner -->
<div class="container">
    <div class="row">
        <div class="col-sm-9">
    <section id="content">
        <article>
            <header class="page-header">
                <h1>
                    <a href="https://dwjbosman.github.io/2017/a-notebook.html"
                       rel="bookmark"
                       title="Permalink to A notebook">
                        A notebook
                    </a>
                </h1>
            </header>
            <div class="entry-content">
                <div class="panel">
                    <div class="panel-body">
<footer class="post-info">
    <span class="label label-default">Date</span>
    <span class="published">
        <i class="fa fa-calendar"></i><time datetime="2017-11-19T21:35:38.064543+01:00"> Sun 19 November 2017</time>
    </span>





    
</footer><!-- /.post-info -->                    </div>
                </div>
                <div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">total_series_length</span> <span class="o">=</span> <span class="mi">50000</span>
<span class="n">truncated_backprop_length</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">state_size</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">echo_step</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">num_batches</span> <span class="o">=</span> <span class="n">total_series_length</span><span class="o">//</span><span class="n">batch_size</span><span class="o">//</span><span class="n">truncated_backprop_length</span>
</pre></div>


<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">generateData</span><span class="p">():</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">total_series_length</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]))</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">echo_step</span><span class="p">)</span>
    <span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">echo_step</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>  <span class="c1"># The first index changing slowest, subseries as rows</span>
    <span class="c1">#print(x.shape)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">tmp</span><span class="o">=</span><span class="n">generateData</span><span class="p">()</span>
</pre></div>


<div class="codehilite"><pre><span></span>(5, 10000)
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">batchX_placeholder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">truncated_backprop_length</span><span class="p">])</span>
<span class="n">batchY_placeholder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">truncated_backprop_length</span><span class="p">])</span>

<span class="n">init_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">state_size</span><span class="p">])</span>
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">state_size</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">state_size</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="n">state_size</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">W2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">state_size</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">b2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="n">num_classes</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span><span class="c1"># Unpack columns</span>
<span class="n">inputs_series</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">batchX_placeholder</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">labels_series</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">batchY_placeholder</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span><span class="c1"># Forward pass</span>
<span class="n">current_state</span> <span class="o">=</span> <span class="n">init_state</span>
<span class="n">states_series</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">current_input</span> <span class="ow">in</span> <span class="n">inputs_series</span><span class="p">:</span>
    <span class="n">current_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">current_input</span><span class="p">,</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">input_and_state_concatenated</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="n">current_input</span><span class="p">,</span> <span class="n">current_state</span><span class="p">])</span>  <span class="c1"># Increasing number of columns</span>

    <span class="n">next_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">input_and_state_concatenated</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>  <span class="c1"># Broadcasted addition</span>
    <span class="n">states_series</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">next_state</span><span class="p">)</span>
<span class="n">current_state</span> <span class="o">=</span> <span class="n">next_state</span>
</pre></div>


<div class="codehilite"><pre><span></span>---------------------------------------------------------------------------

TypeError                                 Traceback (most recent call last)

&lt;ipython-input-52-4ac3079ec7b1&gt; in &lt;module&gt;()
      4 for current_input in inputs_series:
      5     current_input = tf.reshape(current_input, [batch_size, 1])
----&gt; 6     input_and_state_concatenated = tf.concat(1, [current_input, current_state])  # Increasing number of columns
      7 
      8     next_state = tf.tanh(tf.matmul(input_and_state_concatenated, W) + b)  # Broadcasted addition


/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py in concat(values, axis, name)
   1094       ops.convert_to_tensor(
   1095           axis, name=&quot;concat_dim&quot;,
-&gt; 1096           dtype=dtypes.int32).get_shape().assert_is_compatible_with(
   1097               tensor_shape.scalar())
   1098       return identity(values[0], name=scope)


/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, preferred_dtype)
    834       name=name,
    835       preferred_dtype=preferred_dtype,
--&gt; 836       as_ref=False)
    837 
    838


/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx)
    924 
    925     if ret is None:
--&gt; 926       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
    927 
    928     if ret is NotImplemented:


/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/constant_op.py in _constant_tensor_conversion_function(v, dtype, name, as_ref)
    227                                          as_ref=False):
    228   _ = as_ref
--&gt; 229   return constant(v, dtype=dtype, name=name)
    230 
    231


/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/constant_op.py in constant(value, dtype, shape, name, verify_shape)
    206   tensor_value.tensor.CopyFrom(
    207       tensor_util.make_tensor_proto(
--&gt; 208           value, dtype=dtype, shape=shape, verify_shape=verify_shape))
    209   dtype_value = attr_value_pb2.AttrValue(type=tensor_value.tensor.dtype)
    210   const_tensor = g.create_op(


/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py in make_tensor_proto(values, dtype, shape, verify_shape)
    381       nparray = np.empty(shape, dtype=np_dt)
    382     else:
--&gt; 383       _AssertCompatible(values, dtype)
    384       nparray = np.array(values, dtype=np_dt)
    385       # check to them.


/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py in _AssertCompatible(values, dtype)
    301     else:
    302       raise TypeError(&quot;Expected %s, got %s of type &#39;%s&#39; instead.&quot; %
--&gt; 303                       (dtype.name, repr(mismatch), type(mismatch).__name__))
    304 
    305


TypeError: Expected int32, got list containing Tensors of type &#39;_Message&#39; instead.
</pre></div>


<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span><span class="p">,</span> <span class="n">division</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">total_series_length</span> <span class="o">=</span> <span class="mi">50000</span>
<span class="n">truncated_backprop_length</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">state_size</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">echo_step</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">num_batches</span> <span class="o">=</span> <span class="n">total_series_length</span><span class="o">//</span><span class="n">batch_size</span><span class="o">//</span><span class="n">truncated_backprop_length</span>

<span class="k">def</span> <span class="nf">generateData</span><span class="p">():</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">total_series_length</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]))</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">echo_step</span><span class="p">)</span>
    <span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">echo_step</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>  <span class="c1"># The first index changing slowest, subseries as rows</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">batchX_placeholder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">truncated_backprop_length</span><span class="p">])</span>
<span class="n">batchY_placeholder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">truncated_backprop_length</span><span class="p">])</span>

<span class="n">init_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">state_size</span><span class="p">])</span>

<span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">state_size</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">state_size</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="n">state_size</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">W2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">state_size</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">b2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="n">num_classes</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Unpack columns</span>
<span class="n">inputs_series</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">batchX_placeholder</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">labels_series</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">batchY_placeholder</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Forward pass</span>
<span class="n">current_state</span> <span class="o">=</span> <span class="n">init_state</span>
<span class="n">states_series</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">current_input</span> <span class="ow">in</span> <span class="n">inputs_series</span><span class="p">:</span>
    <span class="n">current_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">current_input</span><span class="p">,</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">input_and_state_concatenated</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">current_input</span><span class="p">,</span> <span class="n">current_state</span><span class="p">],</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Increasing number of columns</span>

    <span class="n">next_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">input_and_state_concatenated</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>  <span class="c1"># Broadcasted addition</span>
    <span class="n">states_series</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">next_state</span><span class="p">)</span>
    <span class="n">current_state</span> <span class="o">=</span> <span class="n">next_state</span>

<span class="n">logits_series</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">W2</span><span class="p">)</span> <span class="o">+</span> <span class="n">b2</span> <span class="k">for</span> <span class="n">state</span> <span class="ow">in</span> <span class="n">states_series</span><span class="p">]</span> <span class="c1">#Broadcasted addition</span>
<span class="n">predictions_series</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span> <span class="k">for</span> <span class="n">logits</span> <span class="ow">in</span> <span class="n">logits_series</span><span class="p">]</span>

<span class="n">losses</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sparse_softmax_cross_entropy_with_logits</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span> <span class="k">for</span> <span class="n">logits</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">logits_series</span><span class="p">,</span><span class="n">labels_series</span><span class="p">)]</span>
<span class="n">total_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span>

<span class="n">train_step</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdagradOptimizer</span><span class="p">(</span><span class="mf">0.3</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">total_loss</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="n">loss_list</span><span class="p">,</span> <span class="n">predictions_series</span><span class="p">,</span> <span class="n">batchX</span><span class="p">,</span> <span class="n">batchY</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">cla</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">loss_list</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">batch_series_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
        <span class="n">one_hot_output_series</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">predictions_series</span><span class="p">)[:,</span> <span class="n">batch_series_idx</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">single_output_series</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([(</span><span class="mi">1</span> <span class="k">if</span> <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">out</span> <span class="ow">in</span> <span class="n">one_hot_output_series</span><span class="p">])</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">batch_series_idx</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">cla</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">truncated_backprop_length</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
        <span class="n">left_offset</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">truncated_backprop_length</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">left_offset</span><span class="p">,</span> <span class="n">batchX</span><span class="p">[</span><span class="n">batch_series_idx</span><span class="p">,</span> <span class="p">:],</span> <span class="n">width</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">left_offset</span><span class="p">,</span> <span class="n">batchY</span><span class="p">[</span><span class="n">batch_series_idx</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">left_offset</span><span class="p">,</span> <span class="n">single_output_series</span> <span class="o">*</span> <span class="mf">0.3</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;green&quot;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">draw</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">pause</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">)</span>


<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">initialize_all_variables</span><span class="p">())</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ion</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="n">loss_list</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">epoch_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">generateData</span><span class="p">()</span>
        <span class="n">_current_state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">state_size</span><span class="p">))</span>

        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;New data, epoch&quot;</span><span class="p">,</span> <span class="n">epoch_idx</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">batch_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_batches</span><span class="p">):</span>
            <span class="n">start_idx</span> <span class="o">=</span> <span class="n">batch_idx</span> <span class="o">*</span> <span class="n">truncated_backprop_length</span>
            <span class="n">end_idx</span> <span class="o">=</span> <span class="n">start_idx</span> <span class="o">+</span> <span class="n">truncated_backprop_length</span>

            <span class="n">batchX</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">]</span>
            <span class="n">batchY</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:,</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">]</span>

            <span class="n">_total_loss</span><span class="p">,</span> <span class="n">_train_step</span><span class="p">,</span> <span class="n">_current_state</span><span class="p">,</span> <span class="n">_predictions_series</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="p">[</span><span class="n">total_loss</span><span class="p">,</span> <span class="n">train_step</span><span class="p">,</span> <span class="n">current_state</span><span class="p">,</span> <span class="n">predictions_series</span><span class="p">],</span>
                <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
                    <span class="n">batchX_placeholder</span><span class="p">:</span><span class="n">batchX</span><span class="p">,</span>
                    <span class="n">batchY_placeholder</span><span class="p">:</span><span class="n">batchY</span><span class="p">,</span>
                    <span class="n">init_state</span><span class="p">:</span><span class="n">_current_state</span>
                <span class="p">})</span>

            <span class="n">loss_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_total_loss</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">batch_idx</span><span class="o">%</span><span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Step&quot;</span><span class="p">,</span><span class="n">batch_idx</span><span class="p">,</span> <span class="s2">&quot;Loss&quot;</span><span class="p">,</span> <span class="n">_total_loss</span><span class="p">)</span>
                <span class="n">plot</span><span class="p">(</span><span class="n">loss_list</span><span class="p">,</span> <span class="n">_predictions_series</span><span class="p">,</span> <span class="n">batchX</span><span class="p">,</span> <span class="n">batchY</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">ioff</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">WARNING</span><span class="o">:</span><span class="n">tensorflow</span><span class="o">:</span><span class="n">From</span> <span class="sr">/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/</span><span class="n">tf_should_use</span><span class="o">.</span><span class="na">py</span><span class="o">:</span><span class="mi">107</span><span class="o">:</span> <span class="n">initialize_all_variables</span> <span class="o">(</span><span class="n">from</span> <span class="n">tensorflow</span><span class="o">.</span><span class="na">python</span><span class="o">.</span><span class="na">ops</span><span class="o">.</span><span class="na">variables</span><span class="o">)</span> <span class="k">is</span> <span class="n">deprecated</span> <span class="n">and</span> <span class="n">will</span> <span class="n">be</span> <span class="n">removed</span> <span class="n">after</span> <span class="mi">2017</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">02</span><span class="o">.</span>
<span class="n">Instructions</span> <span class="k">for</span> <span class="n">updating</span><span class="o">:</span>
<span class="n">Use</span> <span class="err">`</span><span class="n">tf</span><span class="o">.</span><span class="na">global_variables_initializer</span><span class="err">`</span> <span class="n">instead</span><span class="o">.</span>



<span class="o">&lt;</span><span class="n">matplotlib</span><span class="o">.</span><span class="na">figure</span><span class="o">.</span><span class="na">Figure</span> <span class="n">at</span> <span class="mh">0x7fe9d9f3b668</span><span class="o">&gt;</span>


<span class="n">New</span> <span class="n">data</span><span class="o">,</span> <span class="n">epoch</span> <span class="mi">0</span>
<span class="n">Step</span> <span class="mi">0</span> <span class="n">Loss</span> <span class="mf">1.07125</span>
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_3.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 0.693241
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_5.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 0.36993
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_7.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 0.0164067
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_9.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 0.00814864
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_11.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 0.0049567
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_13.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 0.00410617
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_15.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 1
Step 0 Loss 0.12148
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_17.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 0.0059931
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_19.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 0.00348456
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_21.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 0.00271249
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_23.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 0.00223826
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_25.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 0.00226034
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_27.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 0.00186489
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_29.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 2
Step 0 Loss 0.187685
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_31.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 0.00133134
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_33.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 0.00127057
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_35.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 0.00143714
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_37.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 0.00111574
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_39.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 0.00100028
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_41.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 0.0008697
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_43.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 3
Step 0 Loss 0.166001
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_45.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 0.000912137
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_47.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 0.000867449
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_49.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 0.000833183
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_51.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 0.00069551
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_53.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 0.000741409
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_55.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 0.000546224
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_57.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 4
Step 0 Loss 0.139698
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_59.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 0.000685644
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_61.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 0.000574397
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_63.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 0.000578429
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_65.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 0.000498919
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_67.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 0.000595561
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_69.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 0.000482958
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_71.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 5
Step 0 Loss 0.203901
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_73.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 0.000481904
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_75.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 0.000448492
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_77.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 0.000412147
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_79.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 0.000524883
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_81.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 0.000414415
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_83.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 0.000438884
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_85.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 6
Step 0 Loss 0.155198
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_87.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 0.000383026
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_89.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 0.000430898
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_91.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 0.000364003
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_93.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 0.000406275
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_95.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 0.000395748
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_97.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 0.000358205
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_99.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 7
Step 0 Loss 0.18041
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_101.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 0.000331059
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_103.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 0.000314816
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_105.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 0.000339814
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_107.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 0.000353175
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_109.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 0.000318253
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_111.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 0.000365742
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_113.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 8
Step 0 Loss 0.219404
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_115.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 0.00027422
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_117.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 0.00035519
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_119.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 0.000284643
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_121.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 0.000295539
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_123.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 0.000286519
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_125.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 0.000254551
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_127.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 9
Step 0 Loss 0.221185
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_129.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 0.000338885
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_131.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 0.000270251
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_133.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 0.000280382
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_135.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 0.000230942
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_137.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 0.000272087
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_139.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 0.000290121
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_141.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 10
Step 0 Loss 0.308103
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_143.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 0.000271362
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_145.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 0.000217331
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_147.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 0.000266937
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_149.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 0.000272792
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_151.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 0.000233873
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_153.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 0.00022395
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_155.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 11
Step 0 Loss 0.331107
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_157.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 0.000300824
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_159.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 0.000287699
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_161.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 0.000277439
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_163.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 0.000260206
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_165.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 0.000192886
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_167.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 0.00023299
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_169.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 12
Step 0 Loss 0.141896
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_171.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 0.000235209
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_173.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 0.000212689
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_175.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 0.000166708
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_177.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 0.000205341
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_179.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 0.000192494
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_181.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 0.000199206
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_183.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 13
Step 0 Loss 0.291513
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_185.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 0.000212753
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_187.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 0.000174835
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_189.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 0.000182657
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_191.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 0.000210347
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_193.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 0.000182589
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_195.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 0.000200661
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_197.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 14
Step 0 Loss 0.246003
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_199.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 0.000372684
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_201.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 0.000331586
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_203.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 0.000274042
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_205.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 0.000249324
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_207.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 0.000272519
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_209.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 0.000289381
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_211.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 15
Step 0 Loss 0.225238
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_213.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 0.000262286
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_215.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 0.000200126
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_217.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 0.000247869
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_219.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 0.000272037
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_221.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 0.000260008
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_223.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 0.000219859
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_225.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 16
Step 0 Loss 0.270356
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_227.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 0.000380753
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_229.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 0.000277417
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_231.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 0.000221937
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_233.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 0.00027703
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_235.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 0.000274809
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_237.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 0.000195551
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_239.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 17
Step 0 Loss 0.440584
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_241.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 0.000229126
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_243.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 0.000226006
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_245.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 0.000171144
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_247.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 0.000224091
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_249.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 0.000192797
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_251.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 0.000188206
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_253.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 18
Step 0 Loss 0.225576
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_255.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 0.00020749
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_257.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 0.000191182
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_259.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 0.000176672
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_261.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 0.000157556
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_263.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 0.000183912
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_265.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 0.000182434
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_267.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 19
Step 0 Loss 0.162119
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_269.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 0.000169445
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_271.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 0.000200583
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_273.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 0.000135114
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_275.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 0.000161292
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_277.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 0.000176606
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_279.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 0.000163995
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_281.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 20
Step 0 Loss 0.164526
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_283.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 0.000138933
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_285.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 0.000149985
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_287.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 0.000127172
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_289.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 0.000164089
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_291.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 0.000128529
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_293.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 0.0001648
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_295.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 21
Step 0 Loss 0.164585
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_297.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 0.000158746
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_299.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 0.000171799
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_301.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 0.000166205
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_303.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 0.000152365
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_305.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 0.000147098
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_307.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 0.000134242
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_309.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 22
Step 0 Loss 0.181048
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_311.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 0.000151645
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_313.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 0.000125166
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_315.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 0.00012803
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_317.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 0.000146927
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_319.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 0.000136423
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_321.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 0.000130542
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_323.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 23
Step 0 Loss 0.30059
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_325.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 0.000216857
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_327.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 0.000167216
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_329.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 0.000160883
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_331.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 0.000160866
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_333.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 0.000155595
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_335.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 0.000156014
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_337.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 24
Step 0 Loss 0.117854
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_339.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 0.000145224
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_341.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 0.000138245
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_343.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 0.000153729
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_345.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 0.000143988
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_347.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 0.000147034
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_349.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 0.000140519
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_351.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 25
Step 0 Loss 0.102775
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_353.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 0.000118676
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_355.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 0.000128886
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_357.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 0.000117784
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_359.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 9.71227e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_361.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 0.000123592
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_363.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 9.55327e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_365.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 26
Step 0 Loss 0.335973
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_367.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 0.000105191
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_369.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 8.83545e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_371.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 0.000136374
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_373.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 0.000127442
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_375.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 0.00013204
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_377.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 0.000120849
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_379.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 27
Step 0 Loss 0.136352
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_381.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 0.000108485
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_383.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 0.000117909
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_385.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 0.000103518
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_387.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 0.0001361
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_389.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 0.000109846
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_391.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 9.70598e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_393.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 28
Step 0 Loss 0.200221
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_395.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 0.000115796
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_397.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 0.00010158
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_399.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 0.000104796
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_401.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 0.000126111
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_403.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 0.000107671
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_405.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 9.82627e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_407.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 29
Step 0 Loss 0.188697
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_409.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 0.000111646
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_411.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 9.46393e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_413.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 0.000128723
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_415.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 0.000110066
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_417.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 0.0001063
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_419.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 8.6198e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_421.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 30
Step 0 Loss 0.266215
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_423.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 0.00010094
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_425.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 0.000101605
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_427.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 0.000106907
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_429.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 0.000103863
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_431.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 0.00010917
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_433.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 0.000106408
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_435.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 31
Step 0 Loss 0.221394
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_437.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 9.20422e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_439.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 0.000118946
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_441.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 9.02325e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_443.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 8.63526e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_445.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 8.74328e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_447.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 9.5865e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_449.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 32
Step 0 Loss 0.194487
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_451.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 0.000126888
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_453.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 0.000103802
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_455.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 0.000137502
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_457.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 9.48006e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_459.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 7.96414e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_461.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 9.77938e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_463.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 33
Step 0 Loss 0.104813
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_465.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 0.000127914
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_467.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 9.22038e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_469.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 9.46989e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_471.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 0.000103478
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_473.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 8.83379e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_475.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 8.76237e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_477.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 34
Step 0 Loss 0.314226
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_479.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 9.21173e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_481.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 0.000101261
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_483.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 9.08193e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_485.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 9.37992e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_487.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 8.74092e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_489.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 9.08691e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_491.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 35
Step 0 Loss 0.333031
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_493.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 0.000123826
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_495.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 0.00010889
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_497.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 7.71169e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_499.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 0.000103733
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_501.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 0.000103615
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_503.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 0.000129801
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_505.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 36
Step 0 Loss 0.289156
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_507.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 8.70863e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_509.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 9.31525e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_511.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 9.1351e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_513.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 8.61955e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_515.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 0.000100541
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_517.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 7.85854e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_519.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 37
Step 0 Loss 0.14173
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_521.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 8.04861e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_523.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 8.91256e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_525.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 7.52521e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_527.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 9.27843e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_529.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 7.5409e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_531.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 6.54573e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_533.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 38
Step 0 Loss 0.168025
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_535.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 7.82702e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_537.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 7.31258e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_539.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 8.6889e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_541.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 7.48513e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_543.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 8.71001e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_545.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 7.46084e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_547.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 39
Step 0 Loss 0.140448
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_549.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 6.53294e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_551.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 7.09421e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_553.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 8.13163e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_555.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 6.94206e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_557.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 7.38536e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_559.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 7.22758e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_561.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 40
Step 0 Loss 0.267783
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_563.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 9.2548e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_565.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 7.92952e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_567.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 0.000101118
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_569.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 8.89266e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_571.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 0.000114515
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_573.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 8.119e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_575.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 41
Step 0 Loss 0.408305
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_577.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 7.30073e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_579.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 8.06134e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_581.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 7.57719e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_583.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 8.56084e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_585.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 7.63245e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_587.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 9.10474e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_589.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 42
Step 0 Loss 0.149331
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_591.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 7.33135e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_593.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 7.75084e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_595.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 6.84132e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_597.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 7.43597e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_599.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 6.64966e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_601.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 7.06794e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_603.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 43
Step 0 Loss 0.183595
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_605.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 9.51624e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_607.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 7.80805e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_609.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 5.6478e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_611.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 7.54684e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_613.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 8.81604e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_615.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 7.36332e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_617.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 44
Step 0 Loss 0.170031
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_619.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 8.19336e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_621.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 7.27388e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_623.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 6.92274e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_625.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 7.5376e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_627.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 7.75806e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_629.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 7.7711e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_631.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 45
Step 0 Loss 0.156922
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_633.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 7.10639e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_635.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 6.82139e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_637.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 6.03736e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_639.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 7.2428e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_641.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 6.73861e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_643.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 8.98598e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_645.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 46
Step 0 Loss 0.185018
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_647.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 9.03489e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_649.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 7.28189e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_651.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 6.61082e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_653.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 7.18989e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_655.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 8.10503e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_657.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 9.72063e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_659.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 47
Step 0 Loss 0.351795
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_661.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 6.42634e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_663.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 7.24717e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_665.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 8.65393e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_667.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 8.17806e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_669.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 6.02936e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_671.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 6.36633e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_673.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 48
Step 0 Loss 0.177593
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_675.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 8.86898e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_677.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 8.61674e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_679.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 7.82841e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_681.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 5.60583e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_683.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 6.74334e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_685.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 0.000221146
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_687.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 49
Step 0 Loss 0.295538
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_689.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 9.06835e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_691.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 9.61242e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_693.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 7.75299e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_695.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 6.6436e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_697.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 6.97074e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_699.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 7.54807e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_701.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 50
Step 0 Loss 0.192232
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_703.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 6.05517e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_705.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 7.48095e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_707.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 7.14935e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_709.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 6.54257e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_711.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 6.63361e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_713.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 6.48028e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_715.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 51
Step 0 Loss 0.353748
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_717.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 6.11471e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_719.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 5.17864e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_721.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 8.39553e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_723.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 6.36021e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_725.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 8.304e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_727.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 6.42258e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_729.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 52
Step 0 Loss 0.347465
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_731.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 6.83499e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_733.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 5.91339e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_735.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 6.30305e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_737.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 6.71391e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_739.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 7.89847e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_741.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 6.2823e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_743.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 53
Step 0 Loss 0.182313
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_745.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 6.59972e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_747.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 6.81621e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_749.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 5.27459e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_751.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 7.22281e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_753.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 5.79802e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_755.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 5.96119e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_757.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 54
Step 0 Loss 0.163043
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_759.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 5.07912e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_761.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 4.4968e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_763.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 6.54582e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_765.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 5.5992e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_767.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 5.57248e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_769.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 6.04238e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_771.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 55
Step 0 Loss 0.287925
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_773.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 7.91842e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_775.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 7.0622e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_777.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 6.63831e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_779.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 6.91541e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_781.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 6.604e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_783.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 7.13081e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_785.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 56
Step 0 Loss 0.280532
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_787.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 6.45747e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_789.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 6.26892e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_791.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 6.48387e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_793.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 5.96899e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_795.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 6.31845e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_797.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 6.62666e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_799.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 57
Step 0 Loss 0.176732
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_801.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 7.71427e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_803.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 5.79926e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_805.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 6.61785e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_807.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 6.30223e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_809.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 7.10873e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_811.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 5.27921e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_813.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 58
Step 0 Loss 0.163352
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_815.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 5.87028e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_817.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 5.14355e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_819.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 4.6281e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_821.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 5.73048e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_823.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 5.87458e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_825.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 5.37082e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_827.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 59
Step 0 Loss 0.222389
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_829.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 6.1353e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_831.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 5.933e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_833.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 6.21867e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_835.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 6.53094e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_837.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 4.4676e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_839.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 4.7036e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_841.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 60
Step 0 Loss 0.231439
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_843.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 7.60707e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_845.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 7.43184e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_847.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 7.02238e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_849.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 7.85981e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_851.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 7.9271e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_853.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 6.82688e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_855.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 61
Step 0 Loss 0.282176
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_857.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 6.60766e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_859.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 5.44501e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_861.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 6.15786e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_863.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 7.65935e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_865.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 5.68691e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_867.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 5.60155e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_869.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 62
Step 0 Loss 0.398481
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_871.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 8.43045e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_873.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 6.83014e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_875.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 7.33699e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_877.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 6.80611e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_879.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 5.18572e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_881.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 6.01025e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_883.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 63
Step 0 Loss 0.135307
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_885.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 6.96166e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_887.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 5.71261e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_889.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 5.52865e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_891.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 6.40624e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_893.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 5.28845e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_895.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 8.90308e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_897.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 64
Step 0 Loss 0.267879
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_899.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 5.45991e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_901.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 7.16343e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_903.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 7.91693e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_905.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 6.0799e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_907.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 6.19667e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_909.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 5.87346e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_911.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 65
Step 0 Loss 0.288019
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_913.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 7.10767e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_915.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 5.50305e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_917.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 7.03516e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_919.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 6.39615e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_921.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 6.25939e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_923.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 5.95012e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_925.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 66
Step 0 Loss 0.129842
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_927.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 5.35792e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_929.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 5.30302e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_931.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 5.56994e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_933.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 6.21359e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_935.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 6.02086e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_937.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 5.52658e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_939.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 67
Step 0 Loss 0.346257
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_941.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 4.77591e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_943.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 5.76953e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_945.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 5.72119e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_947.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 6.69119e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_949.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 4.91397e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_951.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 5.35536e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_953.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 68
Step 0 Loss 0.156423
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_955.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 5.99386e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_957.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 8.14121e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_959.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 5.68672e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_961.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 7.11428e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_963.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 6.84857e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_965.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 5.08774e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_967.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 69
Step 0 Loss 0.367932
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_969.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 6.10646e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_971.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 5.93182e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_973.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 6.07737e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_975.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 5.33941e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_977.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 5.16998e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_979.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 5.59027e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_981.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 70
Step 0 Loss 0.243568
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_983.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 5.08999e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_985.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 5.23509e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_987.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 5.52706e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_989.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 5.01037e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_991.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 3.97173e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_993.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 5.36272e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_995.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 71
Step 0 Loss 0.132964
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_997.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 5.51381e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_999.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 5.35425e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1001.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 3.73077e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1003.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 4.67258e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1005.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 4.99291e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1007.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 4.54055e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1009.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 72
Step 0 Loss 0.179711
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1011.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 5.0869e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1013.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 5.27213e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1015.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 5.64188e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1017.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 6.46114e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1019.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 5.82471e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1021.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 5.68988e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1023.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 73
Step 0 Loss 0.148336
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1025.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 5.0903e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1027.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 4.4994e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1029.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 4.56362e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1031.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 5.62014e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1033.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 4.96982e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1035.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 4.39657e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1037.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 74
Step 0 Loss 0.237479
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1039.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 9.41841e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1041.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 5.48427e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1043.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 5.11024e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1045.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 5.54929e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1047.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 4.9102e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1049.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 5.70366e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1051.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 75
Step 0 Loss 0.318287
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1053.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 4.82691e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1055.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 4.46378e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1057.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 5.5468e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1059.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 4.7599e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1061.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 4.953e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1063.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 5.77413e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1065.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 76
Step 0 Loss 0.162051
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1067.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 4.94537e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1069.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 5.07377e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1071.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 5.43643e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1073.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 4.43153e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1075.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 4.11764e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1077.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 4.86525e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1079.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 77
Step 0 Loss 0.125889
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1081.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 4.2227e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1083.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 4.06328e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1085.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 5.27675e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1087.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 4.82267e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1089.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 4.4139e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1091.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 4.80085e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1093.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 78
Step 0 Loss 0.222535
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1095.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 4.60768e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1097.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 4.66168e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1099.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 6.77957e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1101.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 5.28414e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1103.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 5.37304e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1105.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 5.03758e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1107.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 79
Step 0 Loss 0.161458
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1109.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 4.89242e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1111.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 4.16897e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1113.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 4.35859e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1115.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 4.58761e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1117.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 5.19406e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1119.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 4.18425e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1121.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 80
Step 0 Loss 0.131393
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1123.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 4.50749e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1125.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 4.04496e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1127.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 4.89257e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1129.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 4.59805e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1131.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 3.94362e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1133.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 5.18784e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1135.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 81
Step 0 Loss 0.177967
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1137.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 4.18721e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1139.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 4.64194e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1141.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 4.73046e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1143.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 4.6019e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1145.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 4.45344e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1147.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 4.38987e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1149.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 82
Step 0 Loss 0.218162
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1151.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 4.39097e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1153.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 5.53843e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1155.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 4.82518e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1157.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 4.77924e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1159.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 5.25612e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1161.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 5.15979e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1163.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 83
Step 0 Loss 0.191057
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1165.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 5.36522e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1167.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 3.69168e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1169.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 4.326e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1171.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 4.47109e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1173.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 4.01875e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1175.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 4.21268e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1177.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 84
Step 0 Loss 0.231948
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1179.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 4.17641e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1181.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 4.37445e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1183.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 3.64703e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1185.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 4.52496e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1187.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 4.90571e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1189.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 4.17575e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1191.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 85
Step 0 Loss 0.203053
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1193.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 3.86047e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1195.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 4.33107e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1197.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 4.29357e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1199.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 4.02338e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1201.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 4.66608e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1203.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 3.46377e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1205.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 86
Step 0 Loss 0.204208
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1207.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 3.90242e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1209.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 4.6869e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1211.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 4.25599e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1213.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 5.18326e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1215.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 5.00279e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1217.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 3.78623e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1219.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 87
Step 0 Loss 0.296417
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1221.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 6.40958e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1223.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 4.60711e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1225.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 5.49031e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1227.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 4.61172e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1229.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 4.18942e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1231.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 4.416e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1233.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 88
Step 0 Loss 0.176012
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1235.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 4.18626e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1237.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 4.64446e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1239.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 3.76653e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1241.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 4.46157e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1243.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 4.4965e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1245.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 4.29879e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1247.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 89
Step 0 Loss 0.152412
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1249.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 5.23644e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1251.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 3.31136e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1253.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 3.60886e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1255.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 4.57838e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1257.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 4.77223e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1259.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 4.40247e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1261.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 90
Step 0 Loss 0.134392
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1263.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 3.91176e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1265.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 4.44169e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1267.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 4.03256e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1269.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 4.8869e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1271.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 3.18723e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1273.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 5.30841e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1275.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 91
Step 0 Loss 0.154506
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1277.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 5.38514e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1279.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 6.56582e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1281.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 6.16445e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1283.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 4.8436e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1285.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 3.73268e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1287.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 5.77325e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1289.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 92
Step 0 Loss 0.202538
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1291.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 5.07804e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1293.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 4.95053e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1295.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 5.1166e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1297.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 4.58709e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1299.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 4.6013e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1301.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 5.00522e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1303.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 93
Step 0 Loss 0.163677
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1305.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 3.70645e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1307.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 3.75287e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1309.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 4.01385e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1311.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 5.70001e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1313.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 4.07759e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1315.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 4.41683e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1317.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 94
Step 0 Loss 0.177907
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1319.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 3.92898e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1321.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 3.53368e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1323.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 4.13751e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1325.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 3.63113e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1327.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 3.91052e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1329.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 3.46758e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1331.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 95
Step 0 Loss 0.186947
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1333.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 5.92298e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1335.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 4.22436e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1337.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 5.05384e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1339.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 5.01794e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1341.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 3.78704e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1343.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 5.28369e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1345.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 96
Step 0 Loss 0.215081
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1347.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 4.1023e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1349.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 4.59761e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1351.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 4.48741e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1353.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 4.47787e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1355.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 4.9067e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1357.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 4.1723e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1359.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 97
Step 0 Loss 0.296952
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1361.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 4.12972e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1363.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 3.91994e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1365.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 3.1483e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1367.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 3.69345e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1369.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 3.78896e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1371.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 4.1823e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1373.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 98
Step 0 Loss 0.165632
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1375.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 4.16688e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1377.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 3.55184e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1379.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 4.12624e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1381.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 3.65736e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1383.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 4.25291e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1385.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 3.83585e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1387.png" /></p>
<div class="codehilite"><pre><span></span>New data, epoch 99
Step 0 Loss 0.166703
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1389.png" /></p>
<div class="codehilite"><pre><span></span>Step 100 Loss 3.71602e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1391.png" /></p>
<div class="codehilite"><pre><span></span>Step 200 Loss 4.16517e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1393.png" /></p>
<div class="codehilite"><pre><span></span>Step 300 Loss 3.91581e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1395.png" /></p>
<div class="codehilite"><pre><span></span>Step 400 Loss 4.73584e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1397.png" /></p>
<div class="codehilite"><pre><span></span>Step 500 Loss 3.76653e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1399.png" /></p>
<div class="codehilite"><pre><span></span>Step 600 Loss 5.16872e-05
</pre></div>


<p><img alt="png" src="RNN_files/RNN_6_1401.png" /></p>
<div class="codehilite"><pre><span></span><span class="k">if</span> <span class="s1">&#39;session&#39;</span> <span class="ow">in</span> <span class="nb">locals</span><span class="p">()</span> <span class="ow">and</span> <span class="n">session</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Close interactive session&#39;</span><span class="p">)</span>
    <span class="n">session</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
            </div>
            <!-- /.entry-content -->
    <hr/>
    <section class="comments" id="comments">
        <h2>Comments</h2>

        <div id="disqus_thread"></div>
        <script type="text/javascript">
            /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
            var disqus_shortname = 'dwjbosman'; // required: replace example with your forum shortname

                    var disqus_identifier = 'a-notebook';
                var disqus_url = 'https://dwjbosman.github.io/2017/a-notebook.html';

            var disqus_config = function () {
                this.language = "en";
            };

            /* * * DON'T EDIT BELOW THIS LINE * * */
            (function () {
                var dsq = document.createElement('script');
                dsq.type = 'text/javascript';
                dsq.async = true;
                dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
            })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by
            Disqus.</a></noscript>
        <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

    </section>
        </article>
    </section>

        </div>
        <div class="col-sm-3" id="sidebar">
            <aside>
<!-- Sidebar -->
<section class="well well-sm">
  <ul class="list-group list-group-flush">

<!-- Sidebar/Social -->
<li class="list-group-item">
  <h4><i class="fa fa-home fa-lg"></i><span class="icon-label">Social</span></h4>
  <ul class="list-group" id="social">
    <li class="list-group-item"><a href="https://github.com/dwjbosman/"><i class="fa fa-github-square fa-lg"></i> GitHub</a></li>
  </ul>
</li>
<!-- End Sidebar/Social -->

<!-- Sidebar/Github -->
<li class="list-group-item">
  <h4><i class="fa fa-github fa-lg"></i><span class="icon-label">GitHub Repos</span></h4>
  <div id="gh_repos">
    <p class="list-group-item">Status updating...</p>
  </div>
</li>
<!-- End Sidebar/Github -->

<!-- Sidebar/Links -->
<li class="list-group-item">
  <h4><i class="fa fa-external-link-square fa-lg"></i><span class="icon-label">Links</span></h4>
  <ul class="list-group" id="links">
    <li class="list-group-item">
      <a href="https://www.the-future-group.com/" target="_blank">TFG</a>
    </li>
  </ul>
</li>
<!-- End Sidebar/Links -->
  </ul>
</section>
<!-- End Sidebar -->            </aside>
        </div>
    </div>
</div>
<footer>
   <div class="container">
      <hr>
      <div class="row">
         <div class="col-xs-10">&copy; 2017 Dinne Bosman
            &middot; Powered by <a href="https://github.com/getpelican/pelican-themes/tree/master/pelican-bootstrap3" target="_blank">pelican-bootstrap3</a>,
            <a href="http://docs.getpelican.com/" target="_blank">Pelican</a>,
            <a href="http://getbootstrap.com" target="_blank">Bootstrap</a>                <p><small>  <a rel="license" href="https://creativecommons.org/licenses/by/4.0/deed.en"><img alt="Creative Commons License" style="border-width:0" src="//i.creativecommons.org/l/by/4.0/80x15.png" /></a>
    Content
  licensed under a <a rel="license" href="https://creativecommons.org/licenses/by/4.0/deed.en">Creative Commons Attribution 4.0 International License</a>, except where indicated otherwise.
</small></p>
         </div>
         <div class="col-xs-2"><p class="pull-right"><i class="fa fa-arrow-up"></i> <a href="#">Back to top</a></p></div>
      </div>
   </div>
</footer>
<script src="https://dwjbosman.github.io/theme/js/jquery.min.js"></script>

<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="https://dwjbosman.github.io/theme/js/bootstrap.min.js"></script>

<!-- Enable responsive features in IE8 with Respond.js (https://github.com/scottjehl/Respond) -->
<script src="https://dwjbosman.github.io/theme/js/respond.min.js"></script>


    <script src="https://dwjbosman.github.io/theme/js/bodypadding.js"></script>

<!-- GitHub JS Code -->
<script type="text/javascript">
$(document).ready(function () {
  if (!window.jXHR) {
    var jxhr = document.createElement('script');
    jxhr.type = 'text/javascript';
    jxhr.src = 'https://dwjbosman.github.io/theme/js/jXHR.js';
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(jxhr, s);
  }

  github.showRepos({
    user: 'dwjbosman',
    count: 5,
    skip_forks: false,
    target: '#gh_repos'
  });
});
</script>
<script src="https://dwjbosman.github.io/theme/js/github.js" type="text/javascript"></script>
<!-- End GitHub JS Code -->
    <!-- Disqus -->
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'dwjbosman'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function () {
            var s = document.createElement('script');
            s.async = true;
            s.type = 'text/javascript';
            s.src = '//' + disqus_shortname + '.disqus.com/count.js';
            (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
        }());
    </script>
    <!-- End Disqus Code -->


</body>
</html>