<!DOCTYPE html>
 <html><head><meta charset="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><link rel="preload" href="/component---src-layouts-index-jsx-4d85d3db704abfa04d66.js" as="script"/><link rel="preload" href="/component---src-templates-post-jsx-241c07880a099ad8a1b9.js" as="script"/><link rel="preload" href="/path---lstm-neural-network-for-sequence-learning-e24aeb2f834e204e0141.js" as="script"/><link rel="preload" href="/app-071454487b3aed365e53.js" as="script"/><link rel="preload" href="/commons-d9f717f2c7dd22daba78.js" as="script"/><script id="webpack-manifest">
            //<![CDATA[
            window.webpackManifest = {"231608221292675":"app-071454487b3aed365e53.js","99219681209289":"component---node-modules-gatsby-plugin-offline-app-shell-js-5c4c5a0f7af9dc69d6d7.js","213130420965792":"component---src-templates-post-jsx-241c07880a099ad8a1b9.js","183400410456155":"component---src-templates-tag-jsx-aaa311d3d699ffd762ea.js","129745722219136":"component---src-templates-category-jsx-04a9496049863016d7c6.js","144251824217401":"component---src-pages-about-jsx-ad03a97f9d94d9bb3877.js","213534597649335":"component---src-pages-index-jsx-5cd3e3488ba2b0d716bd.js","60335399758886":"path----557518bd178906f8d58a.js","210333531512890":"path---offline-plugin-app-shell-fallback-a0e39f21c11f6a62c5ab.js","98749194253172":"path---first-post-3d21d8e7b9dd1adef5e7.js","152973645723092":"path---real-time-sound-synthesis-with-jupyter-fd5b75d90284638aba23.js","75487621532073":"path---lstm-neural-network-for-sequence-learning-e24aeb2f834e204e0141.js","269976026368624":"path---generating-text-using-an-lstm-neural-network-77842df3d8ee5536c42f.js","137055218471202":"path---vhdl-i-2-s-transmitter-5dcc80b4f7a5bb48e71f.js","36940768073078":"path---vhdl-sine-wave-oscillator-12cd9521d2d565fdd874.js","260759634830010":"path---tags-github-a9c0a3daa8fff9302933.js","17976388717192":"path---tags-blog-e6feb522c1ce480075a7.js","154462359958523":"path---tags-audio-7cfffbef57fb597d2291.js","210537118814002":"path---tags-sound-5cabfb9bf5f3f5c29af2.js","255169366617017":"path---tags-jupyter-b2004941289a793c8e9c.js","67335324583948":"path---tags-javascript-76247e3dc8e1bb1b251f.js","66827178591201":"path---tags-lstm-5f61e9e2ad1ddee2ebe3.js","92932695606945":"path---tags-artificial-intelligence-4fb433b9bcbe5e2d8186.js","151285986489463":"path---tags-tensorflow-b7fd83b9983cfa2cb6b9.js","127133139012176":"path---tags-vhdl-fpga-dsp-54f62971d05dba132880.js","28831943093088":"path---categories-blaat-69d742714b9a4417c8d7.js","237721887957054":"path---categories-jupyter-826c3205e1c99413c6ef.js","19120532712671":"path---categories-artificial-intelligence-e32b20c824e9cebd437a.js","170999283722127":"path---categories-fpga-12b1c4d7ac5ae02ca487.js","273950069227526":"path---about-a0e39f21c11f6a62c5ab.js","142629428675168":"path---index-08422affd66f66c09b71.js","79611799117203":"component---src-layouts-index-jsx-4d85d3db704abfa04d66.js"}
            //]]>
            </script><title data-react-helmet="true">LSTM neural network for sequence learning | Dinne&#x27;s blog</title><link data-react-helmet="true" rel="canonical" href="https://dwjbosman.github.io/lstm-neural-network-for-sequence-learning"/><meta data-react-helmet="true" name="description" content="In 1996, during my last year in High School, I borrowed a book of a friend about neural networks. It explained how a two layer perceptron…"/><meta data-react-helmet="true" name="image" content="https://dwjbosman.github.io/logos/network.jpg"/><meta data-react-helmet="true" property="og:url" content="https://dwjbosman.github.io//lstm-neural-network-for-sequence-learning"/><meta data-react-helmet="true" property="og:type" content="article"/><meta data-react-helmet="true" property="og:title" content="LSTM neural network for sequence learning"/><meta data-react-helmet="true" property="og:description" content="In 1996, during my last year in High School, I borrowed a book of a friend about neural networks. It explained how a two layer perceptron…"/><meta data-react-helmet="true" property="og:image" content="https://dwjbosman.github.io/logos/network.jpg"/><meta data-react-helmet="true" property="fb:app_id" content="1825356251115265"/><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"/><meta data-react-helmet="true" name="twitter:creator" content=""/><meta data-react-helmet="true" name="twitter:title" content="LSTM neural network for sequence learning"/><meta data-react-helmet="true" name="twitter:description" content="In 1996, during my last year in High School, I borrowed a book of a friend about neural networks. It explained how a two layer perceptron…"/><meta data-react-helmet="true" name="twitter:image" content="https://dwjbosman.github.io/logos/network.jpg"/><script data-react-helmet="true" src="https://cdn.plot.ly/plotly-latest.min.js"></script><script data-react-helmet="true" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.5/require.min.js"></script><script data-react-helmet="true" src="https://code.jquery.com/jquery-3.2.1.min.js"></script><script data-react-helmet="true" type="application/ld+json">[{"@context":"http://schema.org","@type":"WebSite","url":"https://dwjbosman.github.io/","name":"LSTM neural network for sequence learning","alternateName":"Blog about software development"},[{"@context":"http://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"item":{"@id":"https://dwjbosman.github.io//lstm-neural-network-for-sequence-learning","name":"LSTM neural network for sequence learning","image":"https://dwjbosman.github.io/logos/network.jpg"}}]},{"@context":"http://schema.org","@type":"BlogPosting","url":"https://dwjbosman.github.io/","name":"LSTM neural network for sequence learning","alternateName":"Blog about software development","headline":"LSTM neural network for sequence learning","image":{"@type":"ImageObject","url":"https://dwjbosman.github.io/logos/network.jpg"},"description":"In 1996, during my last year in High School, I borrowed a book of a friend about neural networks. It explained how a two layer perceptron…"}]]</script><style type="text/css">
    .anchor {
      float: left;
      padding-right: 4px;
      margin-left: -20px;
    }
    h1 .anchor svg,
    h2 .anchor svg,
    h3 .anchor svg,
    h4 .anchor svg,
    h5 .anchor svg,
    h6 .anchor svg {
      visibility: hidden;
    }
    h1:hover .anchor svg,
    h2:hover .anchor svg,
    h3:hover .anchor svg,
    h4:hover .anchor svg,
    h5:hover .anchor svg,
    h6:hover .anchor svg {
      visibility: visible;
    }
  </style><script>
    document.addEventListener("DOMContentLoaded", function(event) {
      var hash = location.hash.replace('#', '')
      if (hash !== '') {
        var element = document.getElementById(hash)
        if (element) {
          var offset = element.offsetTop
          // Wait for the browser to finish rendering before scrolling.
          setTimeout((function() {
            window.scrollTo(0, offset - 0)
          }), 0)
        }
      }
    })
  </script><link rel="sitemap" type="application/xml" href="/sitemap.xml"/><link rel="manifest" href="/manifest.json"/><meta name="theme-color" content="#c62828"/><link rel="alternate" type="application/rss+xml" href="/rss.xml"/><script>
  !function(e,t,r){function n(){for(;d[0]&&"loaded"==d[0][f];)c=d.shift(),c[o]=!i.parentNode.insertBefore(c,i)}for(var s,a,c,d=[],i=e.scripts[0],o="onreadystatechange",f="readyState";s=r.shift();)a=e.createElement(t),"async"in i?(a.async=!1,e.head.appendChild(a)):i[f]?(d.push(a),a[o]=n):e.write("<"+t+' src="'+s+'" defer></'+t+">"),a.src=s}(document,"script",[
  "/commons-d9f717f2c7dd22daba78.js","/app-071454487b3aed365e53.js","/path---lstm-neural-network-for-sequence-learning-e24aeb2f834e204e0141.js","/component---src-templates-post-jsx-241c07880a099ad8a1b9.js","/component---src-layouts-index-jsx-4d85d3db704abfa04d66.js"
])
  </script><style id="gatsby-inlined-css">@import url(https://fonts.googleapis.com/css?family=Roboto:400,500,700|Material+Icons);.user-links{display:flex;flex-wrap:wrap;justify-content:center;align-items:center;max-width:100%}.user-info p{margin:15px 0}.post-preview-tags{margin:5px 2px 0}.post-tag-container{display:flex;flex-flow:row wrap;align-content:center;justify-content:center;align-items:center}.post-cover{background-size:cover;background-repeat:no-repeat;background-position:50% 50%;padding:0!important}.post-info{display:flex;flex-flow:row wrap;justify-content:space-between;margin-bottom:30px;margin-top:10px}.post-info .category-link,.post-info>div{margin-right:20px}.social-links{display:flex;flex-direction:row;flex-wrap:wrap;justify-content:center;align-content:center;align-items:center;margin:15px 0}.social-links>div{margin:5px 15px}.social-links .share-count{text-align:center}.darker-background,.main-container{background-color:#e0e0e0}a:link{color:#c62828;text-decoration:none}.post-suggestions{display:flex;flex-wrap:nowrap!important;justify-content:space-between;background-color:#d3d3d3}@media (max-width:359px){.post-suggestions .hide-on-mobile{display:none}}.post-suggestions .post-suggestion{display:flex;align-items:center;margin:0 15px;color:#c62828!important}.post-suggestions .post-suggestion .headline-container{margin-right:10px;margin-left:10px}.post-suggestions .post-suggestion .arrow-nav{margin-top:15px}.post-suggestions .secondary-color{color:#c62828!important}code[class*=language-],pre[class*=language-]{font-family:Consolas,Menlo,Monaco,Andale Mono WT,Andale Mono,Lucida Console,Lucida Sans Typewriter,DejaVu Sans Mono,Bitstream Vera Sans Mono,Liberation Mono,Nimbus Mono L,Courier New,Courier,monospace;font-size:14px;line-height:1.375;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-ms-hyphens:none;hyphens:none;background:#1d1f21;color:#c5c8c6}code[class*=language-]::-moz-selection,code[class*=language-] ::-moz-selection,pre[class*=language-]::-moz-selection,pre[class*=language-] ::-moz-selection{text-shadow:none;background:#b4b7b4}code[class*=language-]::selection,code[class*=language-] ::selection,pre[class*=language-]::selection,pre[class*=language-] ::selection{text-shadow:none;background:#b4b7b4}pre[class*=language-]{padding:1em;margin:.5em 0;overflow:auto}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em}.token.cdata,.token.comment,.token.doctype,.token.prolog{color:#969896}.token.punctuation{color:#c5c8c6}.token.namespace{opacity:.7}.token.boolean,.token.number,.token.operator{color:#de935f}.token.property{color:#f0c674}.token.tag{color:#81a2be}.token.string{color:#8abeb7}.token.selector{color:#b294bb}.token.attr-name{color:#de935f}.language-css .token.string,.style .token.string,.token.entity,.token.url{color:#8abeb7}.token.attr-value,.token.control,.token.directive,.token.keyword,.token.unit{color:#b5bd68}.token.atrule,.token.regex,.token.statement{color:#8abeb7}.token.placeholder,.token.variable{color:#81a2be}.token.deleted{text-decoration:line-through}.token.inserted{border-bottom:1px dotted #fff;text-decoration:none}.token.italic{font-style:italic}.token.bold,.token.important{font-weight:700}.token.important{color:#c66}.token.entity{cursor:help}pre>code.highlight{outline:.4em solid #c66;outline-offset:.4em}.post-page{display:flex;flex-direction:column;align-items:center}.post-overlap{margin-top:-80px!important;z-index:2}.post-overlap-mobile{margin-top:-20px!important;z-index:2}.post-page-contents{justify-content:center;width:100%;max-width:752px}.post-page-contents .gatsby-resp-image-wrapper{z-index:6!important}.post-page-contents img,.post-page-contents video{max-width:100%}.post-page-contents .post-header{margin:0;max-width:100%;word-wrap:break-word;white-space:normal}.post-page-contents .post,.post-page-contents .post .post-meta{display:flex;flex-direction:column;justify-content:center}.post-page-contents .post .post-body{max-width:100%}.post-page-contents .post .post-body>h1,.post-page-contents .post .post-body>h2,.post-page-contents .post .post-body>h3,.post-page-contents .post .post-body>h4,.post-page-contents .post .post-body>h5,.post-page-contents .post .post-body>h6{margin-top:30px;margin-bottom:10px!important}.post-page-contents .post .post-body li{margin-top:15px}.post-page-contents .post .post-body table{width:100%;max-width:100%;margin-bottom:20px}.post-page-contents .post .post-body table>tbody>tr>th,.post-page-contents .post .post-body table>tfoot>tr>th,.post-page-contents .post .post-body table>thead>tr>th{text-align:left}.post-page-contents .post .post-body table>tbody>tr>td,.post-page-contents .post .post-body table>tbody>tr>th,.post-page-contents .post .post-body table>tfoot>tr>td,.post-page-contents .post .post-body table>tfoot>tr>th,.post-page-contents .post .post-body table>thead>tr>td,.post-page-contents .post .post-body table>thead>tr>th{padding:10px;line-height:1.429}.post-page-contents .post .post-body table>thead>tr>th{border-bottom:2px solid rgba(0,0,0,.12);font-weight:700}.post-page-contents .post .post-body table>tbody+tbody{border-top:2px solid rgba(0,0,0,.12)}.post-page-contents .post .post-body table>tbody>tr>td{border-bottom:1px solid rgba(0,0,0,.12)}.post-page-contents .post .post-body :target:before{content:"";display:block;position:relative;height:68px;margin:-68px 0 0}.post-preview-cover{background-size:cover;background-repeat:no-repeat;background-position:50% 50%;padding:0!important}.about-wrapper{display:flex;flex-direction:column;align-items:center}.about-wrapper .about-img{border-radius:50%;width:300px;height:300px;margin:10px 0}@media (max-width:359px){.about-wrapper .about-img{padding:20px}}.about-wrapper .about-text{max-width:640px;margin:20px 0!important}@media (max-width:359px){.about-wrapper .about-text{margin:5px 0!important}}/*!
 *  Font Awesome 4.7.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */@font-face{font-family:FontAwesome;src:url(/static/fontawesome-webfont.674f50d2.eot);src:url(/static/fontawesome-webfont.674f50d2.eot?#iefix&v=4.7.0) format("embedded-opentype"),url(/static/fontawesome-webfont.af7ae505.woff2) format("woff2"),url(/static/fontawesome-webfont.fee66e71.woff) format("woff"),url(/static/fontawesome-webfont.b06871f2.ttf) format("truetype"),url(/static/fontawesome-webfont.912ec66d.svg#fontawesomeregular) format("svg");font-weight:400;font-style:normal}.fa{display:inline-block;font:normal normal normal 14px/1 FontAwesome;font-size:inherit;text-rendering:auto;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}.fa-lg{font-size:1.33333em;line-height:.75em;vertical-align:-15%}.fa-2x{font-size:2em}.fa-3x{font-size:3em}.fa-4x{font-size:4em}.fa-5x{font-size:5em}.fa-fw{width:1.28571em;text-align:center}.fa-ul{padding-left:0;margin-left:2.14286em;list-style-type:none}.fa-ul>li{position:relative}.fa-li{position:absolute;left:-2.14286em;width:2.14286em;top:.14286em;text-align:center}.fa-li.fa-lg{left:-1.85714em}.fa-border{padding:.2em .25em .15em;border:.08em solid #eee;border-radius:.1em}.fa-pull-left{float:left}.fa-pull-right{float:right}.fa.fa-pull-left{margin-right:.3em}.fa.fa-pull-right{margin-left:.3em}.pull-right{float:right}.pull-left{float:left}.fa.pull-left{margin-right:.3em}.fa.pull-right{margin-left:.3em}.fa-spin{-webkit-animation:fa-spin 2s infinite linear;animation:fa-spin 2s infinite linear}.fa-pulse{-webkit-animation:fa-spin 1s infinite steps(8);animation:fa-spin 1s infinite steps(8)}@-webkit-keyframes fa-spin{0%{-webkit-transform:rotate(0deg);transform:rotate(0deg)}to{-webkit-transform:rotate(359deg);transform:rotate(359deg)}}@keyframes fa-spin{0%{-webkit-transform:rotate(0deg);transform:rotate(0deg)}to{-webkit-transform:rotate(359deg);transform:rotate(359deg)}}.fa-rotate-90{-ms-filter:"progid:DXImageTransform.Microsoft.BasicImage(rotation=1)";-webkit-transform:rotate(90deg);-ms-transform:rotate(90deg);transform:rotate(90deg)}.fa-rotate-180{-ms-filter:"progid:DXImageTransform.Microsoft.BasicImage(rotation=2)";-webkit-transform:rotate(180deg);-ms-transform:rotate(180deg);transform:rotate(180deg)}.fa-rotate-270{-ms-filter:"progid:DXImageTransform.Microsoft.BasicImage(rotation=3)";-webkit-transform:rotate(270deg);-ms-transform:rotate(270deg);transform:rotate(270deg)}.fa-flip-horizontal{-ms-filter:"progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1)";-webkit-transform:scaleX(-1);-ms-transform:scaleX(-1);transform:scaleX(-1)}.fa-flip-vertical{-ms-filter:"progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1)";-webkit-transform:scaleY(-1);-ms-transform:scaleY(-1);transform:scaleY(-1)}:root .fa-flip-horizontal,:root .fa-flip-vertical,:root .fa-rotate-90,:root .fa-rotate-180,:root .fa-rotate-270{filter:none}.fa-stack{position:relative;display:inline-block;width:2em;height:2em;line-height:2em;vertical-align:middle}.fa-stack-1x,.fa-stack-2x{position:absolute;left:0;width:100%;text-align:center}.fa-stack-1x{line-height:inherit}.fa-stack-2x{font-size:2em}.fa-inverse{color:#fff}.fa-glass:before{content:"\F000"}.fa-music:before{content:"\F001"}.fa-search:before{content:"\F002"}.fa-envelope-o:before{content:"\F003"}.fa-heart:before{content:"\F004"}.fa-star:before{content:"\F005"}.fa-star-o:before{content:"\F006"}.fa-user:before{content:"\F007"}.fa-film:before{content:"\F008"}.fa-th-large:before{content:"\F009"}.fa-th:before{content:"\F00A"}.fa-th-list:before{content:"\F00B"}.fa-check:before{content:"\F00C"}.fa-close:before,.fa-remove:before,.fa-times:before{content:"\F00D"}.fa-search-plus:before{content:"\F00E"}.fa-search-minus:before{content:"\F010"}.fa-power-off:before{content:"\F011"}.fa-signal:before{content:"\F012"}.fa-cog:before,.fa-gear:before{content:"\F013"}.fa-trash-o:before{content:"\F014"}.fa-home:before{content:"\F015"}.fa-file-o:before{content:"\F016"}.fa-clock-o:before{content:"\F017"}.fa-road:before{content:"\F018"}.fa-download:before{content:"\F019"}.fa-arrow-circle-o-down:before{content:"\F01A"}.fa-arrow-circle-o-up:before{content:"\F01B"}.fa-inbox:before{content:"\F01C"}.fa-play-circle-o:before{content:"\F01D"}.fa-repeat:before,.fa-rotate-right:before{content:"\F01E"}.fa-refresh:before{content:"\F021"}.fa-list-alt:before{content:"\F022"}.fa-lock:before{content:"\F023"}.fa-flag:before{content:"\F024"}.fa-headphones:before{content:"\F025"}.fa-volume-off:before{content:"\F026"}.fa-volume-down:before{content:"\F027"}.fa-volume-up:before{content:"\F028"}.fa-qrcode:before{content:"\F029"}.fa-barcode:before{content:"\F02A"}.fa-tag:before{content:"\F02B"}.fa-tags:before{content:"\F02C"}.fa-book:before{content:"\F02D"}.fa-bookmark:before{content:"\F02E"}.fa-print:before{content:"\F02F"}.fa-camera:before{content:"\F030"}.fa-font:before{content:"\F031"}.fa-bold:before{content:"\F032"}.fa-italic:before{content:"\F033"}.fa-text-height:before{content:"\F034"}.fa-text-width:before{content:"\F035"}.fa-align-left:before{content:"\F036"}.fa-align-center:before{content:"\F037"}.fa-align-right:before{content:"\F038"}.fa-align-justify:before{content:"\F039"}.fa-list:before{content:"\F03A"}.fa-dedent:before,.fa-outdent:before{content:"\F03B"}.fa-indent:before{content:"\F03C"}.fa-video-camera:before{content:"\F03D"}.fa-image:before,.fa-photo:before,.fa-picture-o:before{content:"\F03E"}.fa-pencil:before{content:"\F040"}.fa-map-marker:before{content:"\F041"}.fa-adjust:before{content:"\F042"}.fa-tint:before{content:"\F043"}.fa-edit:before,.fa-pencil-square-o:before{content:"\F044"}.fa-share-square-o:before{content:"\F045"}.fa-check-square-o:before{content:"\F046"}.fa-arrows:before{content:"\F047"}.fa-step-backward:before{content:"\F048"}.fa-fast-backward:before{content:"\F049"}.fa-backward:before{content:"\F04A"}.fa-play:before{content:"\F04B"}.fa-pause:before{content:"\F04C"}.fa-stop:before{content:"\F04D"}.fa-forward:before{content:"\F04E"}.fa-fast-forward:before{content:"\F050"}.fa-step-forward:before{content:"\F051"}.fa-eject:before{content:"\F052"}.fa-chevron-left:before{content:"\F053"}.fa-chevron-right:before{content:"\F054"}.fa-plus-circle:before{content:"\F055"}.fa-minus-circle:before{content:"\F056"}.fa-times-circle:before{content:"\F057"}.fa-check-circle:before{content:"\F058"}.fa-question-circle:before{content:"\F059"}.fa-info-circle:before{content:"\F05A"}.fa-crosshairs:before{content:"\F05B"}.fa-times-circle-o:before{content:"\F05C"}.fa-check-circle-o:before{content:"\F05D"}.fa-ban:before{content:"\F05E"}.fa-arrow-left:before{content:"\F060"}.fa-arrow-right:before{content:"\F061"}.fa-arrow-up:before{content:"\F062"}.fa-arrow-down:before{content:"\F063"}.fa-mail-forward:before,.fa-share:before{content:"\F064"}.fa-expand:before{content:"\F065"}.fa-compress:before{content:"\F066"}.fa-plus:before{content:"\F067"}.fa-minus:before{content:"\F068"}.fa-asterisk:before{content:"\F069"}.fa-exclamation-circle:before{content:"\F06A"}.fa-gift:before{content:"\F06B"}.fa-leaf:before{content:"\F06C"}.fa-fire:before{content:"\F06D"}.fa-eye:before{content:"\F06E"}.fa-eye-slash:before{content:"\F070"}.fa-exclamation-triangle:before,.fa-warning:before{content:"\F071"}.fa-plane:before{content:"\F072"}.fa-calendar:before{content:"\F073"}.fa-random:before{content:"\F074"}.fa-comment:before{content:"\F075"}.fa-magnet:before{content:"\F076"}.fa-chevron-up:before{content:"\F077"}.fa-chevron-down:before{content:"\F078"}.fa-retweet:before{content:"\F079"}.fa-shopping-cart:before{content:"\F07A"}.fa-folder:before{content:"\F07B"}.fa-folder-open:before{content:"\F07C"}.fa-arrows-v:before{content:"\F07D"}.fa-arrows-h:before{content:"\F07E"}.fa-bar-chart-o:before,.fa-bar-chart:before{content:"\F080"}.fa-twitter-square:before{content:"\F081"}.fa-facebook-square:before{content:"\F082"}.fa-camera-retro:before{content:"\F083"}.fa-key:before{content:"\F084"}.fa-cogs:before,.fa-gears:before{content:"\F085"}.fa-comments:before{content:"\F086"}.fa-thumbs-o-up:before{content:"\F087"}.fa-thumbs-o-down:before{content:"\F088"}.fa-star-half:before{content:"\F089"}.fa-heart-o:before{content:"\F08A"}.fa-sign-out:before{content:"\F08B"}.fa-linkedin-square:before{content:"\F08C"}.fa-thumb-tack:before{content:"\F08D"}.fa-external-link:before{content:"\F08E"}.fa-sign-in:before{content:"\F090"}.fa-trophy:before{content:"\F091"}.fa-github-square:before{content:"\F092"}.fa-upload:before{content:"\F093"}.fa-lemon-o:before{content:"\F094"}.fa-phone:before{content:"\F095"}.fa-square-o:before{content:"\F096"}.fa-bookmark-o:before{content:"\F097"}.fa-phone-square:before{content:"\F098"}.fa-twitter:before{content:"\F099"}.fa-facebook-f:before,.fa-facebook:before{content:"\F09A"}.fa-github:before{content:"\F09B"}.fa-unlock:before{content:"\F09C"}.fa-credit-card:before{content:"\F09D"}.fa-feed:before,.fa-rss:before{content:"\F09E"}.fa-hdd-o:before{content:"\F0A0"}.fa-bullhorn:before{content:"\F0A1"}.fa-bell:before{content:"\F0F3"}.fa-certificate:before{content:"\F0A3"}.fa-hand-o-right:before{content:"\F0A4"}.fa-hand-o-left:before{content:"\F0A5"}.fa-hand-o-up:before{content:"\F0A6"}.fa-hand-o-down:before{content:"\F0A7"}.fa-arrow-circle-left:before{content:"\F0A8"}.fa-arrow-circle-right:before{content:"\F0A9"}.fa-arrow-circle-up:before{content:"\F0AA"}.fa-arrow-circle-down:before{content:"\F0AB"}.fa-globe:before{content:"\F0AC"}.fa-wrench:before{content:"\F0AD"}.fa-tasks:before{content:"\F0AE"}.fa-filter:before{content:"\F0B0"}.fa-briefcase:before{content:"\F0B1"}.fa-arrows-alt:before{content:"\F0B2"}.fa-group:before,.fa-users:before{content:"\F0C0"}.fa-chain:before,.fa-link:before{content:"\F0C1"}.fa-cloud:before{content:"\F0C2"}.fa-flask:before{content:"\F0C3"}.fa-cut:before,.fa-scissors:before{content:"\F0C4"}.fa-copy:before,.fa-files-o:before{content:"\F0C5"}.fa-paperclip:before{content:"\F0C6"}.fa-floppy-o:before,.fa-save:before{content:"\F0C7"}.fa-square:before{content:"\F0C8"}.fa-bars:before,.fa-navicon:before,.fa-reorder:before{content:"\F0C9"}.fa-list-ul:before{content:"\F0CA"}.fa-list-ol:before{content:"\F0CB"}.fa-strikethrough:before{content:"\F0CC"}.fa-underline:before{content:"\F0CD"}.fa-table:before{content:"\F0CE"}.fa-magic:before{content:"\F0D0"}.fa-truck:before{content:"\F0D1"}.fa-pinterest:before{content:"\F0D2"}.fa-pinterest-square:before{content:"\F0D3"}.fa-google-plus-square:before{content:"\F0D4"}.fa-google-plus:before{content:"\F0D5"}.fa-money:before{content:"\F0D6"}.fa-caret-down:before{content:"\F0D7"}.fa-caret-up:before{content:"\F0D8"}.fa-caret-left:before{content:"\F0D9"}.fa-caret-right:before{content:"\F0DA"}.fa-columns:before{content:"\F0DB"}.fa-sort:before,.fa-unsorted:before{content:"\F0DC"}.fa-sort-desc:before,.fa-sort-down:before{content:"\F0DD"}.fa-sort-asc:before,.fa-sort-up:before{content:"\F0DE"}.fa-envelope:before{content:"\F0E0"}.fa-linkedin:before{content:"\F0E1"}.fa-rotate-left:before,.fa-undo:before{content:"\F0E2"}.fa-gavel:before,.fa-legal:before{content:"\F0E3"}.fa-dashboard:before,.fa-tachometer:before{content:"\F0E4"}.fa-comment-o:before{content:"\F0E5"}.fa-comments-o:before{content:"\F0E6"}.fa-bolt:before,.fa-flash:before{content:"\F0E7"}.fa-sitemap:before{content:"\F0E8"}.fa-umbrella:before{content:"\F0E9"}.fa-clipboard:before,.fa-paste:before{content:"\F0EA"}.fa-lightbulb-o:before{content:"\F0EB"}.fa-exchange:before{content:"\F0EC"}.fa-cloud-download:before{content:"\F0ED"}.fa-cloud-upload:before{content:"\F0EE"}.fa-user-md:before{content:"\F0F0"}.fa-stethoscope:before{content:"\F0F1"}.fa-suitcase:before{content:"\F0F2"}.fa-bell-o:before{content:"\F0A2"}.fa-coffee:before{content:"\F0F4"}.fa-cutlery:before{content:"\F0F5"}.fa-file-text-o:before{content:"\F0F6"}.fa-building-o:before{content:"\F0F7"}.fa-hospital-o:before{content:"\F0F8"}.fa-ambulance:before{content:"\F0F9"}.fa-medkit:before{content:"\F0FA"}.fa-fighter-jet:before{content:"\F0FB"}.fa-beer:before{content:"\F0FC"}.fa-h-square:before{content:"\F0FD"}.fa-plus-square:before{content:"\F0FE"}.fa-angle-double-left:before{content:"\F100"}.fa-angle-double-right:before{content:"\F101"}.fa-angle-double-up:before{content:"\F102"}.fa-angle-double-down:before{content:"\F103"}.fa-angle-left:before{content:"\F104"}.fa-angle-right:before{content:"\F105"}.fa-angle-up:before{content:"\F106"}.fa-angle-down:before{content:"\F107"}.fa-desktop:before{content:"\F108"}.fa-laptop:before{content:"\F109"}.fa-tablet:before{content:"\F10A"}.fa-mobile-phone:before,.fa-mobile:before{content:"\F10B"}.fa-circle-o:before{content:"\F10C"}.fa-quote-left:before{content:"\F10D"}.fa-quote-right:before{content:"\F10E"}.fa-spinner:before{content:"\F110"}.fa-circle:before{content:"\F111"}.fa-mail-reply:before,.fa-reply:before{content:"\F112"}.fa-github-alt:before{content:"\F113"}.fa-folder-o:before{content:"\F114"}.fa-folder-open-o:before{content:"\F115"}.fa-smile-o:before{content:"\F118"}.fa-frown-o:before{content:"\F119"}.fa-meh-o:before{content:"\F11A"}.fa-gamepad:before{content:"\F11B"}.fa-keyboard-o:before{content:"\F11C"}.fa-flag-o:before{content:"\F11D"}.fa-flag-checkered:before{content:"\F11E"}.fa-terminal:before{content:"\F120"}.fa-code:before{content:"\F121"}.fa-mail-reply-all:before,.fa-reply-all:before{content:"\F122"}.fa-star-half-empty:before,.fa-star-half-full:before,.fa-star-half-o:before{content:"\F123"}.fa-location-arrow:before{content:"\F124"}.fa-crop:before{content:"\F125"}.fa-code-fork:before{content:"\F126"}.fa-chain-broken:before,.fa-unlink:before{content:"\F127"}.fa-question:before{content:"\F128"}.fa-info:before{content:"\F129"}.fa-exclamation:before{content:"\F12A"}.fa-superscript:before{content:"\F12B"}.fa-subscript:before{content:"\F12C"}.fa-eraser:before{content:"\F12D"}.fa-puzzle-piece:before{content:"\F12E"}.fa-microphone:before{content:"\F130"}.fa-microphone-slash:before{content:"\F131"}.fa-shield:before{content:"\F132"}.fa-calendar-o:before{content:"\F133"}.fa-fire-extinguisher:before{content:"\F134"}.fa-rocket:before{content:"\F135"}.fa-maxcdn:before{content:"\F136"}.fa-chevron-circle-left:before{content:"\F137"}.fa-chevron-circle-right:before{content:"\F138"}.fa-chevron-circle-up:before{content:"\F139"}.fa-chevron-circle-down:before{content:"\F13A"}.fa-html5:before{content:"\F13B"}.fa-css3:before{content:"\F13C"}.fa-anchor:before{content:"\F13D"}.fa-unlock-alt:before{content:"\F13E"}.fa-bullseye:before{content:"\F140"}.fa-ellipsis-h:before{content:"\F141"}.fa-ellipsis-v:before{content:"\F142"}.fa-rss-square:before{content:"\F143"}.fa-play-circle:before{content:"\F144"}.fa-ticket:before{content:"\F145"}.fa-minus-square:before{content:"\F146"}.fa-minus-square-o:before{content:"\F147"}.fa-level-up:before{content:"\F148"}.fa-level-down:before{content:"\F149"}.fa-check-square:before{content:"\F14A"}.fa-pencil-square:before{content:"\F14B"}.fa-external-link-square:before{content:"\F14C"}.fa-share-square:before{content:"\F14D"}.fa-compass:before{content:"\F14E"}.fa-caret-square-o-down:before,.fa-toggle-down:before{content:"\F150"}.fa-caret-square-o-up:before,.fa-toggle-up:before{content:"\F151"}.fa-caret-square-o-right:before,.fa-toggle-right:before{content:"\F152"}.fa-eur:before,.fa-euro:before{content:"\F153"}.fa-gbp:before{content:"\F154"}.fa-dollar:before,.fa-usd:before{content:"\F155"}.fa-inr:before,.fa-rupee:before{content:"\F156"}.fa-cny:before,.fa-jpy:before,.fa-rmb:before,.fa-yen:before{content:"\F157"}.fa-rouble:before,.fa-rub:before,.fa-ruble:before{content:"\F158"}.fa-krw:before,.fa-won:before{content:"\F159"}.fa-bitcoin:before,.fa-btc:before{content:"\F15A"}.fa-file:before{content:"\F15B"}.fa-file-text:before{content:"\F15C"}.fa-sort-alpha-asc:before{content:"\F15D"}.fa-sort-alpha-desc:before{content:"\F15E"}.fa-sort-amount-asc:before{content:"\F160"}.fa-sort-amount-desc:before{content:"\F161"}.fa-sort-numeric-asc:before{content:"\F162"}.fa-sort-numeric-desc:before{content:"\F163"}.fa-thumbs-up:before{content:"\F164"}.fa-thumbs-down:before{content:"\F165"}.fa-youtube-square:before{content:"\F166"}.fa-youtube:before{content:"\F167"}.fa-xing:before{content:"\F168"}.fa-xing-square:before{content:"\F169"}.fa-youtube-play:before{content:"\F16A"}.fa-dropbox:before{content:"\F16B"}.fa-stack-overflow:before{content:"\F16C"}.fa-instagram:before{content:"\F16D"}.fa-flickr:before{content:"\F16E"}.fa-adn:before{content:"\F170"}.fa-bitbucket:before{content:"\F171"}.fa-bitbucket-square:before{content:"\F172"}.fa-tumblr:before{content:"\F173"}.fa-tumblr-square:before{content:"\F174"}.fa-long-arrow-down:before{content:"\F175"}.fa-long-arrow-up:before{content:"\F176"}.fa-long-arrow-left:before{content:"\F177"}.fa-long-arrow-right:before{content:"\F178"}.fa-apple:before{content:"\F179"}.fa-windows:before{content:"\F17A"}.fa-android:before{content:"\F17B"}.fa-linux:before{content:"\F17C"}.fa-dribbble:before{content:"\F17D"}.fa-skype:before{content:"\F17E"}.fa-foursquare:before{content:"\F180"}.fa-trello:before{content:"\F181"}.fa-female:before{content:"\F182"}.fa-male:before{content:"\F183"}.fa-gittip:before,.fa-gratipay:before{content:"\F184"}.fa-sun-o:before{content:"\F185"}.fa-moon-o:before{content:"\F186"}.fa-archive:before{content:"\F187"}.fa-bug:before{content:"\F188"}.fa-vk:before{content:"\F189"}.fa-weibo:before{content:"\F18A"}.fa-renren:before{content:"\F18B"}.fa-pagelines:before{content:"\F18C"}.fa-stack-exchange:before{content:"\F18D"}.fa-arrow-circle-o-right:before{content:"\F18E"}.fa-arrow-circle-o-left:before{content:"\F190"}.fa-caret-square-o-left:before,.fa-toggle-left:before{content:"\F191"}.fa-dot-circle-o:before{content:"\F192"}.fa-wheelchair:before{content:"\F193"}.fa-vimeo-square:before{content:"\F194"}.fa-try:before,.fa-turkish-lira:before{content:"\F195"}.fa-plus-square-o:before{content:"\F196"}.fa-space-shuttle:before{content:"\F197"}.fa-slack:before{content:"\F198"}.fa-envelope-square:before{content:"\F199"}.fa-wordpress:before{content:"\F19A"}.fa-openid:before{content:"\F19B"}.fa-bank:before,.fa-institution:before,.fa-university:before{content:"\F19C"}.fa-graduation-cap:before,.fa-mortar-board:before{content:"\F19D"}.fa-yahoo:before{content:"\F19E"}.fa-google:before{content:"\F1A0"}.fa-reddit:before{content:"\F1A1"}.fa-reddit-square:before{content:"\F1A2"}.fa-stumbleupon-circle:before{content:"\F1A3"}.fa-stumbleupon:before{content:"\F1A4"}.fa-delicious:before{content:"\F1A5"}.fa-digg:before{content:"\F1A6"}.fa-pied-piper-pp:before{content:"\F1A7"}.fa-pied-piper-alt:before{content:"\F1A8"}.fa-drupal:before{content:"\F1A9"}.fa-joomla:before{content:"\F1AA"}.fa-language:before{content:"\F1AB"}.fa-fax:before{content:"\F1AC"}.fa-building:before{content:"\F1AD"}.fa-child:before{content:"\F1AE"}.fa-paw:before{content:"\F1B0"}.fa-spoon:before{content:"\F1B1"}.fa-cube:before{content:"\F1B2"}.fa-cubes:before{content:"\F1B3"}.fa-behance:before{content:"\F1B4"}.fa-behance-square:before{content:"\F1B5"}.fa-steam:before{content:"\F1B6"}.fa-steam-square:before{content:"\F1B7"}.fa-recycle:before{content:"\F1B8"}.fa-automobile:before,.fa-car:before{content:"\F1B9"}.fa-cab:before,.fa-taxi:before{content:"\F1BA"}.fa-tree:before{content:"\F1BB"}.fa-spotify:before{content:"\F1BC"}.fa-deviantart:before{content:"\F1BD"}.fa-soundcloud:before{content:"\F1BE"}.fa-database:before{content:"\F1C0"}.fa-file-pdf-o:before{content:"\F1C1"}.fa-file-word-o:before{content:"\F1C2"}.fa-file-excel-o:before{content:"\F1C3"}.fa-file-powerpoint-o:before{content:"\F1C4"}.fa-file-image-o:before,.fa-file-photo-o:before,.fa-file-picture-o:before{content:"\F1C5"}.fa-file-archive-o:before,.fa-file-zip-o:before{content:"\F1C6"}.fa-file-audio-o:before,.fa-file-sound-o:before{content:"\F1C7"}.fa-file-movie-o:before,.fa-file-video-o:before{content:"\F1C8"}.fa-file-code-o:before{content:"\F1C9"}.fa-vine:before{content:"\F1CA"}.fa-codepen:before{content:"\F1CB"}.fa-jsfiddle:before{content:"\F1CC"}.fa-life-bouy:before,.fa-life-buoy:before,.fa-life-ring:before,.fa-life-saver:before,.fa-support:before{content:"\F1CD"}.fa-circle-o-notch:before{content:"\F1CE"}.fa-ra:before,.fa-rebel:before,.fa-resistance:before{content:"\F1D0"}.fa-empire:before,.fa-ge:before{content:"\F1D1"}.fa-git-square:before{content:"\F1D2"}.fa-git:before{content:"\F1D3"}.fa-hacker-news:before,.fa-y-combinator-square:before,.fa-yc-square:before{content:"\F1D4"}.fa-tencent-weibo:before{content:"\F1D5"}.fa-qq:before{content:"\F1D6"}.fa-wechat:before,.fa-weixin:before{content:"\F1D7"}.fa-paper-plane:before,.fa-send:before{content:"\F1D8"}.fa-paper-plane-o:before,.fa-send-o:before{content:"\F1D9"}.fa-history:before{content:"\F1DA"}.fa-circle-thin:before{content:"\F1DB"}.fa-header:before{content:"\F1DC"}.fa-paragraph:before{content:"\F1DD"}.fa-sliders:before{content:"\F1DE"}.fa-share-alt:before{content:"\F1E0"}.fa-share-alt-square:before{content:"\F1E1"}.fa-bomb:before{content:"\F1E2"}.fa-futbol-o:before,.fa-soccer-ball-o:before{content:"\F1E3"}.fa-tty:before{content:"\F1E4"}.fa-binoculars:before{content:"\F1E5"}.fa-plug:before{content:"\F1E6"}.fa-slideshare:before{content:"\F1E7"}.fa-twitch:before{content:"\F1E8"}.fa-yelp:before{content:"\F1E9"}.fa-newspaper-o:before{content:"\F1EA"}.fa-wifi:before{content:"\F1EB"}.fa-calculator:before{content:"\F1EC"}.fa-paypal:before{content:"\F1ED"}.fa-google-wallet:before{content:"\F1EE"}.fa-cc-visa:before{content:"\F1F0"}.fa-cc-mastercard:before{content:"\F1F1"}.fa-cc-discover:before{content:"\F1F2"}.fa-cc-amex:before{content:"\F1F3"}.fa-cc-paypal:before{content:"\F1F4"}.fa-cc-stripe:before{content:"\F1F5"}.fa-bell-slash:before{content:"\F1F6"}.fa-bell-slash-o:before{content:"\F1F7"}.fa-trash:before{content:"\F1F8"}.fa-copyright:before{content:"\F1F9"}.fa-at:before{content:"\F1FA"}.fa-eyedropper:before{content:"\F1FB"}.fa-paint-brush:before{content:"\F1FC"}.fa-birthday-cake:before{content:"\F1FD"}.fa-area-chart:before{content:"\F1FE"}.fa-pie-chart:before{content:"\F200"}.fa-line-chart:before{content:"\F201"}.fa-lastfm:before{content:"\F202"}.fa-lastfm-square:before{content:"\F203"}.fa-toggle-off:before{content:"\F204"}.fa-toggle-on:before{content:"\F205"}.fa-bicycle:before{content:"\F206"}.fa-bus:before{content:"\F207"}.fa-ioxhost:before{content:"\F208"}.fa-angellist:before{content:"\F209"}.fa-cc:before{content:"\F20A"}.fa-ils:before,.fa-shekel:before,.fa-sheqel:before{content:"\F20B"}.fa-meanpath:before{content:"\F20C"}.fa-buysellads:before{content:"\F20D"}.fa-connectdevelop:before{content:"\F20E"}.fa-dashcube:before{content:"\F210"}.fa-forumbee:before{content:"\F211"}.fa-leanpub:before{content:"\F212"}.fa-sellsy:before{content:"\F213"}.fa-shirtsinbulk:before{content:"\F214"}.fa-simplybuilt:before{content:"\F215"}.fa-skyatlas:before{content:"\F216"}.fa-cart-plus:before{content:"\F217"}.fa-cart-arrow-down:before{content:"\F218"}.fa-diamond:before{content:"\F219"}.fa-ship:before{content:"\F21A"}.fa-user-secret:before{content:"\F21B"}.fa-motorcycle:before{content:"\F21C"}.fa-street-view:before{content:"\F21D"}.fa-heartbeat:before{content:"\F21E"}.fa-venus:before{content:"\F221"}.fa-mars:before{content:"\F222"}.fa-mercury:before{content:"\F223"}.fa-intersex:before,.fa-transgender:before{content:"\F224"}.fa-transgender-alt:before{content:"\F225"}.fa-venus-double:before{content:"\F226"}.fa-mars-double:before{content:"\F227"}.fa-venus-mars:before{content:"\F228"}.fa-mars-stroke:before{content:"\F229"}.fa-mars-stroke-v:before{content:"\F22A"}.fa-mars-stroke-h:before{content:"\F22B"}.fa-neuter:before{content:"\F22C"}.fa-genderless:before{content:"\F22D"}.fa-facebook-official:before{content:"\F230"}.fa-pinterest-p:before{content:"\F231"}.fa-whatsapp:before{content:"\F232"}.fa-server:before{content:"\F233"}.fa-user-plus:before{content:"\F234"}.fa-user-times:before{content:"\F235"}.fa-bed:before,.fa-hotel:before{content:"\F236"}.fa-viacoin:before{content:"\F237"}.fa-train:before{content:"\F238"}.fa-subway:before{content:"\F239"}.fa-medium:before{content:"\F23A"}.fa-y-combinator:before,.fa-yc:before{content:"\F23B"}.fa-optin-monster:before{content:"\F23C"}.fa-opencart:before{content:"\F23D"}.fa-expeditedssl:before{content:"\F23E"}.fa-battery-4:before,.fa-battery-full:before,.fa-battery:before{content:"\F240"}.fa-battery-3:before,.fa-battery-three-quarters:before{content:"\F241"}.fa-battery-2:before,.fa-battery-half:before{content:"\F242"}.fa-battery-1:before,.fa-battery-quarter:before{content:"\F243"}.fa-battery-0:before,.fa-battery-empty:before{content:"\F244"}.fa-mouse-pointer:before{content:"\F245"}.fa-i-cursor:before{content:"\F246"}.fa-object-group:before{content:"\F247"}.fa-object-ungroup:before{content:"\F248"}.fa-sticky-note:before{content:"\F249"}.fa-sticky-note-o:before{content:"\F24A"}.fa-cc-jcb:before{content:"\F24B"}.fa-cc-diners-club:before{content:"\F24C"}.fa-clone:before{content:"\F24D"}.fa-balance-scale:before{content:"\F24E"}.fa-hourglass-o:before{content:"\F250"}.fa-hourglass-1:before,.fa-hourglass-start:before{content:"\F251"}.fa-hourglass-2:before,.fa-hourglass-half:before{content:"\F252"}.fa-hourglass-3:before,.fa-hourglass-end:before{content:"\F253"}.fa-hourglass:before{content:"\F254"}.fa-hand-grab-o:before,.fa-hand-rock-o:before{content:"\F255"}.fa-hand-paper-o:before,.fa-hand-stop-o:before{content:"\F256"}.fa-hand-scissors-o:before{content:"\F257"}.fa-hand-lizard-o:before{content:"\F258"}.fa-hand-spock-o:before{content:"\F259"}.fa-hand-pointer-o:before{content:"\F25A"}.fa-hand-peace-o:before{content:"\F25B"}.fa-trademark:before{content:"\F25C"}.fa-registered:before{content:"\F25D"}.fa-creative-commons:before{content:"\F25E"}.fa-gg:before{content:"\F260"}.fa-gg-circle:before{content:"\F261"}.fa-tripadvisor:before{content:"\F262"}.fa-odnoklassniki:before{content:"\F263"}.fa-odnoklassniki-square:before{content:"\F264"}.fa-get-pocket:before{content:"\F265"}.fa-wikipedia-w:before{content:"\F266"}.fa-safari:before{content:"\F267"}.fa-chrome:before{content:"\F268"}.fa-firefox:before{content:"\F269"}.fa-opera:before{content:"\F26A"}.fa-internet-explorer:before{content:"\F26B"}.fa-television:before,.fa-tv:before{content:"\F26C"}.fa-contao:before{content:"\F26D"}.fa-500px:before{content:"\F26E"}.fa-amazon:before{content:"\F270"}.fa-calendar-plus-o:before{content:"\F271"}.fa-calendar-minus-o:before{content:"\F272"}.fa-calendar-times-o:before{content:"\F273"}.fa-calendar-check-o:before{content:"\F274"}.fa-industry:before{content:"\F275"}.fa-map-pin:before{content:"\F276"}.fa-map-signs:before{content:"\F277"}.fa-map-o:before{content:"\F278"}.fa-map:before{content:"\F279"}.fa-commenting:before{content:"\F27A"}.fa-commenting-o:before{content:"\F27B"}.fa-houzz:before{content:"\F27C"}.fa-vimeo:before{content:"\F27D"}.fa-black-tie:before{content:"\F27E"}.fa-fonticons:before{content:"\F280"}.fa-reddit-alien:before{content:"\F281"}.fa-edge:before{content:"\F282"}.fa-credit-card-alt:before{content:"\F283"}.fa-codiepie:before{content:"\F284"}.fa-modx:before{content:"\F285"}.fa-fort-awesome:before{content:"\F286"}.fa-usb:before{content:"\F287"}.fa-product-hunt:before{content:"\F288"}.fa-mixcloud:before{content:"\F289"}.fa-scribd:before{content:"\F28A"}.fa-pause-circle:before{content:"\F28B"}.fa-pause-circle-o:before{content:"\F28C"}.fa-stop-circle:before{content:"\F28D"}.fa-stop-circle-o:before{content:"\F28E"}.fa-shopping-bag:before{content:"\F290"}.fa-shopping-basket:before{content:"\F291"}.fa-hashtag:before{content:"\F292"}.fa-bluetooth:before{content:"\F293"}.fa-bluetooth-b:before{content:"\F294"}.fa-percent:before{content:"\F295"}.fa-gitlab:before{content:"\F296"}.fa-wpbeginner:before{content:"\F297"}.fa-wpforms:before{content:"\F298"}.fa-envira:before{content:"\F299"}.fa-universal-access:before{content:"\F29A"}.fa-wheelchair-alt:before{content:"\F29B"}.fa-question-circle-o:before{content:"\F29C"}.fa-blind:before{content:"\F29D"}.fa-audio-description:before{content:"\F29E"}.fa-volume-control-phone:before{content:"\F2A0"}.fa-braille:before{content:"\F2A1"}.fa-assistive-listening-systems:before{content:"\F2A2"}.fa-american-sign-language-interpreting:before,.fa-asl-interpreting:before{content:"\F2A3"}.fa-deaf:before,.fa-deafness:before,.fa-hard-of-hearing:before{content:"\F2A4"}.fa-glide:before{content:"\F2A5"}.fa-glide-g:before{content:"\F2A6"}.fa-sign-language:before,.fa-signing:before{content:"\F2A7"}.fa-low-vision:before{content:"\F2A8"}.fa-viadeo:before{content:"\F2A9"}.fa-viadeo-square:before{content:"\F2AA"}.fa-snapchat:before{content:"\F2AB"}.fa-snapchat-ghost:before{content:"\F2AC"}.fa-snapchat-square:before{content:"\F2AD"}.fa-pied-piper:before{content:"\F2AE"}.fa-first-order:before{content:"\F2B0"}.fa-yoast:before{content:"\F2B1"}.fa-themeisle:before{content:"\F2B2"}.fa-google-plus-circle:before,.fa-google-plus-official:before{content:"\F2B3"}.fa-fa:before,.fa-font-awesome:before{content:"\F2B4"}.fa-handshake-o:before{content:"\F2B5"}.fa-envelope-open:before{content:"\F2B6"}.fa-envelope-open-o:before{content:"\F2B7"}.fa-linode:before{content:"\F2B8"}.fa-address-book:before{content:"\F2B9"}.fa-address-book-o:before{content:"\F2BA"}.fa-address-card:before,.fa-vcard:before{content:"\F2BB"}.fa-address-card-o:before,.fa-vcard-o:before{content:"\F2BC"}.fa-user-circle:before{content:"\F2BD"}.fa-user-circle-o:before{content:"\F2BE"}.fa-user-o:before{content:"\F2C0"}.fa-id-badge:before{content:"\F2C1"}.fa-drivers-license:before,.fa-id-card:before{content:"\F2C2"}.fa-drivers-license-o:before,.fa-id-card-o:before{content:"\F2C3"}.fa-quora:before{content:"\F2C4"}.fa-free-code-camp:before{content:"\F2C5"}.fa-telegram:before{content:"\F2C6"}.fa-thermometer-4:before,.fa-thermometer-full:before,.fa-thermometer:before{content:"\F2C7"}.fa-thermometer-3:before,.fa-thermometer-three-quarters:before{content:"\F2C8"}.fa-thermometer-2:before,.fa-thermometer-half:before{content:"\F2C9"}.fa-thermometer-1:before,.fa-thermometer-quarter:before{content:"\F2CA"}.fa-thermometer-0:before,.fa-thermometer-empty:before{content:"\F2CB"}.fa-shower:before{content:"\F2CC"}.fa-bath:before,.fa-bathtub:before,.fa-s15:before{content:"\F2CD"}.fa-podcast:before{content:"\F2CE"}.fa-window-maximize:before{content:"\F2D0"}.fa-window-minimize:before{content:"\F2D1"}.fa-window-restore:before{content:"\F2D2"}.fa-times-rectangle:before,.fa-window-close:before{content:"\F2D3"}.fa-times-rectangle-o:before,.fa-window-close-o:before{content:"\F2D4"}.fa-bandcamp:before{content:"\F2D5"}.fa-grav:before{content:"\F2D6"}.fa-etsy:before{content:"\F2D7"}.fa-imdb:before{content:"\F2D8"}.fa-ravelry:before{content:"\F2D9"}.fa-eercast:before{content:"\F2DA"}.fa-microchip:before{content:"\F2DB"}.fa-snowflake-o:before{content:"\F2DC"}.fa-superpowers:before{content:"\F2DD"}.fa-wpexplorer:before{content:"\F2DE"}.fa-meetup:before{content:"\F2E0"}.sr-only{position:absolute;width:1px;height:1px;padding:0;margin:-1px;overflow:hidden;clip:rect(0,0,0,0);border:0}.sr-only-focusable:active,.sr-only-focusable:focus{position:static;width:auto;height:auto;margin:0;overflow:visible;clip:auto}.toolbar-actions{height:100%;display:flex;flex:1 1 auto;justify-content:flex-end;align-items:center}@media (max-width:639px){.toolbar-actions .userlinks-container{display:none}}.darker-background,.main-container{background-color:#e0e0e0}a:link{color:#c62828;text-decoration:none}.footer{justify-content:center;align-content:center;background-color:#bdbdbd;padding:10px 5px 5px}.footer .notice-container{display:flex;align-content:center;align-items:center;margin-top:25px}.footer .notice-container .copyright{display:flex;flex:1;justify-content:flex-start}@media (max-width:639px){.footer .notice-container .copyright{justify-content:center}}.footer .notice-container .rss{display:flex;flex:1;justify-content:center}@media (max-width:639px){.footer .notice-container .rss{display:none}}.footer .notice-container .based-on{display:flex;flex:1;justify-content:flex-end}@media (max-width:639px){.footer .notice-container .based-on{display:none}}.footer .notice-container h4{color:#c62828;text-align:center;margin:0}.footer-fixed{position:fixed;left:0;bottom:0;right:0;z-index:15}.main-content{display:flex;flex-direction:column}.main-content .main-container{display:flex;min-height:100%;flex-direction:column;flex:1}.main-content .main-container .main-content{flex:1}*{box-sizing:border-box}html{height:100%}body{margin:0}.md-display-4{letter-spacing:-.1px}.md-display-3{letter-spacing:-.05px}.md-display-1,.md-display-2,.md-headline,h1,h2{letter-spacing:0}.md-title,h3{letter-spacing:.5px}.md-body-1,.md-body-2,.md-subheading-1,.md-subheading-2,h4,h5,h6,p{letter-spacing:.1px}.md-caption,caption{letter-spacing:.2px}.md-body-1,.md-body-2,.md-caption,.md-display-1,.md-display-2,.md-display-3,.md-display-4,.md-headline,.md-subheading-1,.md-subheading-2,.md-title,caption,h1,h2,h3,h4,h5,h6,p{margin:0}.md-display-1,.md-display-2,.md-display-3,.md-display-4,.md-headline,.md-title,h1,h2,h3{margin-bottom:14px}.md-body-1,.md-body-2,.md-caption,.md-subheading-1,.md-subheading-2,caption,h4,h5,h6,p{margin-bottom:10px}.md-display-3,.md-display-4,.md-title,h3{white-space:nowrap}.md-body-1,.md-caption,.md-display-1,.md-display-2,.md-display-3,.md-headline,.md-subheading-1,.md-subheading-2,caption,h1,h2,h4,h5,p{font-weight:400}.md-body-2,.md-title,h3,h6{font-weight:500}.md-display-4{font-size:112px;font-weight:300;line-height:128px}.md-display-3{font-size:56px;line-height:84px}.md-display-2{font-size:45px;line-height:48px}.md-display-1,h1{font-size:34px;line-height:40px}.md-headline,h2{font-size:24px;line-height:32px}.md-title,h3{font-size:20px}.md-subheading-2,.md-title,h3,h4{line-height:28px}.md-subheading-1,h5{line-height:24px}.md-body-1,.md-body-2,h6,p{line-height:1.42857}.md-caption,caption{font-size:12px}.md-picker-control,.md-text-left{text-align:left}.md-calendar-date,.md-text-center{text-align:center}.md-text-right{text-align:right}.md-text-justify{text-align:justify}.md-text-capitalize{text-transform:capitalize}.md-text-lowercalse{text-transform:lowercase}.md-text-uppercase{text-transform:uppercase}.md-text-nowrap{white-space:nowrap}.md-text-no-select{user-select:none}.md-font-light{font-weight:300}.md-font-regular{font-weight:400}.md-btn .md-icon-text,.md-clock-time-value,.md-font-medium{font-weight:500}.md-font-semibold{font-weight:600}.md-font-bold{font-weight:700}.md-transition--sharp{transition-timing-function:cubix-bezier(.4,0,.6,1)}.md-transition--standard{transition-timing-function:cubic-bezier(.4,0,.2,1)}.md-drop-down-leave.md-drop-down-leave-active,.md-transition--acceleration{transition-timing-function:cubic-bezier(.4,0,1,1)}.md-drop-down-enter.md-drop-down-enter-active,.md-transition--decceleration,.md-transition--deceleration{transition-timing-function:cubic-bezier(0,0,.2,1)}.md-calendar-date,.md-inline-block{display:inline-block;vertical-align:bottom}.md-full-width{width:100%}.md-block-centered,.md-bottom-nav .md-icon,.md-text-container{display:block;margin-left:auto;margin-right:auto}.md-cell--right,.md-collapser--card,.md-divider--expand-from-right:after,.md-grid.md-grid--no-spacing>.md-cell.md-cell--right{margin-left:auto}.md-expansion-panel-list,.md-list,.md-list-unstyled,.md-tabs{list-style:none;margin:0;padding-left:0}.md-media embed,.md-media iframe,.md-media img,.md-media object,.md-media svg,.md-media video{bottom:0;height:100%;left:0;position:absolute;right:0;top:0;width:100%}.darker-background,.main-container{background-color:#e0e0e0}a:link{color:#c62828;text-decoration:none}@media screen and (min-width:320px){.md-subheading-1,.md-subheading-2{font-size:16px}.md-body-1,.md-body-2{font-size:14px}h4,h5{font-size:16px}h6,p{font-size:14px}}@media screen and (min-width:1025px){.md-subheading-1,.md-subheading-2{font-size:15px}.md-body-1,.md-body-2{font-size:13px}h4,h5{font-size:15px}h6,p{font-size:13px}}*,:after,:before{box-sizing:border-box;-webkit-tap-highlight-color:transparent;transition-timing-function:cubic-bezier(.4,0,.2,1)}html{background:#fafafa;font-size:14px;min-width:100%}body{font-family:Roboto,sans-serif;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;font-weight:400;line-height:1.42857;text-rendering:optimizeLegibility}.md-body-1,.md-body-2,.md-headline,.md-subheading-1,.md-subheading-2,.md-title,h2,h3,h4,h5,h6,p{color:rgba(0,0,0,.87)}.md-caption,.md-display-1,.md-display-2,.md-display-3,.md-display-4,caption,h1{color:rgba(0,0,0,.54)}button,h1,h2,h3,h4,h5,h6,html,input,p,textarea{font-family:Roboto,sans-serif}.md-text-container{max-width:640px;width:100%}.md-text-container.md-text-container.md-cell{margin-left:auto;margin-right:auto}.md-fake-btn{background:transparent;position:relative}.md-fake-btn--no-outline{outline-style:none}.md-no-scroll.md-no-scroll{overflow:hidden;position:fixed}.md-pointer--hover:hover{cursor:pointer}.md-pointer--none{pointer-events:none}.md-content-jump{left:-1000px;position:absolute;top:-1000px}.md-content-jump:active,.md-content-jump:focus{left:0;top:0}.md-grid{align-items:stretch;display:flex;flex-flow:row wrap;margin:0 auto}.md-grid.md-grid--no-spacing{padding:0}.md-grid.md-grid--no-spacing>.md-cell{margin:0}.md-grid--stacked{flex-direction:column}.md-cell--top{align-self:flex-start}.md-cell--middle{align-self:center}.md-cell--center{margin-left:auto;margin-right:auto}.md-cell--bottom{align-self:flex-end}.md-cell--stretch{align-self:stretch}@media (max-width:599px){.md-grid{padding:8px}.md-cell{width:calc(100% - 16px);margin:8px}.md-grid.md-grid--no-spacing>.md-cell{width:100%}.md-cell--phone-hidden{display:none!important}.md-cell--order-1,.md-cell--order-1-phone.md-cell--order-1-phone{order:1}.md-cell--order-2,.md-cell--order-2-phone.md-cell--order-2-phone{order:2}.md-cell--order-3,.md-cell--order-3-phone.md-cell--order-3-phone{order:3}.md-cell--order-4,.md-cell--order-4-phone.md-cell--order-4-phone{order:4}.md-cell--order-5,.md-cell--order-5-phone.md-cell--order-5-phone{order:5}.md-cell--order-6,.md-cell--order-6-phone.md-cell--order-6-phone{order:6}.md-cell--order-7,.md-cell--order-7-phone.md-cell--order-7-phone{order:7}.md-cell--order-8,.md-cell--order-8-phone.md-cell--order-8-phone{order:8}.md-cell--order-9,.md-cell--order-9-phone.md-cell--order-9-phone{order:9}.md-cell--order-10,.md-cell--order-10-phone.md-cell--order-10-phone{order:10}.md-cell--order-11,.md-cell--order-11-phone.md-cell--order-11-phone{order:11}.md-cell--order-12,.md-cell--order-12-phone.md-cell--order-12-phone{order:12}.md-cell--1,.md-cell--1-phone.md-cell--1-phone{width:calc(25% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--1,.md-grid.md-grid--no-spacing>.md-cell--1-phone.md-cell--1-phone{width:25%}.md-cell--2,.md-cell--2-phone.md-cell--2-phone{width:calc(50% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--2,.md-grid.md-grid--no-spacing>.md-cell--2-phone.md-cell--2-phone{width:50%}.md-cell--3,.md-cell--3-phone.md-cell--3-phone{width:calc(75% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--3,.md-grid.md-grid--no-spacing>.md-cell--3-phone.md-cell--3-phone{width:75%}.md-cell--4,.md-cell--4-phone.md-cell--4-phone{width:calc(100% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--4,.md-grid.md-grid--no-spacing>.md-cell--4-phone.md-cell--4-phone{width:100%}.md-cell--5,.md-cell--5-phone.md-cell--5-phone{width:calc(100% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--5,.md-grid.md-grid--no-spacing>.md-cell--5-phone.md-cell--5-phone{width:100%}.md-cell--6,.md-cell--6-phone.md-cell--6-phone{width:calc(100% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--6,.md-grid.md-grid--no-spacing>.md-cell--6-phone.md-cell--6-phone{width:100%}.md-cell--7,.md-cell--7-phone.md-cell--7-phone{width:calc(100% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--7,.md-grid.md-grid--no-spacing>.md-cell--7-phone.md-cell--7-phone{width:100%}.md-cell--8,.md-cell--8-phone.md-cell--8-phone{width:calc(100% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--8,.md-grid.md-grid--no-spacing>.md-cell--8-phone.md-cell--8-phone{width:100%}.md-cell--9,.md-cell--9-phone.md-cell--9-phone{width:calc(100% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--9,.md-grid.md-grid--no-spacing>.md-cell--9-phone.md-cell--9-phone{width:100%}.md-cell--10,.md-cell--10-phone.md-cell--10-phone{width:calc(100% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--10,.md-grid.md-grid--no-spacing>.md-cell--10-phone.md-cell--10-phone{width:100%}.md-cell--11,.md-cell--11-phone.md-cell--11-phone{width:calc(100% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--11,.md-grid.md-grid--no-spacing>.md-cell--11-phone.md-cell--11-phone{width:100%}.md-cell--12,.md-cell--12-phone.md-cell--12-phone{width:calc(100% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--12,.md-grid.md-grid--no-spacing>.md-cell--12-phone.md-cell--12-phone{width:100%}.md-cell--1-offset,.md-cell--1-phone-offset.md-cell--1-phone-offset{margin-left:calc(25% + 8px)}.md-grid--no-spacing>.md-cell--1-offset,.md-grid--no-spacing>.md-cell--1-phone-offset.md-cell--1-phone-offset{margin-left:25%}.md-cell--2-offset,.md-cell--2-phone-offset.md-cell--2-phone-offset{margin-left:calc(50% + 8px)}.md-grid--no-spacing>.md-cell--2-offset,.md-grid--no-spacing>.md-cell--2-phone-offset.md-cell--2-phone-offset{margin-left:50%}.md-cell--3-offset,.md-cell--3-phone-offset.md-cell--3-phone-offset{margin-left:calc(75% + 8px)}.md-grid--no-spacing>.md-cell--3-offset,.md-grid--no-spacing>.md-cell--3-phone-offset.md-cell--3-phone-offset{margin-left:75%}}@media (min-width:600px) and (max-width:839px){.md-grid{padding:8px}.md-cell{width:calc(50% - 16px);margin:8px}.md-grid.md-grid--no-spacing>.md-cell{width:50%}.md-cell--tablet-hidden{display:none!important}.md-cell--order-1,.md-cell--order-1-tablet.md-cell--order-1-tablet{order:1}.md-cell--order-2,.md-cell--order-2-tablet.md-cell--order-2-tablet{order:2}.md-cell--order-3,.md-cell--order-3-tablet.md-cell--order-3-tablet{order:3}.md-cell--order-4,.md-cell--order-4-tablet.md-cell--order-4-tablet{order:4}.md-cell--order-5,.md-cell--order-5-tablet.md-cell--order-5-tablet{order:5}.md-cell--order-6,.md-cell--order-6-tablet.md-cell--order-6-tablet{order:6}.md-cell--order-7,.md-cell--order-7-tablet.md-cell--order-7-tablet{order:7}.md-cell--order-8,.md-cell--order-8-tablet.md-cell--order-8-tablet{order:8}.md-cell--order-9,.md-cell--order-9-tablet.md-cell--order-9-tablet{order:9}.md-cell--order-10,.md-cell--order-10-tablet.md-cell--order-10-tablet{order:10}.md-cell--order-11,.md-cell--order-11-tablet.md-cell--order-11-tablet{order:11}.md-cell--order-12,.md-cell--order-12-tablet.md-cell--order-12-tablet{order:12}.md-cell--1,.md-cell--1-tablet.md-cell--1-tablet{width:calc(12.5% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--1,.md-grid.md-grid--no-spacing>.md-cell--1-tablet.md-cell--1-tablet{width:12.5%}.md-cell--2,.md-cell--2-tablet.md-cell--2-tablet{width:calc(25% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--2,.md-grid.md-grid--no-spacing>.md-cell--2-tablet.md-cell--2-tablet{width:25%}.md-cell--3,.md-cell--3-tablet.md-cell--3-tablet{width:calc(37.5% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--3,.md-grid.md-grid--no-spacing>.md-cell--3-tablet.md-cell--3-tablet{width:37.5%}.md-cell--4,.md-cell--4-tablet.md-cell--4-tablet{width:calc(50% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--4,.md-grid.md-grid--no-spacing>.md-cell--4-tablet.md-cell--4-tablet{width:50%}.md-cell--5,.md-cell--5-tablet.md-cell--5-tablet{width:calc(62.5% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--5,.md-grid.md-grid--no-spacing>.md-cell--5-tablet.md-cell--5-tablet{width:62.5%}.md-cell--6,.md-cell--6-tablet.md-cell--6-tablet{width:calc(75% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--6,.md-grid.md-grid--no-spacing>.md-cell--6-tablet.md-cell--6-tablet{width:75%}.md-cell--7,.md-cell--7-tablet.md-cell--7-tablet{width:calc(87.5% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--7,.md-grid.md-grid--no-spacing>.md-cell--7-tablet.md-cell--7-tablet{width:87.5%}.md-cell--8,.md-cell--8-tablet.md-cell--8-tablet{width:calc(100% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--8,.md-grid.md-grid--no-spacing>.md-cell--8-tablet.md-cell--8-tablet{width:100%}.md-cell--9,.md-cell--9-tablet.md-cell--9-tablet{width:calc(100% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--9,.md-grid.md-grid--no-spacing>.md-cell--9-tablet.md-cell--9-tablet{width:100%}.md-cell--10,.md-cell--10-tablet.md-cell--10-tablet{width:calc(100% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--10,.md-grid.md-grid--no-spacing>.md-cell--10-tablet.md-cell--10-tablet{width:100%}.md-cell--11,.md-cell--11-tablet.md-cell--11-tablet{width:calc(100% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--11,.md-grid.md-grid--no-spacing>.md-cell--11-tablet.md-cell--11-tablet{width:100%}.md-cell--12,.md-cell--12-tablet.md-cell--12-tablet{width:calc(100% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--12,.md-grid.md-grid--no-spacing>.md-cell--12-tablet.md-cell--12-tablet{width:100%}.md-cell--1-offset,.md-cell--1-tablet-offset.md-cell--1-tablet-offset{margin-left:calc(12.5% + 8px)}.md-grid--no-spacing>.md-cell--1-offset,.md-grid--no-spacing>.md-cell--1-tablet-offset.md-cell--1-tablet-offset{margin-left:12.5%}.md-cell--2-offset,.md-cell--2-tablet-offset.md-cell--2-tablet-offset{margin-left:calc(25% + 8px)}.md-grid--no-spacing>.md-cell--2-offset,.md-grid--no-spacing>.md-cell--2-tablet-offset.md-cell--2-tablet-offset{margin-left:25%}.md-cell--3-offset,.md-cell--3-tablet-offset.md-cell--3-tablet-offset{margin-left:calc(37.5% + 8px)}.md-grid--no-spacing>.md-cell--3-offset,.md-grid--no-spacing>.md-cell--3-tablet-offset.md-cell--3-tablet-offset{margin-left:37.5%}.md-cell--4-offset,.md-cell--4-tablet-offset.md-cell--4-tablet-offset{margin-left:calc(50% + 8px)}.md-grid--no-spacing>.md-cell--4-offset,.md-grid--no-spacing>.md-cell--4-tablet-offset.md-cell--4-tablet-offset{margin-left:50%}.md-cell--5-offset,.md-cell--5-tablet-offset.md-cell--5-tablet-offset{margin-left:calc(62.5% + 8px)}.md-grid--no-spacing>.md-cell--5-offset,.md-grid--no-spacing>.md-cell--5-tablet-offset.md-cell--5-tablet-offset{margin-left:62.5%}.md-cell--6-offset,.md-cell--6-tablet-offset.md-cell--6-tablet-offset{margin-left:calc(75% + 8px)}.md-grid--no-spacing>.md-cell--6-offset,.md-grid--no-spacing>.md-cell--6-tablet-offset.md-cell--6-tablet-offset{margin-left:75%}.md-cell--7-offset,.md-cell--7-tablet-offset.md-cell--7-tablet-offset{margin-left:calc(87.5% + 8px)}.md-grid--no-spacing>.md-cell--7-offset,.md-grid--no-spacing>.md-cell--7-tablet-offset.md-cell--7-tablet-offset{margin-left:87.5%}}@media (min-width:840px){.md-grid{padding:8px}.md-cell{width:calc(33.33333% - 16px);margin:8px}.md-grid.md-grid--no-spacing>.md-cell{width:33.33333%}.md-cell--desktop-hidden{display:none!important}.md-cell--order-1,.md-cell--order-1-desktop.md-cell--order-1-desktop{order:1}.md-cell--order-2,.md-cell--order-2-desktop.md-cell--order-2-desktop{order:2}.md-cell--order-3,.md-cell--order-3-desktop.md-cell--order-3-desktop{order:3}.md-cell--order-4,.md-cell--order-4-desktop.md-cell--order-4-desktop{order:4}.md-cell--order-5,.md-cell--order-5-desktop.md-cell--order-5-desktop{order:5}.md-cell--order-6,.md-cell--order-6-desktop.md-cell--order-6-desktop{order:6}.md-cell--order-7,.md-cell--order-7-desktop.md-cell--order-7-desktop{order:7}.md-cell--order-8,.md-cell--order-8-desktop.md-cell--order-8-desktop{order:8}.md-cell--order-9,.md-cell--order-9-desktop.md-cell--order-9-desktop{order:9}.md-cell--order-10,.md-cell--order-10-desktop.md-cell--order-10-desktop{order:10}.md-cell--order-11,.md-cell--order-11-desktop.md-cell--order-11-desktop{order:11}.md-cell--order-12,.md-cell--order-12-desktop.md-cell--order-12-desktop{order:12}.md-cell--1,.md-cell--1-desktop.md-cell--1-desktop{width:calc(8.33333% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--1,.md-grid.md-grid--no-spacing>.md-cell--1-desktop.md-cell--1-desktop{width:8.33333%}.md-cell--2,.md-cell--2-desktop.md-cell--2-desktop{width:calc(16.66667% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--2,.md-grid.md-grid--no-spacing>.md-cell--2-desktop.md-cell--2-desktop{width:16.66667%}.md-cell--3,.md-cell--3-desktop.md-cell--3-desktop{width:calc(25% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--3,.md-grid.md-grid--no-spacing>.md-cell--3-desktop.md-cell--3-desktop{width:25%}.md-cell--4,.md-cell--4-desktop.md-cell--4-desktop{width:calc(33.33333% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--4,.md-grid.md-grid--no-spacing>.md-cell--4-desktop.md-cell--4-desktop{width:33.33333%}.md-cell--5,.md-cell--5-desktop.md-cell--5-desktop{width:calc(41.66667% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--5,.md-grid.md-grid--no-spacing>.md-cell--5-desktop.md-cell--5-desktop{width:41.66667%}.md-cell--6,.md-cell--6-desktop.md-cell--6-desktop{width:calc(50% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--6,.md-grid.md-grid--no-spacing>.md-cell--6-desktop.md-cell--6-desktop{width:50%}.md-cell--7,.md-cell--7-desktop.md-cell--7-desktop{width:calc(58.33333% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--7,.md-grid.md-grid--no-spacing>.md-cell--7-desktop.md-cell--7-desktop{width:58.33333%}.md-cell--8,.md-cell--8-desktop.md-cell--8-desktop{width:calc(66.66667% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--8,.md-grid.md-grid--no-spacing>.md-cell--8-desktop.md-cell--8-desktop{width:66.66667%}.md-cell--9,.md-cell--9-desktop.md-cell--9-desktop{width:calc(75% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--9,.md-grid.md-grid--no-spacing>.md-cell--9-desktop.md-cell--9-desktop{width:75%}.md-cell--10,.md-cell--10-desktop.md-cell--10-desktop{width:calc(83.33333% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--10,.md-grid.md-grid--no-spacing>.md-cell--10-desktop.md-cell--10-desktop{width:83.33333%}.md-cell--11,.md-cell--11-desktop.md-cell--11-desktop{width:calc(91.66667% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--11,.md-grid.md-grid--no-spacing>.md-cell--11-desktop.md-cell--11-desktop{width:91.66667%}.md-cell--12,.md-cell--12-desktop.md-cell--12-desktop{width:calc(100% - 16px)}.md-grid.md-grid--no-spacing>.md-cell--12,.md-grid.md-grid--no-spacing>.md-cell--12-desktop.md-cell--12-desktop{width:100%}.md-cell--1-desktop-offset.md-cell--1-desktop-offset,.md-cell--1-offset{margin-left:calc(8.33333% + 8px)}.md-grid--no-spacing>.md-cell--1-desktop-offset.md-cell--1-desktop-offset,.md-grid--no-spacing>.md-cell--1-offset{margin-left:8.33333%}.md-cell--2-desktop-offset.md-cell--2-desktop-offset,.md-cell--2-offset{margin-left:calc(16.66667% + 8px)}.md-grid--no-spacing>.md-cell--2-desktop-offset.md-cell--2-desktop-offset,.md-grid--no-spacing>.md-cell--2-offset{margin-left:16.66667%}.md-cell--3-desktop-offset.md-cell--3-desktop-offset,.md-cell--3-offset{margin-left:calc(25% + 8px)}.md-grid--no-spacing>.md-cell--3-desktop-offset.md-cell--3-desktop-offset,.md-grid--no-spacing>.md-cell--3-offset{margin-left:25%}.md-cell--4-desktop-offset.md-cell--4-desktop-offset,.md-cell--4-offset{margin-left:calc(33.33333% + 8px)}.md-grid--no-spacing>.md-cell--4-desktop-offset.md-cell--4-desktop-offset,.md-grid--no-spacing>.md-cell--4-offset{margin-left:33.33333%}.md-cell--5-desktop-offset.md-cell--5-desktop-offset,.md-cell--5-offset{margin-left:calc(41.66667% + 8px)}.md-grid--no-spacing>.md-cell--5-desktop-offset.md-cell--5-desktop-offset,.md-grid--no-spacing>.md-cell--5-offset{margin-left:41.66667%}.md-cell--6-desktop-offset.md-cell--6-desktop-offset,.md-cell--6-offset{margin-left:calc(50% + 8px)}.md-grid--no-spacing>.md-cell--6-desktop-offset.md-cell--6-desktop-offset,.md-grid--no-spacing>.md-cell--6-offset{margin-left:50%}.md-cell--7-desktop-offset.md-cell--7-desktop-offset,.md-cell--7-offset{margin-left:calc(58.33333% + 8px)}.md-grid--no-spacing>.md-cell--7-desktop-offset.md-cell--7-desktop-offset,.md-grid--no-spacing>.md-cell--7-offset{margin-left:58.33333%}.md-cell--8-desktop-offset.md-cell--8-desktop-offset,.md-cell--8-offset{margin-left:calc(66.66667% + 8px)}.md-grid--no-spacing>.md-cell--8-desktop-offset.md-cell--8-desktop-offset,.md-grid--no-spacing>.md-cell--8-offset{margin-left:66.66667%}.md-cell--9-desktop-offset.md-cell--9-desktop-offset,.md-cell--9-offset{margin-left:calc(75% + 8px)}.md-grid--no-spacing>.md-cell--9-desktop-offset.md-cell--9-desktop-offset,.md-grid--no-spacing>.md-cell--9-offset{margin-left:75%}.md-cell--10-desktop-offset.md-cell--10-desktop-offset,.md-cell--10-offset{margin-left:calc(83.33333% + 8px)}.md-grid--no-spacing>.md-cell--10-desktop-offset.md-cell--10-desktop-offset,.md-grid--no-spacing>.md-cell--10-offset{margin-left:83.33333%}.md-cell--11-desktop-offset.md-cell--11-desktop-offset,.md-cell--11-offset{margin-left:calc(91.66667% + 8px)}.md-grid--no-spacing>.md-cell--11-desktop-offset.md-cell--11-desktop-offset,.md-grid--no-spacing>.md-cell--11-offset{margin-left:91.66667%}}.md-autocomplete-container{position:relative}.md-autocomplete-suggestion{color:rgba(0,0,0,.54);line-height:1.15;overflow:hidden;position:absolute;top:12px;white-space:nowrap}@media screen and (min-width:320px){.md-autocomplete-suggestion{font-size:16px}.md-autocomplete-suggestion--floating{top:37px}.md-autocomplete-suggestion--block{top:18px}}@media screen and (min-width:1025px){.md-autocomplete-suggestion{font-size:13px}.md-autocomplete-suggestion--floating{top:33px}.md-autocomplete-suggestion--block{top:15px}}.md-avatar{border:1px solid rgba(0,0,0,.12);border-radius:50%;height:40px;overflow:hidden;text-align:center;width:40px}.md-avatar .md-icon{color:inherit}.md-avatar--icon-sized{height:24px;width:24px}.md-avatar-img{height:100%;width:auto}.md-avatar-content{align-items:center;display:flex;font-size:24px;height:100%;justify-content:center;width:100%}.md-avatar--default{background:#616161;color:#f5f5f5}@media screen and (min-width:1025px){.md-avatar-content{font-size:20px}.md-avatar--icon-sized{height:20px;width:20px}}.md-avatar--red{background:#d50000;color:#ffebee}.md-avatar--pink{background:#d81b60;color:#fff}.md-avatar--purple{background:#7b1fa2;color:#e1bee7}.md-avatar--deep-purple{background:#311b92;color:#d1c4e9}.md-avatar--indigo{background:#3949ab;color:#c5cae9}.md-avatar--blue{background:#2962ff;color:#fff}.md-avatar--light-blue{background:#4fc3f7;color:#311b92}.md-avatar--cyan{background:#26c6da;color:#004d40}.md-avatar--teal{background:#1de9b6;color:#004d40}.md-avatar--green{background:#2e7d32;color:#e8f5e9}.md-avatar--light-green{background:#aed581;color:#1b5e20}.md-avatar--lime{background:#d4e157;color:#00695c}.md-avatar--yellow{background:#ff0;color:#795548}.md-avatar--amber{background:#ffca28;color:#4e342e}.md-avatar--orange{background:#fb8c00;color:#212121}.md-avatar--deep-orange{background:#ff3d00;color:#212121}.md-avatar--brown{background:#795548;color:#efebe9}.md-avatar--grey{background:#616161;color:#f5f5f5}.md-avatar--blue-grey{background:#455a64;color:#eceff1}.md-badge-container{position:relative}.md-badge{position:absolute;right:-8px;top:-8px}.md-badge--circular{align-items:center;border-radius:50%;display:flex;font-size:10px;height:24px;justify-content:center;width:24px}.md-badge--default{background:rgba(0,0,0,.2)}.md-bottom-navigation{bottom:0;display:flex;justify-content:center;left:0;overflow:hidden;position:fixed;width:100%;z-index:11}.md-bottom-navigation--shifting{transition-duration:.3s;transition-property:background}.md-bottom-navigation--dynamic{transform:translateZ(0);transition-duration:.3s;transition-property:background,transform}.md-bottom-navigation--dynamic-inactive{transform:translate3d(0,100%,0)}.md-bottom-navigation-offset{padding-bottom:56px}.md-bottom-nav{color:inherit;display:block;flex-grow:1;font-size:12px;height:56px;max-width:168px;padding:8px 12px 10px;text-align:center;text-decoration:none;user-select:none}.md-bottom-nav--active{flex-shrink:0;font-size:14px;padding-top:6px}.md-bottom-nav--fixed{min-width:80px}.md-bottom-nav--shifting{min-width:96px;position:static;transition-duration:.15s;transition-property:max-width}.md-bottom-nav--shifting-inactive{max-width:96px;min-width:56px;padding-top:16px}.md-bottom-nav--shifting .md-ink-container{overflow:visible}.md-bottom-nav--shifting .md-ink{background:hsla(0,0%,100%,.12)}.md-bottom-nav-label{transition-duration:.15s;transition-property:color,font-size}.md-bottom-nav-label--shifting-inactive{max-width:32px;overflow:hidden;white-space:nowrap}a.md-btn{text-decoration:none}.md-btn{background:transparent;border:0;position:relative;transition-duration:.15s;transition-property:background,color}.md-btn[disabled] *{pointer-events:none}.md-btn--tooltip{overflow:visible}.md-btn:focus{outline-style:none}.md-btn .md-icon-separator{height:100%}.md-btn--hover{background:hsla(0,0%,60%,.12)}.md-btn--color-primary-active{background:hsla(0,0%,74%,.12)}.md-btn--color-secondary-active{background:rgba(198,40,40,.12)}.md-btn--text{border-radius:2px;font-weight:500;min-width:88px;padding:8px 16px;text-transform:uppercase}.md-btn--raised{box-shadow:0 2px 2px 0 rgba(0,0,0,.14),0 1px 5px 0 rgba(0,0,0,.12),0 3px 1px -2px rgba(0,0,0,.2);transition:background .15s,box-shadow .3s,color .15s}.md-btn--raised-disabled{background:rgba(0,0,0,.12)}.md-btn--raised-pressed{box-shadow:0 4px 5px 0 rgba(0,0,0,.14),0 1px 10px 0 rgba(0,0,0,.12),0 2px 4px -1px rgba(0,0,0,.4)}.md-btn--icon{border-radius:50%;color:rgba(0,0,0,.54);height:48px;padding:12px;width:48px}.md-btn--floating{height:56px;padding:16px;transition-property:background,box-shadow,color;width:56px}.md-btn--floating-mini{height:40px;padding:8px;width:40px}.md-btn--fixed{position:fixed;z-index:10}@media screen and (min-width:320px){.md-btn--text{height:36px;margin-bottom:6px;margin-top:6px;font-size:14px}.md-btn--text:after,.md-btn--text:before{content:"";height:6px;left:0;position:absolute;right:0}.md-btn--text:before{top:-6px}.md-btn--text:after{bottom:-6px}.md-btn--fixed-tl{left:16px;top:16px}.md-btn--fixed-tr{right:16px;top:16px}.md-btn--fixed-bl{bottom:16px;left:16px}.md-btn--fixed-br{bottom:16px;right:16px}}@media screen and (min-width:1025px){.md-btn--text{height:32px;margin-bottom:0;margin-top:0;font-size:13px}.md-btn--text:after,.md-btn--text:before{display:none;visibility:hidden}.md-btn--text:before{top:0}.md-btn--text:after{bottom:0}.md-btn--fixed-tl{left:24px;top:24px}.md-btn--fixed-tr{right:24px;top:24px}.md-btn--fixed-bl{bottom:24px;left:24px}.md-btn--fixed-br{bottom:24px;right:24px}.md-btn--icon{height:40px;width:40px;padding:10px}.md-btn--floating{height:48px;padding:14px;width:48px}.md-btn--floating-mini{height:40px;padding:10px;width:40px}}.md-card{display:block}.md-card--raise{transition-duration:.3s;transition-property:box-shadow}.md-collapser--card{transition-duration:.3s;transition-property:background,transform}.md-card-text{font-size:14px;padding:16px}.md-card-text p{font-size:inherit}.md-card-text p:last-child{margin-bottom:0}.md-card-text:last-child{padding-bottom:24px}.md-card-title{align-items:center;display:flex;padding:16px}.md-card-title:last-child{padding-bottom:24px}.md-card-title--primary{padding-top:24px}.md-card-title--title{font-size:14px;line-height:1.42857;margin:0;white-space:normal}.md-card-title--large{font-size:24px}.md-card-title--one-line{overflow:hidden}.md-card-title--one-line .md-card-title--title{overflow:hidden;text-overflow:ellipsis;white-space:nowrap}.md-avatar--card{flex-shrink:0;margin-right:16px}.md-dialog-footer--card{align-items:center;display:flex;justify-content:flex-start}.md-dialog-footer--card-centered{justify-content:center}.md-card--table .md-card-title{padding-left:24px}.md-chip{align-items:center;background:#e0e0e0;border:0;border-radius:16px;display:inline-flex;height:32px;padding-left:12px;padding-right:12px;position:relative;transition-duration:.15s;transition-property:box-shadow,background;vertical-align:top;white-space:nowrap}.md-chip:focus{box-shadow:0 2px 2px 0 rgba(0,0,0,.14),0 1px 5px 0 rgba(0,0,0,.12),0 3px 1px -2px rgba(0,0,0,.2);outline-style:none}.md-chip--hover.md-chip--hover{background:#616161}.md-chip-text{color:rgba(0,0,0,.87);font-size:13px;transition-duration:.15s;transition-property:color}.md-chip .md-avatar{border:0;height:32px;left:0;position:absolute;top:0;width:32px}.md-chip--avatar{padding-left:40px}.md-chip-icon{color:rgba(0,0,0,.54);margin-left:4px;margin-right:4px;position:absolute;right:0;top:4px;z-index:1}.md-chip-icon--rotate{transform:rotate(45deg)}.md-chip--remove{padding-right:32px}.md-chip-text--contact{font-size:14px}.md-chip-text--hover{color:#fff}@media screen and (min-width:1025px){.md-chip-icon{margin-left:6px;margin-right:6px;top:6px}}.md-collapser.md-collapser,.md-collapser .md-tooltip-container{transition-duration:.15s;transition-property:transform}.md-collapser .md-tooltip-container{transform:rotate(0deg)}.md-collapser--flipped{transform:rotate(180deg)}.md-collapser--flipped .md-tooltip-container{transform:rotate(-180deg)}.md-data-table{border-collapse:collapse;max-width:100%}.md-data-table--full-width{width:100%}.md-data-table--responsive{-webkit-overflow-scrolling:touch;overflow-x:auto}tbody .md-table-row:not(:last-child),thead .md-table-row{border-bottom:1px solid rgba(0,0,0,.12)}tbody .md-table-row{transition-duration:.15s;transition-property:background}tbody .md-table-row--active{background:#f5f5f5}@media (min-device-width:1025px){tbody .md-table-row--hover{background:#eee}}.md-table-column{line-height:normal;padding-bottom:0;padding-right:24px;padding-top:0;vertical-align:middle;white-space:nowrap}.md-table-column:first-child{padding-left:24px}.md-table-column--relative{position:relative}.md-table-column--adjusted{padding-right:56px}.md-table-column--header{font-size:12px;font-weight:500;height:56px}.md-table-column--header .md-icon{font-size:16px}.md-table-column--data{font-size:13px;height:48px}.md-table-column--plain{height:48px;white-space:normal}.md-table-column--grow{width:100%}.md-table-column--select-header{padding-left:16px}.md-table-column .md-icon-separator{line-height:inherit}.md-table-checkbox .md-selection-control-label{display:block}.md-table-checkbox .md-selection-control-container{margin-left:12px;margin-right:12px}.md-edit-dialog.md-dialog{width:250px}.md-edit-dialog__label{overflow:hidden;padding:16px 0;text-overflow:ellipsis;width:250px}@media screen and (max-width:1024px){.md-edit-dialog__label{font-size:16px}}.md-edit-dialog__content{display:flex;padding:24px;padding-bottom:8px}.md-edit-dialog__content:not(:first-child){padding-top:0}.md-edit-dialog__header{font-weight:500}.md-edit-dialog__header.md-text-field{font-size:12px}.md-edit-dialog__blocked-field{height:47px;width:250px}.md-edit-dialog__blocked-field.md-edit-dialog__blocked-field{padding-bottom:0;padding-top:0}.md-edit-dialog__blocked-field .md-text-field-icon-container{align-items:center}.md-table-column--select-field{padding-left:24px}.md-select-field-column .md-select-field--btn{height:47px}.md-table-footer--pagination .md-table-column{padding-left:0}.md-table-pagination{height:56px}.md-table-pagination--controls{align-items:center;display:inline-flex;justify-content:flex-start;position:absolute;white-space:nowrap}@media (max-width:767px){.md-table-pagination .md-text-field{font-size:13px}.md-table-pagination .md-icon-text:first-child{padding-right:4px}.md-table-pagination__label{display:none}}.md-table-card-header{position:relative}.md-table-card-header--no-title{align-items:center;display:flex;height:80px;padding-right:2px}.md-table-card-header .md-card-title{padding-right:2px}.md-table-card-header .md-card-title:last-child{padding-bottom:16px}.md-table-card-header .md-btn--dialog+.md-btn--dialog{margin-left:8px}.md-card-title--contextual{background:#ffebee;height:100%;left:0;position:absolute;top:0;width:100%;z-index:1}.md-card-title--title-contextual{color:#c62828;font-size:16px;font-weight:500;line-height:80px}.md-drop-down-enter{transform:translate3d(0,-100%,0)}.md-drop-down-enter.md-drop-down-enter-active{transform:translateZ(0);transition-duration:.15s;transition-property:transform}.md-drop-down-leave{transform:translateZ(0)}.md-drop-down-leave.md-drop-down-leave-active{transform:translate3d(0,-100%,0);transition-duration:.15s;transition-property:transform}.md-data-table--fixed{overflow-y:hidden}.md-data-table__fixed-wrapper{display:table;min-width:100%;position:relative}.md-data-table__fixed-wrapper--header{padding-top:56px}.md-data-table__fixed-wrapper--footer{padding-bottom:48px}.md-data-table__scroll-wrapper{overflow-x:hidden;overflow-y:auto}.md-table-column--fixed{height:0;padding-bottom:0;padding-top:0;visibility:hidden;white-space:nowrap}.md-table-column--fixed>*{display:none}.md-table-column--fixed .md-table-column__fixed{display:block}.md-table-column__fixed{position:absolute;visibility:visible}.md-table-column__fixed--header{top:0}.md-table-column__fixed--footer{bottom:0}.md-table-column__fixed--flex{align-items:center;display:flex}.md-table-column__fixed--flex-right{justify-content:flex-end}.md-table-column__fixed .md-table-checkbox--header{display:flex;height:56px}.md-table-column__fixed .md-table-checkbox--footer{display:flex;height:48px}.md-dialog-container.md-overlay{transition-duration:.3s;z-index:20}.md-dialog{width:280px;cursor:auto;position:fixed}.md-dialog--centered{left:50%;max-height:calc(100% - 48px);max-width:calc(100% - 80px);top:50%;transform:translate3d(-50%,-50%,0)}.md-dialog--centered .md-list{padding-bottom:8px;padding-top:0}.md-dialog--centered .md-list-tile{height:auto;padding:16px 24px}.md-dialog--centered .md-tile-text--primary{white-space:normal}.md-dialog--centered-enter{transform:translate3d(-50%,calc(-50% + -30px),0)}.md-dialog--centered-enter.md-dialog--centered-enter-active{transform:translate3d(-50%,-50%,0);transition-duration:.3s;transition-property:transform}.md-dialog--centered-leave{transform:translate3d(-50%,-50%,0)}.md-dialog--centered-leave.md-dialog--centered-leave-active{transform:translate3d(-50%,calc(-50% + -30px),0);transition-duration:.3s;transition-property:transform}.md-dialog--full-page{bottom:0;left:0;overflow:auto;top:0;width:100vw;z-index:110}.md-dialog--full-page-enter{transform:scale(0)}.md-dialog--full-page-enter.md-dialog--full-page-enter-active{transform:scale(1);transition-duration:.3s;transition-property:transform}.md-dialog--full-page-leave{transform:scale(1)}.md-dialog--full-page-leave.md-dialog--full-page-leave-active{transform:scale(0);transition-duration:.3s;transition-property:transform}.md-title--dialog{margin-bottom:0;padding:24px;padding-bottom:20px;white-space:normal}.md-dialog-content{-webkit-overflow-scrolling:touch;overflow:auto}.md-dialog-content--padded{padding:24px}.md-dialog-content--padded:not(:first-child){padding-top:0}.md-dialog-footer{display:flex;justify-content:flex-end}.md-dialog-footer--inline{padding:8px}.md-dialog-footer--inline .md-btn--dialog+.md-btn--dialog{margin-left:8px}.md-dialog-footer--stacked{align-items:flex-end;flex-direction:column;padding-bottom:8px;padding-right:8px}.md-dialog-footer--stacked .md-btn--dialog{margin-bottom:6px;margin-top:6px}.md-btn--dialog{height:36px;min-width:64px;padding-left:8px;padding-right:8px}.md-divider{background:rgba(0,0,0,.12);border:0;content:"";display:block;height:1px;margin:0}.md-divider--vertical{height:100%;width:1px}.md-divider--inset{margin-left:72px}.md-divider-border{border:0 solid rgba(0,0,0,.12)}.md-divider-border--top{border-top-width:1px}.md-divider-border--right{border-right-width:1px}.md-divider-border--bottom{border-bottom-width:1px}.md-divider-border--left{border-left-width:1px}@media screen and (min-width:320px) and (max-width:1024px){.md-drawer--left{max-width:320px;transform:translate3d(-100%,0,0);width:calc(100vw - 56px)}.md-drawer--right{left:0;transform:translate3d(100%,0,0)}.md-drawer--mini.md-drawer--mini{width:48px}.md-list-tile--mini.md-list-tile--mini{padding-left:12px;padding-right:12px}.md-drawer-relative--mini.md-drawer-relative--mini{margin-left:48px}.md-toolbar~.md-list--drawer{height:calc(100% - 56px)}}@media screen and (min-width:320px) and (min-aspect-ratio:13/9){.md-toolbar~.md-list--drawer{height:calc(100% - 48px)}}@media screen and (min-width:768px){.md-drawer--left{max-width:400px;transform:translate3d(-256px,0,0);width:256px}.md-drawer--right{transform:translate3d(100%,0,0)}.md-drawer--mini.md-drawer--mini{width:72px}.md-list-tile--mini.md-list-tile--mini{padding-left:26px;padding-right:26px}.md-drawer-relative{margin-left:256px}.md-drawer-relative--mini.md-drawer-relative--mini{margin-left:72px}.md-toolbar~.md-list--drawer{height:calc(100% - 64px)}}.md-drawer{transition-duration:.3s;transition-property:transform}.md-drawer--fixed{bottom:0;position:fixed;top:0;z-index:17}.md-drawer--inline{display:inline-block;height:100%}.md-drawer--left{left:0}.md-drawer--right{right:0}.md-drawer--active{transform:translateZ(0)}.md-drawer--mini{z-index:16}.md-list--drawer{-webkit-overflow-scrolling:touch;height:100%;overflow-y:auto}.md-overlay--drawer.md-overlay--drawer{transition-duration:.3s}.md-expansion-panel{background:#fff;transition-duration:.15s;transition-property:margin}.md-expansion-panel--expanded:not(:first-child){margin-top:16px}.md-expansion-panel--expanded:not(:last-child){margin-bottom:16px}.md-panel-column--overflown{flex-shrink:1;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;word-wrap:break-word}.md-panel-column:not(:last-child){padding-right:16px}.md-panel-header{align-items:center;display:flex;font-size:15px;height:48px;justify-content:space-between;padding-left:24px;padding-right:24px;transition-duration:.15s;transition-property:background,height}.md-panel-header--expanded{height:64px}.md-panel-header--focused{background:#eee}.md-panel-content{padding:0 24px 16px}.md-panel-secondary-label{color:rgba(0,0,0,.54);font-size:12px}.md-file-input{height:0;opacity:0;overflow:hidden;position:absolute;width:0}.md-file-input-container{position:relative}.md-file-input-container .md-btn{display:block}.md-ink-container{border-radius:inherit;height:100%;left:0;overflow:hidden;pointer-events:none;position:absolute;top:0;width:100%;z-index:1}.md-ink-container--2x{height:200%;left:-50%;top:-50%;width:200%}.md-ink{background:rgba(0,0,0,.12);border-radius:50%;display:block;opacity:1;position:absolute;transform:scale(0);z-index:-1}.md-ink--active{transition-duration:.45s;transition-property:opacity,transform;transition-timing-function:cubic-bezier(.4,0,1,1)}.md-ink--expanded{transform:scale(1)}.md-ink--leaving{opacity:0;transition-duration:.3s;transition-timing-function:cubic-bezier(0,0,.2,1)}.md-icon{color:rgba(0,0,0,.54);font-size:24px;text-align:center;transition-duration:.15s;transition-property:color;user-select:none}svg.md-icon{fill:currentColor;height:24px;width:24px}.md-icon-separator{align-items:center;display:flex;font-weight:inherit;text-align:left}.md-icon-separator .md-icon{flex-grow:0;flex-shrink:0}.md-icon-text{flex-grow:1;flex-shrink:0;font-weight:inherit;line-height:inherit}.md-icon-text:first-child{padding-right:16px}.md-icon-text:last-child{padding-left:16px}@media screen and (min-width:1025px){.material-icons.md-icon{font-size:20px}svg.md-icon{height:20px;width:20px}}.md-layover-enter{transform:scale(0)}.md-layover-enter.md-layover-enter-active{transform:scale(1);transition-duration:.2s;transition-property:transform;transition-timing-function:cubic-bezier(0,0,.2,1)}.md-layover-leave{opacity:1}.md-layover-leave.md-layover-leave-active{opacity:0;transition-duration:.2s;transition-property:opacity;transition-timing-function:cubic-bezier(.4,0,1,1)}.md-layover-child{position:fixed;z-index:100}.md-layover-child--tl{transform-origin:0 0}.md-layover-child--tr{transform-origin:100% 0}.md-layover-child--bl{transform-origin:0 100%}.md-layover-child--br{transform-origin:100% 100%}.md-layover-child--below{transform-origin:50% 0}.md-layover-child--below.md-layover-enter{transform:scaleY(0)}.md-layover-child--below.md-layover-enter.md-layover-enter-active{transform:scaleY(1)}.md-layover--simplified{position:relative}.md-layover-child--simplified{position:absolute}.md-list{background:#fff;user-select:none}.md-list .md-avatar,.md-list .md-icon{flex-shrink:0}.md-list .md-divider{margin-bottom:8px;margin-top:8px}.md-list .md-list:not(.md-list--menu){background:inherit}.md-list-tile{align-items:center;display:flex;padding-left:16px;padding-right:16px;text-decoration:none;transition-duration:.15s;transition-property:background}.md-list-tile--active{background:rgba(0,0,0,.12)}.md-list-item--inset{padding-left:72px}.md-tile-content{flex-grow:1;overflow:hidden}.md-tile-content--left-icon{padding-left:32px}.md-tile-content--left-avatar{padding-left:16px}.md-tile-content--right-padding{padding-right:16px}.md-tile-addon{line-height:1.42857}.md-tile-addon--icon{height:24px}.md-tile-addon--avatar{height:40px}.md-text--theme-primary .md-icon{color:inherit}.md-tile-text--primary,.md-tile-text--secondary{display:block;overflow:hidden;text-overflow:ellipsis;white-space:nowrap}.md-tile-text--three-lines{white-space:pre-line;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2}.md-list-tile--three-lines .md-tile-addon{align-self:flex-start}.md-list--nested-1 .md-list-tile{padding-left:72px}.md-list--nested-2 .md-list-tile{padding-left:108px}.md-list-control{flex-grow:1}.md-list-control .md-selection-control-label,.md-list-control .md-selection-control-label>span{width:100%}.md-tile-content--left-button{padding-left:24px}.md-list-control--right{justify-content:flex-end}.md-list-tile--control-left{padding-left:0}.md-list-tile--control-right{padding-right:0}@media screen and (min-width:320px){.md-list{padding-bottom:8px;padding-top:8px}.md-list-tile{height:48px}.md-tile-text--primary{font-size:16px}.md-tile-text--secondary{font-size:14px}.md-list-tile--avatar{height:56px}.md-list-tile--two-lines{height:72px}.md-list-tile--three-lines{height:88px}.md-list-tile--three-lines .md-tile-text--secondary{height:40px}.md-list-tile--three-lines .md-tile-addon{margin-top:14px}}@media screen and (min-width:1025px){.md-list{padding-bottom:4px;padding-top:4px}.md-list-tile{height:40px}.md-tile-text--primary,.md-tile-text--secondary{font-size:13px}.md-list-tile--avatar{height:48px}.md-list-tile--two-lines{height:60px}.md-list-tile--three-lines{height:76px}.md-list-tile--three-lines .md-tile-text--secondary{height:37.14286px}.md-list-tile--three-lines .md-tile-addon{margin-top:12px}.md-tile-addon--icon{height:20px}.md-tile-content--left-icon{padding-left:36px}}.md-list--inline{display:flex;padding:0}.md-media{display:block;height:0;overflow:hidden;padding:0;position:relative}.md-media--16-9{padding-bottom:56.25%}.md-media--4-3{padding-bottom:75%}.md-media--1-1{padding-bottom:100%}.md-media-overlay{background:rgba(0,0,0,.54);bottom:0;position:absolute;width:100%;z-index:1}.md-media-overlay .md-btn,.md-media-overlay .md-text{color:#fff}.md-media-overlay .md-text--secondary{color:hsla(0,0%,100%,.7)}.md-list--menu{min-width:112px}.md-list--menu-restricted{-webkit-overflow-scrolling:touch;overflow-y:auto}.md-list--menu-contained{width:100%}.md-list--menu-below{left:0;top:100%;transform-origin:50% 0}.md-list--menu-tr{right:0;top:0;transform-origin:100% 0}.md-list--menu-tl{top:0;transform-origin:0 0}.md-list--menu-br{right:0;transform-origin:100% 100%}.md-list--menu-bl{transform-origin:0 100%}@media screen and (min-width:1025px){.md-list--menu-cascading{padding-bottom:16px;padding-top:16px}.md-list--menu-cascading .md-list-tile{padding-left:24px;padding-right:24px}.md-list--menu-cascading .md-list-tile:not(.md-list-tile--two-lines):not(.md-list-tile--three-lines){height:32px}.md-list--menu-cascading .md-tile-text--primary{font-size:15px}.md-list--menu-cascading .md-collapser{transform:rotate(-90deg)}.md-list--menu-cascading .md-collapser--flipped{transform:rotate(90deg)}}@media screen and (min-width:320px){.md-list--menu-restricted{max-height:272px}}@media screen and (min-width:1025px){.md-list--menu-restricted{max-height:264px}}@media screen and (min-width:320px){.md-navigation-drawer-content{min-height:calc(100vh - 56px)}}@media screen and (min-width:320px) and (min-aspect-ratio:13/9){.md-navigation-drawer-content{min-height:calc(100vh - 48px)}}@media screen and (min-width:768px){.md-navigation-drawer-content{min-height:calc(100vh - 64px)}.md-title.md-title--persistent-offset{margin-left:216px}}@media screen and (min-width:1025px){.md-title.md-title--persistent-offset{margin-left:226px}}.md-toolbar.md-toolbar--over-drawer{z-index:19}.md-title--drawer-active.md-title--drawer-active{transition-duration:.3s;transition-property:margin-left}.md-navigation-drawer-content{display:block}.md-navigation-drawer-content:focus{outline-style:none}.md-navigation-drawer-content--inactive{margin-left:0}.md-navigation-drawer-content--active{transition-duration:.3s;transition-property:margin-left}.md-navigation-drawer-content--prominent-offset{min-height:calc(100vh - 128px)}.md-title.md-title--permanent-offset{margin-left:276px}.md-cross-fade-enter{opacity:.01;transform:translate3d(0,16px,0)}.md-cross-fade-enter.md-cross-fade-enter-active{opacity:1;transform:translateZ(0);transition-duration:.3s;transition-property:transform,opacity}.md-overlay{background:rgba(0,0,0,.4);bottom:0;left:0;opacity:0;position:fixed;right:0;top:0;transition-duration:.15s;transition-property:opacity;z-index:16}.md-overlay--active{opacity:1}.md-paper--0{box-shadow:none}@media screen and (min-width:1025px){.md-paper--0-hover{transition-duration:.3s;transition-property:box-shadow}.md-paper--0-hover:hover{box-shadow:0 6px 10px 0 rgba(0,0,0,.14),0 1px 18px 0 rgba(0,0,0,.12),0 3px 5px -1px rgba(0,0,0,.4)}}.md-paper--1{box-shadow:0 2px 2px 0 rgba(0,0,0,.14),0 1px 5px 0 rgba(0,0,0,.12),0 3px 1px -2px rgba(0,0,0,.2)}.md-paper--2{box-shadow:0 4px 5px 0 rgba(0,0,0,.14),0 1px 10px 0 rgba(0,0,0,.12),0 2px 4px -1px rgba(0,0,0,.4)}.md-paper--3{box-shadow:0 6px 10px 0 rgba(0,0,0,.14),0 1px 18px 0 rgba(0,0,0,.12),0 3px 5px -1px rgba(0,0,0,.4)}.md-paper--4{box-shadow:0 8px 10px 1px rgba(0,0,0,.14),0 3px 14px 2px rgba(0,0,0,.12),0 5px 5px -3px rgba(0,0,0,.4)}.md-paper--5{box-shadow:0 16px 24px 2px rgba(0,0,0,.14),0 6px 30px 5px rgba(0,0,0,.12),0 8px 10px -5px rgba(0,0,0,.4)}.md-picker-container{position:relative}.md-picker-content-container{background:#fff}.md-picker--inline{box-shadow:0 6px 10px 0 rgba(0,0,0,.14),0 1px 18px 0 rgba(0,0,0,.12),0 3px 5px -1px rgba(0,0,0,.4);position:absolute;z-index:12}.md-picker--inline-icon{left:40px}.md-picker-control{padding:0}.md-picker-text{color:hsla(0,0%,100%,.7)}.md-picker-text.md-picker-text>*{color:inherit}.md-picker-text>*{font-weight:inherit;margin:0;transition-duration:.15s;transition-property:color,font}.md-picker-text--active{color:#fff;font-weight:500}.md-dialog--picker{-webkit-overflow-scrolling:touch;max-height:calc(100% - 16px);max-width:calc(100% - 16px);overflow:auto;width:auto}.md-dialog-content--picker{padding:0}.md-picker-header{background:#bdbdbd;padding:24px}@media (orientation:portrait){.md-picker{width:320px}.md-picker .md-picker-header{height:110px}.md-picker .md-time-periods{display:inline-block;padding-left:1em;padding-right:24px}.md-picker .md-picker-content{height:340px}.md-picker .md-display-3{font-size:4.8em;line-height:1}.md-picker .md-calendar-dows{padding-bottom:12px}.md-picker.md-picker--date .md-display-1{display:inline-block}.md-picker .md-calendar-date--btn{height:44px}.md-picker .md-calendar-date--btn:after{height:36px;width:36px}.md-picker .md-clock-face{height:272px;width:272px}.md-picker .md-clock-hand{width:116px}.md-picker .md-clock-hand--inner{width:80px}}@media (orientation:landscape){.md-picker{display:flex;width:560px}.md-picker .md-picker-header{width:180px}.md-picker .md-picker-content{height:280px;width:380px}.md-picker .md-calendar-date--btn{height:35px}.md-picker .md-calendar-date--btn:after{height:32px;width:32px}.md-picker.md-picker--time .md-picker-header{padding-top:93.33333px}.md-picker .md-clock-face{height:244px;width:244px}.md-picker .md-clock-hand{width:102px}.md-picker .md-clock-hand--inner{width:66px}.md-picker .md-time-periods{margin-left:auto;margin-right:2.5em;width:35px}.md-picker .md-display-3{font-size:3.25em}}@media (max-width:320px) and (orientation:portrait){.md-picker{width:304px}}@media (max-height:320px) and (orientation:landscape){.md-picker .md-picker-content{height:256px;width:calc(100vw - 196px)}}.md-picker--date .md-picker-control{display:block}.md-picker-content--calendar{padding-left:12px;padding-right:12px}.md-calendar-controls{align-items:center;display:flex}.md-calendar-controls .md-title{flex-grow:1;font-size:16px;margin-bottom:0;text-align:center}.md-calendar-date{margin:0;width:14.28571%}.md-picker-content--year{-webkit-overflow-scrolling:touch;overflow-y:auto}.md-years{list-style:none;margin:0;padding:0}.md-year{font-size:16px;padding:12px;transition-duration:.15s;transition-property:color,font-size}.md-year:focus:not(.md-year--active){font-size:20px}.md-year--active{font-size:24px;font-weight:500}.md-calendar-date--btn:after{background:#bdbdbd;border-radius:50%;content:"";display:block;left:50%;position:absolute;top:50%;transform:translateX(-50%) translateY(-50%) scale(0);transition-duration:.15s;transition-property:transform;z-index:0}.md-calendar-date--btn-active{font-weight:700}.md-calendar-date--btn-active:after{transform:translateX(-50%) translateY(-50%) scale(1)}.md-calendar-date--date{position:relative;z-index:1}.md-calendar-dow{font-size:13px;font-weight:700;line-height:1.42857}.md-picker-content--clock{padding:24px;padding-bottom:12px}.md-time-periods .md-picker-control{display:block}.md-time-period{font-size:1.14286em;font-weight:500;margin:0;padding:0}.md-clock-face{background:#f5f5f5;border-radius:50%;position:relative}.md-clock-hand{height:2px;position:absolute;transform-origin:0 0;transition-duration:.15s;transition-property:width;z-index:1}.md-clock-hand--active{transition-property:transform,width}.md-clock-hand:after,.md-clock-hand:before{background:#bdbdbd;border-radius:50%;content:"";position:absolute}.md-clock-hand:before{height:6px;left:-3px;top:-2px;width:6px}.md-clock-hand:after{height:36px;right:-16px;top:-18px;transition-duration:.15s;transition-property:background,border,transform;width:36px}.md-clock-hand--minute-hover:after{transform:scale(.4)}.md-clock-time{align-items:center;display:flex;height:36px;justify-content:center;position:absolute;width:36px;z-index:8}.md-clock-time:focus{outline-style:none}.md-progress{display:block;margin-bottom:1em;margin-top:1em}.md-progress--circular-determinate{transition-duration:.15s;transition-property:transform}.md-progress--circular-indeterminate{animation-duration:2.4s;animation-iteration-count:infinite;animation-name:md-circular-progress;animation-timing-function:linear}.md-circular-progress-path{fill:none;stroke:#c62828;stroke-dasharray:187px}.md-circular-progress-path--animated{animation-duration:2.4s;animation-iteration-count:infinite;animation-name:md-circular-progress-dash;animation-timing-function:ease-ine-out;stroke-dashoffset:0}@keyframes md-circular-progress{0%{transform:rotate(0deg)}50%{transform:rotate(135deg)}75%{transform:rotate(450deg)}to{transform:rotate(2turn)}}@keyframes md-circular-progress-dash{0%{stroke-dashoffset:187px}50%{stroke-dashoffset:46.75px}to{stroke-dashoffset:187px}}.md-progress--linear{background:#ff8a80;height:3px;overflow:hidden;position:relative;width:100%}.md-progress--linear-active{background:#c62828}.md-progress--linear-determinate{height:100%;position:absolute;z-index:1}.md-progress--linear-indeterminate:after,.md-progress--linear-indeterminate:before{background:inherit;bottom:0;content:"";position:absolute;top:0;will-change:left,right;z-index:1}.md-progress--linear-indeterminate:before{animation-duration:2.4s;animation-iteration-count:infinite;animation-name:md-linear-indeterminate;animation-timing-function:cubic-bezier(.4,0,.2,1)}.md-progress--linear-indeterminate:after{animation-delay:1.15s;animation-duration:2.4s;animation-iteration-count:infinite;animation-name:md-linear-indeterminate-short;animation-timing-function:cubic-bezier(.4,0,1,1)}.md-progress--linear-query:after,.md-progress--linear-query:before{animation-direction:reverse}@keyframes md-linear-indeterminate{0%{left:-35%;right:100%}60%{left:100%;right:-90%}to{left:100%;right:-90%}}@keyframes md-linear-indeterminate-short{0%{left:-200%;right:100%}60%{left:107%;right:-8%}to{left:107%;right:-8%}}.md-select-field{cursor:inherit;display:flex;flex-wrap:wrap;user-select:none}.md-select-field .md-divider{width:100%}.md-select-field__toggle{position:relative}.md-select-field--btn.md-select-field--btn{padding:16px 16px 16px 24px}.md-select-field--text-field{pointer-events:none}.md-drop-enter{transform:translate3d(0,-6px,0)}.md-drop-enter.md-drop-enter-active{transform:translateZ(0);transition-duration:.3s;transition-property:transform}@media screen and (min-width:320px){.md-select-field--btn{height:48px}.md-select-field--text-field{height:18px}}@media screen and (min-width:1025px){.md-select-field--btn{height:40px}.md-select-field--text-field{height:15px}}.md-selection-control-container--inline{display:inline-block}.md-selection-control-input{height:0;position:absolute;visibility:hidden;width:0}.md-selection-control-label{align-items:center;display:inline-flex}.md-selection-control-group{border:0}.md-switch-container{align-items:center;display:flex;height:48px}.md-switch-container.md-selection-control-container--inline{display:inline-flex}.md-switch-track{border-radius:8px;flex-shrink:0;height:16px;margin-left:12px;margin-right:12px;position:relative;width:40px}.md-switch-track--on{background:rgba(244,67,54,.5)}.md-switch-track--off{background:rgba(0,0,0,.38)}.md-switch-track--disabled{background:rgba(0,0,0,.12)}.md-switch-thumb{box-shadow:0 2px 2px 0 rgba(0,0,0,.14),0 1px 5px 0 rgba(0,0,0,.12),0 3px 1px -2px rgba(0,0,0,.2);border-radius:50%;content:"";display:block;height:24px;position:absolute;transition-duration:.15s;transition-property:background,transform;width:24px}.md-switch-thumb--on{background:#f44336;transform:translate3d(20px,-4px,0)}.md-switch-thumb--off{background:#fafafa;transform:translate3d(-4px,-4px,0)}.md-switch-thumb--disabled{background:#bdbdbd}@media screen and (min-width:320px){.md-selection-control-label{font-size:16px}}@media screen and (min-width:1025px){.md-selection-control-label{font-size:13px}.md-selection-control-container{height:40px}}.md-slider-container{display:flex;flex-wrap:wrap;text-align:left}.md-slider-label{display:block;width:100%}.md-slider-input{height:0;position:absolute;visibility:hidden;width:0}.md-slider-track{background:rgba(0,0,0,.26);content:"";display:block;flex-grow:1;flex-shrink:0;height:2px;margin-bottom:23px;margin-top:23px;position:relative}.md-slider-track-fill{background:#bdbdbd;border:0;height:2px;left:0;margin:0;position:absolute;top:0;transition-duration:.15s;transition-property:width}.md-slider-track-fill--dragging{transition-property:none}.md-slider-thumb{border-radius:50%;content:"";display:inline-block;height:14px;position:absolute;top:-6px;transition-duration:.15s;transition-property:left,transform,background;width:14px;z-index:5}.md-slider-thumb:focus{outline-style:none}.md-slider-thumb--on{background:#bdbdbd}.md-slider-thumb--active{transform:scale(1.5);transform-origin:center}.md-slider-thumb--dragging{transition-property:transform,background}.md-slider-thumb--disabled{background:rgba(0,0,0,.26);transform:scale(.75)}.md-slider-thumb--continuous-off{background:#fff;border:2px solid;border-color:rgba(0,0,0,.26);position:relative}.md-slider-thumb--mask{transform:scale(1)}.md-slider-thumb--mask-inked{background:hsla(0,0%,74%,.15);transform:scale(3.5);z-index:4}.md-slider-thumb--mask-disabled{background:#fff;border-radius:0;transform:scale(1.1);z-index:4}.md-slider-thumb--discrete:after{border-left:7px solid transparent;border-right:7px solid transparent;border-top:7px solid transparent;border-top-left-radius:10px;border-top-right-radius:10px;content:"";height:0;left:0;position:absolute;top:10px;transition-duration:.15s;transition-property:border-top-color,transform;width:0}.md-slider-thumb--discrete-active{top:0;transform:scale(2) translate3d(0,-18px,0)}.md-slider-thumb--discrete-on:after{border-top-color:#bdbdbd}.md-slider-thumb--discrete-off{background:#000}.md-slider-thumb--discrete-active-off{background:#bdbdbd}.md-slider-thumb--discrete-active-off:after{border-top-color:#bdbdbd}.md-slider-thumb--discrete-mask-inked{transform:scale(2.5);transition-duration:.3s}.md-slider-thumb--discrete-mask-leaving{background:hsla(0,0%,74%,.3);transition-duration:.3s;z-index:4}.md-slider-discrete-value{align-items:center;color:#fff;display:flex;font-size:12px;height:28px;justify-content:center;position:absolute;text-align:center;transform:translate3d(-7px,-43px,0);transition-duration:.15s;transition-property:left;width:28px;z-index:6}.md-slider-discrete-tick{background:#000;content:"";height:2px;position:absolute;top:0;z-index:4}.md-slider-discrete-value--dragging{transition-property:none}.md-slider-editor{text-align:right}.md-slider-container .md-text-field-container{margin-left:4px;padding-right:0}@media screen and (min-width:320px){.md-slider-ind{font-size:16px;margin-top:14px}}@media screen and (min-width:1025px){.md-slider-ind{font-size:13px;margin-top:16px}}.md-slider-container .md-icon{margin-bottom:12px;margin-top:12px}.md-slider-ind{display:block;text-align:center}.md-slider-track--ind-left{margin-left:16px}.md-slider-track--ind-right{margin-right:16px}.md-subheader{font-size:14px;font-weight:500;height:48px;line-height:48px;padding-left:16px;padding-right:16px}.md-snackbar-container{position:absolute}.md-snackbar{align-items:center;background:#323232;bottom:0;display:flex;height:48px;justify-content:space-between;position:fixed;transform-origin:0 100%;z-index:20}.md-snackbar--multiline{height:80px}.md-snackbar--toast{color:#fff;margin-bottom:0;padding-left:24px;padding-right:24px}.md-snackbar-enter-active,.md-snackbar-leave-active{transition-duration:.3s;transition-property:transform}.md-snackbar-enter-active *,.md-snackbar-leave-active *{transition-duration:.3s;transition-property:opacity}.md-snackbar-enter.md-snackbar-enter-active{transition-timing-function:cubic-bezier(0,0,.2,1)}.md-snackbar-leave.md-snackbar-leave-active{transition-timing-function:cubic-bezier(.4,0,1,1)}.md-snackbar-enter *,.md-snackbar-leave.md-snackbar-leave-active *{opacity:0}.md-snackbar-enter.md-snackbar-enter-active *,.md-snackbar-leave *{opacity:1}.md-btn--snackbar{padding-left:24px;padding-right:24px}@media screen and (min-width:320px){.md-snackbar{left:0;right:0}.md-snackbar-enter,.md-snackbar-leave.md-snackbar-leave-active{transform:translate3d(0,100%,0)}.md-snackbar-enter.md-snackbar-enter-active,.md-snackbar-leave{transform:translateZ(0)}.md-snackbar--action{padding-right:0}.md-btn--snackbar-floating{transition:bottom .3s,background .15s,box-shadow .15s,color .15s;will-change:bottom}.md-btn--snackbar-floating-adjust{bottom:64px}.md-btn--snackbar-floating-multiline-adjust{bottom:96px}}@media screen and (min-width:768px){.md-snackbar{border-radius:2px;left:50%;max-width:568px;min-width:288px;right:auto;transform:translate3d(-50%,0,0)}.md-snackbar-enter,.md-snackbar-leave.md-snackbar-leave-active{transform:translate3d(-50%,100%,0)}.md-snackbar-enter.md-snackbar-enter-active,.md-snackbar-leave{transform:translate3d(-50%,0,0)}.md-snackbar--action{padding-right:24px}.md-btn--snackbar-floating-adjust,.md-btn--snackbar-floating-multiline-adjust{bottom:24px}}.md-tabs{display:flex;position:relative}.md-tabs.md-background--primary .md-ink{background:hsla(0,0%,100%,.12)}.md-tabs--centered{justify-content:center}.md-tabs--centered .md-tab,.md-tabs--pagination .md-tab{flex-grow:0}.md-tab{align-items:center;color:inherit;display:flex;flex-direction:column;flex-grow:1;flex-shrink:0;height:48px;justify-content:flex-end;overflow:hidden;padding-bottom:20px;padding-left:12px;padding-right:12px;position:relative;text-align:center;text-decoration:none;text-transform:uppercase}.md-tab--multiline{font-size:12px;padding-bottom:12px}.md-tab--icon{height:72px;padding-bottom:16px}.md-tab--inactive{color:hsla(0,0%,100%,.7)}.md-tab-indicator{background:#c62828;bottom:0;content:"";height:2px;left:0;position:absolute}.md-btn--tab-overflow{bottom:2px;position:absolute}.md-btn--tab-overflow--icon{bottom:8px}.md-btn--tab-overflow-left{left:6px;z-index:3}.md-btn--tab-overflow-right{right:12px}.md-menu--tab{margin-right:100%}.md-menu--tab .md-icon{color:inherit}.md-menu--tab .md-tab{padding-top:12px}.md-icon--tab{color:inherit;margin-bottom:10px}.md-tab-toolbar{width:100%}.md-tabs-fixed-container{left:0;position:fixed;right:0;top:0;z-index:15}.md-tabs-content--offset{margin-top:48px}.md-tabs-content--offset-icon{margin-top:72px}.md-tabs-content--offset-toolbar-prominent{margin-top:176px}.md-tabs-content--offset-toolbar-prominent-icon{margin-top:200px}@media screen and (min-width:320px){.md-toolbar~.md-tabs{margin-top:-1px}.md-tabs{-webkit-overflow-scrolling:touch;overflow-x:auto}.md-tab{max-width:calc(100vw - 56px);min-width:72px}.md-tab-label{font-size:14px;font-weight:500;line-height:14px}}@media screen and (min-width:320px) and (max-aspect-ratio:13/9){.md-tabs-content--offset-toolbar{margin-top:104px}.md-tabs-content--offset-toolbar-icon{margin-top:128px}}@media screen and (min-width:320px) and (min-aspect-ratio:13/9){.md-tabs-content--offset-toolbar{margin-top:96px}.md-tabs-content--offset-toolbar-icon{margin-top:120px}}@media screen and (min-width:768px){.md-tabs-content--offset-toolbar{margin-top:112px}.md-tabs-content--offset-toolbar-icon{margin-top:136px}}@media screen and (min-width:1025px){.md-toolbar~.md-tabs{margin-top:0}.md-tabs{overflow:visible}.md-tab{max-width:264px;min-width:160px;padding-left:24px;padding-right:24px}.md-tab-label{font-size:13px;line-height:13px}.md-icon--tab{margin-bottom:12px;margin-top:2px}}.md-text-field-container{position:relative}.md-text-field-container--input{line-height:1.15}.md-text-field-container--input-block{display:flex}.md-text-field-container--input-block .md-text-field-message-container{flex-shrink:0}.md-text-field-container--multiline,.md-text-field-multiline-container{transition-duration:.15s;transition-property:height}.md-text-field-multiline-container{position:relative}.md-text-field-container--multiline{display:flex;flex-direction:column}.md-text-field{background:none;border:0;line-height:inherit;padding:0;width:100%}.md-text-field:placeholder{color:rgba(0,0,0,.54)}.md-text-field:-moz-placeholder,.md-text-field::-moz-placeholder{color:rgba(0,0,0,.54)}.md-text-field:-ms-input-placeholder{color:rgba(0,0,0,.54)}.md-text-field::-webkit-input-placeholder{color:rgba(0,0,0,.54)}.md-text-field:focus{outline-style:none}.md-text-field[type=search]{-webkit-appearance:textfield}.md-text-field:-webkit-autofill,.md-text-field:-webkit-autofill:focus{box-shadow:inset 0 0 0 50px #fff}.md-text-field--margin{margin-top:13px}.md-text-field[disabled]:placeholder{color:rgba(0,0,0,.38)}.md-text-field[disabled]:-moz-placeholder,.md-text-field[disabled]::-moz-placeholder{color:rgba(0,0,0,.38)}.md-text-field[disabled]:-ms-input-placeholder{color:rgba(0,0,0,.38)}.md-text-field[disabled]::-webkit-input-placeholder{color:rgba(0,0,0,.38)}.md-text-field--multiline{padding-bottom:0;padding-top:0;resize:none}.md-text-field--multiline-mask{overflow:hidden;position:absolute;visibility:hidden}.md-divider--text-field{margin-top:7px;overflow:visible}.md-divider--text-field:after{background:#bdbdbd;content:"";display:block;height:2px;transition-duration:.15s;transition-property:width;width:0}.md-divider--text-field-expanded:after{width:100%}.md-divider--text-field-error,.md-divider--text-field-error:after{background:#f44336}.md-divider--expand-from-left:after{left:0}.md-divider--expand-from-center:after{margin:auto}.md-divider--expand-from-right:after{right:0}.md-floating-label{cursor:text;line-height:1;pointer-events:none;position:absolute;top:0;transition-duration:.15s;transition-property:transform,font-size,color;white-space:nowrap}.md-floating-label--floating{font-size:12px}.md-floating-label--icon-offset{left:40px}@media screen and (min-width:1025px){.md-floating-label--icon-offset{left:36px}}.md-text-field-message-container{display:flex;font-size:12px;justify-content:space-between}.md-text-field-message-container--count-only{justify-content:flex-end}.md-text-field-message-container--left-icon-offset{padding-left:40px}.md-text-field-message-container--right-icon-offset{padding-right:40px}.md-text-field-message{color:inherit;flex-grow:1;line-height:1.42857;transition-duration:.15s;transition-property:opacity;white-space:normal}.md-text-field-message--counter{display:block;flex-grow:0;flex-shrink:0;padding-left:16px}.md-text-field-message--inactive{opacity:0}.md-text-field-message--active{opacity:1}.md-text-field-divider-container{display:inline-block}.md-text-field-divider-container--grow{display:block;flex-grow:1}.md-text-field-divider-container+.md-text-field-icon,.md-text-field-icon+.md-text-field-divider-container{margin-left:16px}.md-text-field-icon-container{align-items:flex-end;display:flex;width:100%}.md-text-field-container--input-block .md-text-field-icon-container{align-items:center}.md-text-field-inline-indicator{position:absolute;right:0}.md-text-field--inline-indicator{width:calc(100% - 24px)}.md-password-btn{background:transparent;border:0;height:24px;padding:0;width:24px}.md-password-btn:not(.md-password-btn--focus):focus{outline-style:none}.md-password-btn .md-icon{color:inherit}.md-password-btn--active:before{background:rgba(0,0,0,.54)}.md-password-btn--invisible:after,.md-password-btn--invisible:before{content:"";display:block;height:2px;position:absolute;top:50%;width:100%}.md-password-btn--invisible:before{transform:translate3d(-1px,-50%,0) rotate(45deg)}.md-password-btn--invisible:after{background:#fafafa;transform:translate3d(1px,-50%,0) rotate(45deg)}@media screen and (min-width:320px){.md-text-field-container--input-block{padding-bottom:20px;padding-top:20px}.md-text-field-container--multiline-block{margin-bottom:20px;margin-top:20px}.md-text-field-container--padded-block{padding-left:20px;padding-right:20px}.md-text-field{font-size:16px}.md-text-field--floating-margin{margin-top:37px}.md-divider--text-field{margin-bottom:8px}.md-floating-label--inactive{transform:translate3d(0,39px,0)}.md-floating-label--inactive-sized{font-size:16px}.md-floating-label--floating{transform:translate3d(0,16px,0)}.md-text-field-icon--positioned{margin-bottom:13.5px}.md-text-field-inline-indicator{top:9px}.md-text-field-inline-indicator--floating{top:34px}.md-text-field-inline-indicator--block{top:17px}.md-floating-label--inactive-title{transform:translate3d(0,42px,0)}}@media screen and (min-width:1025px){.md-text-field-container--input-block{padding-bottom:16px;padding-top:16px}.md-text-field-container--multiline-block{margin-bottom:16px;margin-top:16px}.md-text-field-container--padded-block{padding-left:16px;padding-right:16px}.md-text-field{font-size:13px}.md-text-field--floating-margin{margin-top:33px}.md-divider--text-field{margin-bottom:4px}.md-floating-label--inactive{transform:translate3d(0,33px,0)}.md-floating-label--inactive-sized{font-size:13px}.md-floating-label--floating{transform:translate3d(0,12px,0)}.md-text-field-icon--positioned{margin-bottom:9.5px}.md-password-btn.md-password-btn{height:20px;width:20px}.md-text-field-message-container--left-icon-offset{padding-left:36px}.md-text-field-message-container--right-icon-offset{padding-right:36px}.md-text-field-inline-indicator{top:9px}.md-text-field-inline-indicator--floating{top:30px}.md-text-field-inline-indicator--block{top:12px}.md-floating-label--inactive-title{transform:translate3d(0,36px,0)}}.md-text-field--title{font-size:34px}.md-floating-label--title{transition-duration:.25s}.md-floating-label--inactive-title{font-size:34px}@media screen and (min-width:320px){.md-toolbar-relative{margin-top:56px}.md-toolbar-relative--padding{padding-top:56px}.md-toolbar{height:56px}.md-btn--toolbar{margin-bottom:4px;margin-top:4px}.md-toolbar .md-btn--text{margin-bottom:10px;margin-top:10px}.md-toolbar--action-left{margin-left:4px}.md-toolbar--action-right{margin-right:4px}.md-title--toolbar{line-height:56px;margin-left:20px}.md-title--toolbar-offset{margin-left:72px}.md-select-field--toolbar.md-select-field--toolbar{margin-bottom:6px;margin-top:6px}}@media screen and (min-width:320px) and (min-aspect-ratio:13/9){.md-toolbar-relative{margin-top:48px}.md-toolbar-relative--padding{padding-top:48px}.md-toolbar{height:48px}.md-toolbar--action-left{margin-left:4px}.md-toolbar--action-right{margin-right:4px}.md-title--toolbar{line-height:48px;margin-left:20px}.md-title--toolbar-offset{margin-left:72px}}@media screen and (min-width:768px){.md-toolbar-relative{margin-top:64px}.md-toolbar-relative--padding{padding-top:64px}.md-toolbar{height:64px}.md-btn--toolbar{margin-bottom:8px;margin-top:8px}.md-toolbar .md-btn--text{margin-bottom:14px;margin-top:14px}.md-toolbar--action-left{margin-left:12px}.md-toolbar--action-right{margin-right:12px}.md-title--toolbar{line-height:64px;margin-left:20px}.md-title--toolbar-offset{margin-left:80px}.md-select-field--toolbar.md-select-field--toolbar{margin-bottom:10px;margin-top:10px}}@media screen and (min-width:768px) and (min-aspect-ratio:13/9){.md-select-field--toolbar.md-select-field--toolbar{margin-bottom:12px;margin-top:12px}}@media screen and (min-width:1025px){.md-toolbar--action-left{margin-left:14px}.md-toolbar--action-right{margin-right:14px}.md-title--toolbar{margin-left:26px}.md-title--toolbar-offset{margin-left:80px}.md-btn--toolbar{margin-bottom:12px;margin-top:12px}.md-toolbar .md-btn--text{margin-bottom:16px;margin-top:16px}}.md-toolbar{display:flex}.md-toolbar--fixed{left:0;position:fixed;right:0;top:0;z-index:15}.md-toolbar--inset{margin:8px;max-width:calc(100vw - 16px)}.md-toolbar--text-white{color:#fff}.md-toolbar--text-white .md-btn,.md-toolbar--text-white .md-icon,.md-toolbar--text-white .md-select-field,.md-toolbar--text-white .md-text-field,.md-toolbar--text-white .md-title--toolbar{color:inherit}.md-toolbar--text-white :placeholder{color:hsla(0,0%,100%,.7)}.md-toolbar--text-white :-moz-placeholder,.md-toolbar--text-white ::-moz-placeholder{color:hsla(0,0%,100%,.7)}.md-toolbar--text-white :-ms-input-placeholder{color:hsla(0,0%,100%,.7)}.md-toolbar--text-white ::-webkit-input-placeholder{color:hsla(0,0%,100%,.7)}.md-toolbar--themed{background:#f5f5f5}.md-toolbar--themed .md-title--toolbar{color:rgba(0,0,0,.87)}.md-toolbar--prominent{height:128px}.md-title--toolbar{color:rgba(0,0,0,.87);margin-bottom:0;transition-duration:.15s;transition-property:transform}.md-title--toolbar-prominent{position:absolute;transform:translate3d(0,64px,0)}.md-toolbar-relative--prominent{margin-top:128px}.md-toolbar-relative--prominent-padding{padding-top:128px}.md-toolbar .md-text-field-container{padding-bottom:0;padding-top:0}.md-toolbar .md-text-field--toolbar{font-size:20px}.md-toolbar .md-autocomplete,.md-toolbar .md-autocomplete-container{height:100%}@media screen and (min-width:320px){.md-tooltip{font-size:14px;padding:9px 16px}.md-tooltip--top{top:-24px}.md-tooltip--right{right:-24px}.md-tooltip--bottom{bottom:-24px}.md-tooltip--left{left:-24px}}@media screen and (min-width:1025px){.md-tooltip{font-size:10px;padding:6px 8px}.md-tooltip--top{top:-14px}.md-tooltip--right{right:-14px}.md-tooltip--bottom{bottom:-14px}.md-tooltip--left{left:-14px}}.md-tooltip-container{height:100%;left:0;pointer-events:none;position:absolute;top:0;user-select:none;width:100%;z-index:1}.md-tooltip{background:#616161;color:#fff;display:block;font-weight:500;opacity:.9;outline-style:none;position:absolute;white-space:nowrap}.md-tooltip--active{transition-duration:.15s;transition-property:opacity,transform}.md-tooltip--enter,.md-tooltip--leave-active{opacity:0}.md-tooltip--enter-active{opacity:.9;transition-timing-function:cubic-bezier(0,0,.2,1)}.md-tooltip--leave-active{transition-timing-function:cubic-bezier(.4,0,1,1)}.md-tooltip--horizontal{left:50%;transform:translate3d(-50%,0,0)}.md-tooltip--vertical{top:50%;transform:translate3d(0,-50%,0)}.md-tooltip--top-active{transform:translate3d(-50%,-100%,0)}.md-tooltip--right-active{transform:translate3d(100%,-50%,0)}.md-tooltip--bottom-active{transform:translate3d(-50%,100%,0)}.md-tooltip--left-active{transform:translate3d(-100%,-50%,0)}.md-text{color:rgba(0,0,0,.87)}.md-text--secondary{color:rgba(0,0,0,.54)}.md-text--disabled{color:rgba(0,0,0,.38)}.md-text--theme-primary{color:#bdbdbd}.md-text--theme-secondary{color:#c62828}.md-text--error{color:#f44336}.md-text--inherit.md-text--inherit{color:inherit}.md-ink--primary .md-ink{background:hsla(0,0%,74%,.26)}.md-ink--secondary .md-ink{background:rgba(198,40,40,.26)}.md-background{background:#fafafa}.md-background--card{background:#fff}.md-background--primary{background:#bdbdbd;color:#fff}.md-background--secondary{background:#c62828;color:#fff}@media screen and (min-width:1025px){.md-background--primary-hover:hover{background:hsla(0,0%,74%,.9)}.md-background--secondary-hover:hover{background:rgba(198,40,40,.9)}}@media (max-width:359px){div .mobile-fix{padding-left:0;padding-right:0}}</style></head><body><div id="___gatsby"><div data-reactroot="" data-reactid="1" data-react-checksum="-1680124505"><header class="md-paper md-paper--2 md-toolbar md-background--primary md-toolbar--text-white md-toolbar--fixed" data-reactid="2"><button type="button" class="md-btn md-btn--icon md-pointer--hover md-inline-block md-btn--toolbar md-toolbar--action-left" data-reactid="3"><div class="md-ink-container" data-reactid="4"></div><i class="md-icon material-icons md-text--inherit" data-reactid="5">menu</i></button><!-- react-empty: 6 --><div class="md-cell--right md-toolbar--action-right" data-reactid="7"><div class="toolbar-actions" data-reactid="8"><div class="userlinks-container" data-reactid="9"><div class="user-links" data-reactid="10"><a href="https://github.com/dwjbosman" class="md-btn md-btn--icon md-pointer--hover md-text--theme-secondary md-ink--secondary md-inline-block" data-reactid="11"><div class="md-ink-container" data-reactid="12"></div><i class="md-icon fa fa-github md-text--inherit" data-reactid="13"></i></a><a href="https://www.linkedin.com/in/dwjbosman" class="md-btn md-btn--icon md-pointer--hover md-text--theme-secondary md-ink--secondary md-inline-block" data-reactid="14"><div class="md-ink-container" data-reactid="15"></div><i class="md-icon fa fa-linkedin md-text--inherit" data-reactid="16"></i></a><a href="https://www.twitter.com/dwjbosman" class="md-btn md-btn--icon md-pointer--hover md-text--theme-secondary md-ink--secondary md-inline-block" data-reactid="17"><div class="md-ink-container" data-reactid="18"></div><i class="md-icon fa fa-twitter md-text--inherit" data-reactid="19"></i></a><a href="mailto:dinne.bosman@the-future-group.com" class="md-btn md-btn--icon md-pointer--hover md-text--theme-secondary md-ink--secondary md-inline-block" data-reactid="20"><div class="md-ink-container" data-reactid="21"></div><i class="md-icon fa fa-envelope md-text--inherit" data-reactid="22"></i></a></div></div></div></div></header><!-- react-empty: 23 --><main id="main-content" tabindex="-1" class="md-navigation-drawer-content md-navigation-drawer-content--inactive md-transition--acceleration md-toolbar-relative main-content" data-reactid="24"><div class="main-container" data-reactid="25"><div data-reactid="26"><!-- react-empty: 27 --><div class="post-page md-grid md-grid--no-spacing" data-reactid="28"><!-- react-empty: 29 --><!-- react-empty: 30 --><div style="background-image:url(/logos/network.jpg);height:180px;" class="md-grid md-cell--9 post-cover" data-reactid="31"></div><div class="md-grid md-cell--9 post-page-contents mobile-fix post-overlap-mobile" data-reactid="32"><div class="md-paper md-paper--1 md-card md-background--card md-grid md-cell md-cell--12 post" data-reactid="33"><section class="md-card-text post-body" data-reactid="34"><h1 class="md-display-2 post-header" data-reactid="35">LSTM neural network for sequence learning</h1><div class="post-info" data-reactid="36"><div class="md-card-title" data-reactid="37"><div class="md-inline-block md-avatar md-avatar--default md-avatar--card" data-reactid="38"><div class="md-avatar-content" data-reactid="39"><i class="md-icon fa fa-calendar" data-reactid="40"></i></div></div><div class="md-card-title--title-block md-card-title--one-line" data-reactid="41"><h2 class="md-card-title--title md-text" data-reactid="42">Published on 2017-11-26 22:00</h2><h3 class="md-card-title--title md-text--secondary" data-reactid="43">22 min read</h3></div></div><a class="category-link" href="/categories/artificial-intelligence" data-reactid="44"><div class="md-card-title" data-reactid="45"><div class="md-inline-block md-avatar md-avatar--default md-avatar--card" data-reactid="46"><div class="md-avatar-content" data-reactid="47"><i class="md-icon fa fa-folder-open" data-reactid="48"></i></div></div><div class="md-card-title--title-block md-card-title--one-line" data-reactid="49"><h2 class="md-card-title--title md-text" data-reactid="50">In category</h2><h3 class="md-card-title--title md-text--secondary" data-reactid="51">Artificial Intelligence</h3></div></div></a></div><div data-reactid="52"><script data-my-script="" type="text/javascript">requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>
<p>In 1996, during my last year in High School, I borrowed a book of a friend about neural networks. It explained how a two layer perceptron network could learn the XOR function. Back then I tried implementing the formulas and was able to do the feed-forward calculations. The training algorithm however still eluded me. Being able to perform forward calculations was already very exciting. I created a windows 95 screen save which would fill the screen with the output of a randomized neural network. The output images we're very interesting. Especially when replacing the activation functions of the network by exotic ones such as sin(x), abs(x) etc. (Although I lost the source code, you can still download it <a href="http://www.free-downloads-center.com/download/neural-screen-saver-v1-0-11252.html">here</a>)</p>
<p>At the time it seemed that Neural networks were just another statistical method to interpolate data. Furthermore limited training data and the problem of vanishing gradients limited their usefulness. Fast forward to 2017. Massive amounts of training data and computing power are available. A number of relatively small improvements in the basic neural network algorithms have made it possible to train networks consisting of many more layers. These so-called deep neural networks have fueled progress and interest in Artificial Intelligence development.</p>
<p>One particular innovation that caught my attention is the LSTM neural network architecture. This architecture solves the issue of vanishing gradients for Recurrent Neural Networks (RNN). LSTM networks are especially suited to perform analysis of sequences and time series. Some interesting links:</p>
<ul>
<li><a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">article about text generation kernel code</a></li>
<li><a href="https://larseidnes.com/2015/10/13/auto-generating-clickbait-with-recurrent-neural-networks/">fake news generator</a></li>
<li><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">LSTM architecture</a></li>
<li><a href="https://arxiv.org/pdf/1506.00019.pdf">LSTM explanation</a></li>
<li><a href="https://distill.pub/2016/augmented-rnns/">Modeling attention</a></li>
<li><a href="https://deepmind.com/blog/wavenet-generative-model-raw-audio/">Convolutional network for speech synthesis</a></li>
</ul>
<p>In this first test I wanted to experience implementing a sine wave predictor. using Tensor Flow. It's a toy example. Due to the periodic nature of the sine wave the train, dev, and test set overlap. This limits the possibilities to check if the network can generailize.  </p>
<p>This notebook can be <a href="https://raw.githubusercontent.com/dwjbosman/tensorflow-experiments/master/Sine_LSTM_batch_size.ipynb">downloaded</a> from my git repository.</p>
<div class="gatsby-highlight">
      <pre class="language-python"><code><span class="token keyword">import</span> plotly
<span class="token keyword">from</span> plotly<span class="token punctuation">.</span>graph_objs <span class="token keyword">import</span> Scatter<span class="token punctuation">,</span> Layout
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">import</span> sys
plotly<span class="token punctuation">.</span>offline<span class="token punctuation">.</span>init_notebook_mode<span class="token punctuation">(</span>connected<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">import</span> IPython<span class="token punctuation">.</span>display
</code></pre>
      </div>
<h2 id="training-data"><a href="#training-data" aria-hidden="true" class="anchor"><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Training data</h2>
<p>The following cell generates the training data. I decided to add some noise to the sine wave which forces some regularization.     </p>
<div class="gatsby-highlight">
      <pre class="language-python"><code>sample_length <span class="token operator">=</span> <span class="token number">50001</span>
time_per_sample <span class="token operator">=</span> <span class="token number">0.01</span>
signal_time <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span>num<span class="token operator">=</span>sample_length<span class="token punctuation">,</span>start <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> stop <span class="token operator">=</span> sample_length <span class="token operator">*</span> time_per_sample <span class="token punctuation">)</span>
signal_amp <span class="token operator">=</span> np<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>signal_time<span class="token operator">*</span><span class="token number">2</span><span class="token operator">*</span>np<span class="token punctuation">.</span>pi<span class="token punctuation">)</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span>size<span class="token operator">=</span>sample_length<span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">0.02</span>
    <span class="token comment">#np.sin(2+signal_time*1.7*np.pi)*0.5 + \</span>
    <span class="token comment">#np.sin(1+signal_time*2.2*np.pi) + \</span>
    
</code></pre>
      </div>
<div class="gatsby-highlight">
      <pre class="language-python"><code><span class="token comment">#plot part of the signal, just to see what's in there</span>
s_i <span class="token operator">=</span> <span class="token number">0</span>
e_i <span class="token operator">=</span> s_i <span class="token operator">+</span> <span class="token number">100</span>
x <span class="token operator">=</span> plotly<span class="token punctuation">.</span>offline<span class="token punctuation">.</span>iplot<span class="token punctuation">(</span><span class="token punctuation">{</span>
    <span class="token string">"data"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>Scatter<span class="token punctuation">(</span>x<span class="token operator">=</span>signal_time<span class="token punctuation">[</span>s_i<span class="token punctuation">:</span>e_i<span class="token punctuation">]</span><span class="token punctuation">,</span>y<span class="token operator">=</span>signal_amp<span class="token punctuation">[</span>s_i<span class="token punctuation">:</span>e_i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">"layout"</span><span class="token punctuation">:</span> Layout<span class="token punctuation">(</span>title<span class="token operator">=</span><span class="token string">""</span><span class="token punctuation">)</span>
    
<span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre>
      </div>
<div id="66a0fd2d-53a6-4c13-840c-4ab505be77c0" style="height: 525px; width: 100%;" class="plotly-graph-div"></div><script data-my-script="" type="text/javascript">require(["plotly"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL="https://plot.ly";Plotly.newPlot("66a0fd2d-53a6-4c13-840c-4ab505be77c0", [{"x": [0.0, 0.010000199999999999, 0.020000399999999998, 0.030000599999999995, 0.040000799999999996, 0.050001, 0.06000119999999999, 0.07000139999999999, 0.08000159999999999, 0.09000179999999999, 0.100002, 0.1100022, 0.12000239999999998, 0.1300026, 0.14000279999999998, 0.150003, 0.16000319999999998, 0.17000339999999997, 0.18000359999999999, 0.19000379999999997, 0.200004, 0.21000419999999997, 0.2200044, 0.23000459999999998, 0.24000479999999996, 0.250005, 0.2600052, 0.27000539999999995, 0.28000559999999997, 0.2900058, 0.300006, 0.31000619999999995, 0.32000639999999997, 0.3300066, 0.34000679999999994, 0.35000699999999996, 0.36000719999999997, 0.3700074, 0.38000759999999995, 0.39000779999999996, 0.400008, 0.41000819999999993, 0.42000839999999995, 0.43000859999999996, 0.4400088, 0.45000899999999994, 0.46000919999999995, 0.47000939999999997, 0.4800095999999999, 0.49000979999999994, 0.50001, 0.5100102, 0.5200104, 0.5300106, 0.5400107999999999, 0.5500109999999999, 0.5600111999999999, 0.5700114, 0.5800116, 0.5900118, 0.600012, 0.6100121999999999, 0.6200123999999999, 0.6300125999999999, 0.6400127999999999, 0.650013, 0.6600132, 0.6700134, 0.6800135999999999, 0.6900137999999999, 0.7000139999999999, 0.7100141999999999, 0.7200143999999999, 0.7300146, 0.7400148, 0.7500149999999999, 0.7600151999999999, 0.7700153999999999, 0.7800155999999999, 0.7900157999999999, 0.800016, 0.8100162, 0.8200163999999999, 0.8300165999999999, 0.8400167999999999, 0.8500169999999999, 0.8600171999999999, 0.8700173999999999, 0.8800176, 0.8900177999999999, 0.9000179999999999, 0.9100181999999999, 0.9200183999999999, 0.9300185999999999, 0.9400187999999999, 0.950019, 0.9600191999999999, 0.9700193999999999, 0.9800195999999999, 0.9900197999999999], "type": "scatter", "y": [-0.009999358952767035, 0.0636596725936513, 0.09396539891340987, 0.18736083188739677, 0.24554522107360244, 0.30474662791998464, 0.3540644715650535, 0.427310695217905, 0.5082610045992348, 0.528743319714693, 0.610873715328187, 0.6595808302414805, 0.6714801770744819, 0.7161724630504367, 0.8017361218478947, 0.8227584059757931, 0.8339431865355841, 0.8589156197859245, 0.9032790012741199, 0.9277440963860971, 0.944348827684898, 0.9550259159741353, 0.9939331935171848, 0.9953889438631083, 1.031895777398816, 0.991926769744457, 1.008018984611331, 0.9898874568317324, 0.9660036288267146, 0.9778216806047674, 0.9427574719479263, 0.9160079988143766, 0.903887727996592, 0.9011663035689388, 0.8367907573153219, 0.8260939809053769, 0.7683508266691262, 0.7234202492635545, 0.7121569782970198, 0.6213383920442218, 0.5786361839359868, 0.5380777310192311, 0.46138829067940923, 0.4441318595463302, 0.34964272800620694, 0.3233662082126278, 0.24534658923290942, 0.18524150173515894, 0.12375363227000283, 0.04747565849617937, -0.0037387080934477928, -0.051743377712968094, -0.15214920425224088, -0.19449442529116476, -0.26660097990763254, -0.32123644885610925, -0.38842565077399277, -0.441144767589916, -0.48607544550013165, -0.524011507610602, -0.5891608717435157, -0.6453265897593556, -0.6902171009691433, -0.7271350896313418, -0.7695574187711549, -0.8019483627796674, -0.8705328832225805, -0.8882826334487386, -0.941180390156566, -0.9078491448280709, -0.9832570314642423, -0.942594348092753, -0.9894904989827801, -1.033150433359927, -0.9886850624679566, -1.0280845624475607, -1.0089557387836479, -0.9901244244917171, -0.9947835829309849, -0.9469085583633676, -0.928849321496094, -0.9595811107489216, -0.899135580368624, -0.904911369504552, -0.8489143109698182, -0.7904224335162588, -0.7793467872833741, -0.7288845420182568, -0.6813326718442346, -0.6342428891149459, -0.5838042233620713, -0.5394518302446045, -0.49395160308410146, -0.43786637091879443, -0.3736342591485493, -0.3050754102189696, -0.23006119896148175, -0.15796119062894998, -0.13899400784200322, -0.07349763188343796]}], {"title": ""}, {"showLink": true, "linkText": "Export to plot.ly"})});</script>
<div class="gatsby-highlight">
      <pre class="language-python"><code><span class="token comment">#Setup general  hyper parameters</span>

<span class="token comment">#Unroll the RNN to sequence_length timesteps</span>
sequence_length <span class="token operator">=</span> <span class="token number">100</span>
<span class="token comment">#The number timesteps to predict</span>
prediction_length <span class="token operator">=</span> <span class="token number">1</span>
<span class="token comment">#The number of features per input time step</span>
input_feature_count <span class="token operator">=</span> <span class="token number">1</span>
<span class="token comment">#The number of featuers per prediction</span>
output_feature_count <span class="token operator">=</span> <span class="token number">1</span>

<span class="token comment">#the number of LSTM nodes per layer of the network</span>
hidden_count_per_layer <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">]</span>

tf<span class="token punctuation">.</span>reset_default_graph<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment">#inputs is a vector of (batch_size, sequence_length, feature_count)</span>
inputs <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> 
                        <span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> sequence_length<span class="token punctuation">,</span> input_feature_count<span class="token punctuation">]</span><span class="token punctuation">,</span> 
                        name <span class="token operator">=</span> <span class="token string">'inputs'</span><span class="token punctuation">)</span>
<span class="token comment">#targets will be an example to train. </span>
<span class="token comment">#It will be filled with the value of the next time step. </span>
<span class="token comment">#Size (batch_size, feature count)</span>
targets <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> 
                         <span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> output_feature_count<span class="token punctuation">]</span><span class="token punctuation">,</span> 
                         name <span class="token operator">=</span> <span class="token string">'targets'</span><span class="token punctuation">)</span>
<span class="token comment">#Apply drop out regularization with a a probability of keep_prob </span>
<span class="token comment">#to keep a connection </span>
keep_prob <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> name <span class="token operator">=</span> <span class="token string">'keep'</span><span class="token punctuation">)</span>
<span class="token comment">#Used a learning rate for AdamOptimzer</span>
learning_rate <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> name <span class="token operator">=</span> <span class="token string">'learning_rate'</span><span class="token punctuation">)</span>
</code></pre>
      </div>
<h2 id="defining-the-lstm-multi-layer-network"><a href="#defining-the-lstm-multi-layer-network" aria-hidden="true" class="anchor"><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Defining the LSTM multi layer network</h2>
<p>Define a network by creating a number of layers. In most examples I found all layers used equal node counts. In this example you can specify the number of neurons per layer through the 'hidden<em>count</em>per_layer' array.</p>
<div class="gatsby-highlight">
      <pre class="language-python"><code>layers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>


<span class="token keyword">for</span> hidden_count <span class="token keyword">in</span> hidden_count_per_layer<span class="token punctuation">:</span>
    layer <span class="token operator">=</span>  tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>rnn_cell<span class="token punctuation">.</span>LSTMCell<span class="token punctuation">(</span>hidden_count<span class="token punctuation">,</span> state_is_tuple <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
    layer_with_dropout <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>rnn_cell<span class="token punctuation">.</span>DropoutWrapper<span class="token punctuation">(</span>layer<span class="token punctuation">,</span>
                                          input_keep_prob<span class="token operator">=</span>keep_prob<span class="token punctuation">,</span>
                                          output_keep_prob<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span>
    layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>layer<span class="token punctuation">)</span>
hidden_network <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>rnn_cell<span class="token punctuation">.</span>MultiRNNCell<span class="token punctuation">(</span>layers<span class="token punctuation">,</span> state_is_tuple <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>   
</code></pre>
      </div>
<h2 id="packingunpacking-the-lstm-network-state"><a href="#packingunpacking-the-lstm-network-state" aria-hidden="true" class="anchor"><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Packing/Unpacking the LSTM network state</h2>
<p>'state<em>is</em>tuple = True' means that the LSTM State data structure will be a Tuple. Although inconvenient to work with this seems to be the future default. I will introduce some functions which help to work more easily with these state tuples. </p>
<p>In order to use the LSTM network to generate a predicted sequence of arbitrary length you need to store the state of the network. The output state after predicting a sample should be fed back in to the network when predicting the next sample.</p>
<p>The LSTM implementation in Tensor flow uses a LSTMStateTuple(c,h) data structure. The idea is to pack this LSTMStateTuple(c,h) into a 2D vector of size (batch_size, states). </p>
<p>There were some challenges implementing these packing/unpacking functions. Especially you want to avoid them beeing dependent on a specific batch<em>size. During building of the computation graph the batch</em>size should be None.</p>
<p>There is a pointer on how to use dynamic batch_sizes and packing/unpacking states <a href="https://stackoverflow.com/questions/40438107/tensorflow-changing-batch-size-for-rnn-during-text-generation">here</a>. I made some changes to clarify these functions. </p>
<div class="gatsby-highlight">
      <pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">get_network_state_size</span><span class="token punctuation">(</span>network<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Returns the number of states variables in the network"""</span>
    states <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> layer_size <span class="token keyword">in</span> hidden_network<span class="token punctuation">.</span>state_size<span class="token punctuation">:</span>
        states <span class="token operator">+=</span> layer_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token comment"># LSTMState tuple element c</span>
        states <span class="token operator">+=</span> layer_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token comment"># LSTMState tuple element h</span>
    <span class="token keyword">return</span> states
</code></pre>
      </div>
<div class="gatsby-highlight">
      <pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">pack_state_tuple</span><span class="token punctuation">(</span>state_tuple<span class="token punctuation">,</span> indent<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Returns a (batch_size,network_state_size) matrix of the states in the network
        state_tupel = the states obtained from  _ , state = tf.nn.dynamic_rnn(...)
    """</span>
    <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>state_tuple<span class="token punctuation">,</span> tf<span class="token punctuation">.</span>Tensor<span class="token punctuation">)</span> <span class="token operator">or</span> <span class="token operator">not</span> <span class="token builtin">hasattr</span><span class="token punctuation">(</span>state_tuple<span class="token punctuation">,</span> <span class="token string">'__iter__'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment">#The LSTMSTateTuple contains 2 Tensors</span>
        <span class="token keyword">return</span> state_tuple
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        l <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token comment">#an unpacked LSTM network is tuple of layer size, each element of the tuple is an LSTMStateTuple</span>
        <span class="token comment">#state_tupel is either the tuple of LSTMStateTuples or it is a LSTMSTateTuple (via recursive call)</span>
        <span class="token keyword">for</span> item <span class="token keyword">in</span> state_tuple<span class="token punctuation">:</span>
            <span class="token comment"># item is either an LSTMStateTuple (top level call)</span>
            <span class="token comment"># or it is an element of the LSTMStateTuple (first recursive call)</span>
            i <span class="token operator">=</span> pack_state_tuple<span class="token punctuation">(</span>item<span class="token punctuation">,</span> indent<span class="token operator">+</span><span class="token number">2</span><span class="token punctuation">)</span>
            l<span class="token punctuation">.</span>append<span class="token punctuation">(</span>i<span class="token punctuation">)</span>
        
        <span class="token comment">#convert the list of [Tensor(bsz,a), Tensor(bsz,b), ...] Into one long Tensor (bsz, a-b-c-...)</span>
        <span class="token keyword">return</span> tf<span class="token punctuation">.</span>concat<span class="token punctuation">(</span>l<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
    
</code></pre>
      </div>
<div class="gatsby-highlight">
      <pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">unpack_state_tuple</span><span class="token punctuation">(</span>state_tensor<span class="token punctuation">,</span> sizes<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""The inverse of pack, given a packed_states vector of (batch_size,x) return the LSTMStateTuple 
    datastructure that can be used as initial state for tf.nn.dynamic_rnn(...) 
        sizes is the network state size list (cell.state_size)
    """</span>

    <span class="token keyword">def</span> <span class="token function">_unpack_state_tuple</span><span class="token punctuation">(</span> sizes_<span class="token punctuation">,</span> offset_<span class="token punctuation">,</span> indent<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>sizes_<span class="token punctuation">,</span> tf<span class="token punctuation">.</span>Tensor<span class="token punctuation">)</span> <span class="token operator">or</span> <span class="token operator">not</span> <span class="token builtin">hasattr</span><span class="token punctuation">(</span>sizes_<span class="token punctuation">,</span> <span class="token string">'__iter__'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> 
            <span class="token comment">#get a small part (batch size, c or h size of LSTMStateTuple) of the packed state vector of shape (batch size, network states)</span>
            <span class="token keyword">return</span> tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>state_tensor<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> offset_ <span class="token punctuation">:</span> <span class="token punctuation">(</span>offset_ <span class="token operator">+</span> sizes_<span class="token punctuation">)</span> <span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> sizes_<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> offset_ <span class="token operator">+</span> sizes_
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            result <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
            <span class="token comment">#Top level: sizes is a tuple of size network layers, each element of the tuple is an LSTMStateTuple(c size, h size)</span>
            <span class="token comment">#Recursive call: sizes_ is a LSTMStateTuple</span>
            <span class="token keyword">for</span> size <span class="token keyword">in</span> sizes_<span class="token punctuation">:</span>
                <span class="token comment">#size is an LSTMStateTuple (toplevel)</span>
                <span class="token comment">#or size is c size or h size (recursive call)</span>
                s<span class="token punctuation">,</span> offset_ <span class="token operator">=</span> _unpack_state_tuple<span class="token punctuation">(</span> size<span class="token punctuation">,</span> offset_<span class="token punctuation">,</span> indent<span class="token operator">+</span><span class="token number">2</span><span class="token punctuation">)</span>
                result<span class="token punctuation">.</span>append<span class="token punctuation">(</span>s<span class="token punctuation">)</span>
            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>sizes_<span class="token punctuation">,</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>rnn_cell<span class="token punctuation">.</span>LSTMStateTuple<span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token comment">#end of recursive call</span>
                <span class="token comment">#Build a LSTMStateTuple using the c size and h size elements in the result list</span>
                <span class="token keyword">return</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>rnn_cell<span class="token punctuation">.</span>LSTMStateTuple<span class="token punctuation">(</span><span class="token operator">*</span>result<span class="token punctuation">)</span><span class="token punctuation">,</span> offset_
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                <span class="token comment"># end of toplevel call</span>
                <span class="token comment"># create a tuple of size network layers. Result is a list of LSTMStateTuple</span>
                <span class="token keyword">return</span> <span class="token builtin">tuple</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span><span class="token punctuation">,</span> offset_
    <span class="token keyword">return</span> _unpack_state_tuple<span class="token punctuation">(</span> sizes<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
</code></pre>
      </div>
<h3 id="testing-the-packingunpacking-functions"><a href="#testing-the-packingunpacking-functions" aria-hidden="true" class="anchor"><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Testing the packing/unpacking functions</h3>
<p>Next I wrote a check to see if the pack and unpack functions are indeed each others inverse. The vectors should be packed/unpacked in the correct order. The idea is to create 'packed' vector containing the values 0..n. Then unpack and repack. The output value should be equal to the original vector. </p>
<div class="gatsby-highlight">
      <pre class="language-python"><code><span class="token comment">#Test pack and unpack</span>

<span class="token comment">#create a placeholder in which we can feeisd packed states (vector of (batch_size, states) as initial_state</span>
state_packed_in <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>
    tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> 
    <span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span>get_network_state_size<span class="token punctuation">(</span>hidden_network<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
    name<span class="token operator">=</span><span class="token string">"state_packed_1"</span><span class="token punctuation">)</span>


<span class="token comment">#Unpack the packed states</span>
state_unpacked_out <span class="token operator">=</span> unpack_state_tuple<span class="token punctuation">(</span>state_packed_in<span class="token punctuation">,</span>hidden_network<span class="token punctuation">.</span>state_size<span class="token punctuation">)</span>
<span class="token comment">#Repack the unpacked states</span>
state_packed_out <span class="token operator">=</span> pack_state_tuple<span class="token punctuation">(</span>state_unpacked_out<span class="token punctuation">)</span>


inputs_batch_size <span class="token operator">=</span> <span class="token number">40</span>
a_batch_of_inputs <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>inputs_batch_size<span class="token punctuation">,</span> sequence_length<span class="token punctuation">,</span> input_feature_count<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">#create an initial state vector and fill it with test data</span>
an_initial_state <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>inputs_batch_size<span class="token operator">*</span>get_network_state_size<span class="token punctuation">(</span>hidden_network<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
an_initial_state<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span>start<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>stop<span class="token operator">=</span>an_initial_state<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>num<span class="token operator">=</span>an_initial_state<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment">#reshape it as an packed state </span>
an_initial_state_packed <span class="token operator">=</span> np<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>an_initial_state<span class="token punctuation">,</span> <span class="token punctuation">(</span>inputs_batch_size<span class="token punctuation">,</span>get_network_state_size<span class="token punctuation">(</span>hidden_network<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>


init<span class="token operator">=</span>tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">with</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> sess<span class="token punctuation">:</span>
    sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>init<span class="token punctuation">)</span>
    up<span class="token punctuation">,</span>p <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token punctuation">[</span>state_unpacked_out<span class="token punctuation">,</span> state_packed_out<span class="token punctuation">]</span><span class="token punctuation">,</span>  feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>state_packed_in<span class="token punctuation">:</span> an_initial_state_packed<span class="token punctuation">}</span><span class="token punctuation">)</span>
    <span class="token comment"># compare the original packed states with the ones the were unpacked and then repacked</span>
    diff <span class="token operator">=</span> an_initial_state_packed <span class="token operator">-</span> p
    <span class="token comment"># should return 0</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"diff"</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>diff<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
      </div>
<div class="gatsby-highlight">
      <pre class="language-none"><code>diff 0.0</code></pre>
      </div>
<h2 id="initial-state"><a href="#initial-state" aria-hidden="true" class="anchor"><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Initial state</h2>
<p>Create a placeholder for initial packed states. This makes it possible to supply the initial states to the LSTM network as a simple vector. Then add a unpack operation to the computation graph. This outputs the initial state as a LSTMTuple vector which can be used by the dynamic RNN function later on.</p>
<div class="gatsby-highlight">
      <pre class="language-python"><code>sz <span class="token operator">=</span> get_network_state_size<span class="token punctuation">(</span>hidden_network<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"states in network"</span><span class="token punctuation">,</span> sz<span class="token punctuation">)</span>


initial_state_packed <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>
    tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> 
    <span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span>sz<span class="token punctuation">)</span><span class="token punctuation">,</span> 
    name<span class="token operator">=</span><span class="token string">"initial_state"</span><span class="token punctuation">)</span>

state_unpacked <span class="token operator">=</span> unpack_state_tuple<span class="token punctuation">(</span>initial_state_packed<span class="token punctuation">,</span>hidden_network<span class="token punctuation">.</span>state_size<span class="token punctuation">)</span>
</code></pre>
      </div>
<div class="gatsby-highlight">
      <pre class="language-none"><code>states in network 64</code></pre>
      </div>
<h2 id="forward-propagation"><a href="#forward-propagation" aria-hidden="true" class="anchor"><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Forward propagation</h2>
<p>Define the forward calculations by using the dynamic_rnn function. This function needs and outputs the network states in unpacked format. </p>
<div class="gatsby-highlight">
      <pre class="language-python"><code><span class="token comment">#out_weights=tf.Variable(tf.random_normal([hidden_count_per_layer[-1],output_feature_count]))</span>
<span class="token comment">#out_bias=tf.Variable(tf.random_normal([output_feature_count]))</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"inputs "</span><span class="token punctuation">,</span>inputs<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
outputs<span class="token punctuation">,</span> state_unpacked_network_out <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>dynamic_rnn<span class="token punctuation">(</span>hidden_network<span class="token punctuation">,</span> inputs<span class="token punctuation">,</span> initial_state <span class="token operator">=</span> state_unpacked<span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span> <span class="token comment">#, initial_state=rnn_tuple_state, )</span>
state_packed_network_out <span class="token operator">=</span> pack_state_tuple<span class="token punctuation">(</span>state_unpacked_network_out<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"packed state"</span><span class="token punctuation">,</span> state_packed_network_out<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"outputs before transpose"</span><span class="token punctuation">,</span> outputs<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
outputs <span class="token operator">=</span> tf<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"outputs after transpose"</span><span class="token punctuation">,</span> outputs<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token comment">#last_output = tf.gather(outputs, int(outputs.get_shape()[0]) - 1)</span>
last_output <span class="token operator">=</span>  outputs<span class="token punctuation">[</span>outputs<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"last output"</span><span class="token punctuation">,</span> last_output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
                                   
<span class="token comment">#out_size = target.get_shape()[2].value</span>
predictions <span class="token operator">=</span> tf<span class="token punctuation">.</span>contrib<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>fully_connected<span class="token punctuation">(</span>last_output<span class="token punctuation">,</span> output_feature_count<span class="token punctuation">,</span> activation_fn<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"prediction"</span><span class="token punctuation">,</span> predictions<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"targets"</span><span class="token punctuation">,</span> targets<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre>
      </div>
<div class="gatsby-highlight">
      <pre class="language-none"><code>inputs  (?, 100, 1)
packed state (?, 64)
outputs before transpose (?, 100, 16)
outputs after transpose (100, ?, 16)
last output (?, 16)
prediction (?, 1)
targets (?, 1)</code></pre>
      </div>
<h2 id="backward-pass-training"><a href="#backward-pass-training" aria-hidden="true" class="anchor"><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Backward pass, training</h2>
<p>Define the loss as the total of the squared differences between the the last output (prediction) and the target. </p>
<div class="gatsby-highlight">
      <pre class="language-python"><code>loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>squared_difference<span class="token punctuation">(</span>predictions<span class="token punctuation">,</span> targets<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
      </div>
<div class="gatsby-highlight">
      <pre class="language-python"><code>opt<span class="token operator">=</span>tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>AdamOptimizer<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span><span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>
</code></pre>
      </div>
<h2 id="defining-the-train-dev-and-test-set"><a href="#defining-the-train-dev-and-test-set" aria-hidden="true" class="anchor"><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Defining the train, dev and test set</h2>
<p>Generally you would define 3 sets:</p>
<ul>
<li>A set to train on: Train set</li>
<li>A set to tune the hyper parameters on: Dev set</li>
<li>A set to test the generalization performance of the network: Test set</li>
</ul>
<p>In the case of sine wave this is a bit useless. The dev set and test set overlap because of the periodic nature of the sine wave. I added noise to the source signal to make the train, dev and test set at least partly independent.</p>
<div class="gatsby-highlight">
      <pre class="language-python"><code>start_indices <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span>
    <span class="token number">0</span><span class="token punctuation">,</span>
    sample_length<span class="token operator">-</span>sequence_length<span class="token operator">-</span>prediction_length<span class="token number">-1</span><span class="token punctuation">,</span>
    sample_length<span class="token operator">-</span>sequence_length<span class="token operator">-</span>prediction_length<span class="token number">-1</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span> np<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>

<span class="token comment">#When you have many examples then you can get away with tiny sizes for the dev and test set.</span>
dev_size_perc <span class="token operator">=</span> <span class="token number">0.20</span>
test_size_perc <span class="token operator">=</span> <span class="token number">0.20</span>
batch_size <span class="token operator">=</span> <span class="token number">128</span> <span class="token comment">#512 </span>

dev_size <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>floor<span class="token punctuation">(</span>start_indices<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> dev_size_perc<span class="token punctuation">)</span><span class="token punctuation">)</span>
test_size  <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>floor<span class="token punctuation">(</span>start_indices<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> test_size_perc<span class="token punctuation">)</span><span class="token punctuation">)</span>
train_size <span class="token operator">=</span> start_indices<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">-</span> test_size <span class="token operator">-</span> dev_size
train_batch_count <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>floor<span class="token punctuation">(</span>train_size <span class="token operator">/</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
dev_batch_count <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>floor<span class="token punctuation">(</span>dev_size <span class="token operator">/</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
test_batch_count <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>floor<span class="token punctuation">(</span>test_size <span class="token operator">/</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"dataset size %d"</span> <span class="token operator">%</span><span class="token punctuation">(</span>start_indices<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"%d Examples (%d batches) in train set"</span> <span class="token operator">%</span><span class="token punctuation">(</span>train_size<span class="token punctuation">,</span> train_batch_count<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"%d Examples (%d batches) in dev set"</span> <span class="token operator">%</span><span class="token punctuation">(</span>dev_size<span class="token punctuation">,</span>dev_batch_count<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"%d Examples (%d batches) in test set"</span> <span class="token operator">%</span><span class="token punctuation">(</span>test_size<span class="token punctuation">,</span>test_batch_count<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
      </div>
<div class="gatsby-highlight">
      <pre class="language-none"><code>dataset size 49899
29941 Examples (233 batches) in train set
9979 Examples (77 batches) in dev set
9979 Examples (77 batches) in test set</code></pre>
      </div>
<h2 id="creating-batches"><a href="#creating-batches" aria-hidden="true" class="anchor"><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Creating batches</h2>
<p>The network will be trained using mini batches. This speeds up training because a network training step is performed after each mini batch in contrast to updating after presenting the complete training set.</p>
<div class="gatsby-highlight">
      <pre class="language-python"><code><span class="token comment">#A batch of examples can start at an arbitrary index in the source signal. </span>
<span class="token comment"># Shuffle the indices to fill the train. dev and test set with different sequences</span>

np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>shuffle <span class="token punctuation">(</span>start_indices<span class="token punctuation">)</span>
train_indices <span class="token operator">=</span> start_indices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token builtin">int</span><span class="token punctuation">(</span>train_size<span class="token punctuation">)</span><span class="token punctuation">]</span>
dev_indices<span class="token operator">=</span> start_indices<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>train_size<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token builtin">int</span><span class="token punctuation">(</span>train_size<span class="token operator">+</span>dev_size<span class="token punctuation">)</span><span class="token punctuation">]</span>
test_indices <span class="token operator">=</span> start_indices<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>train_size<span class="token operator">+</span>dev_size<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token builtin">int</span><span class="token punctuation">(</span>train_size<span class="token operator">+</span>dev_size<span class="token operator">+</span>test_size<span class="token punctuation">)</span><span class="token punctuation">]</span>

<span class="token keyword">def</span> <span class="token function">get_batch</span><span class="token punctuation">(</span>batch_index<span class="token punctuation">,</span> indexes<span class="token punctuation">,</span> size<span class="token operator">=</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    batch_start_indexes <span class="token operator">=</span> indexes<span class="token punctuation">[</span>batch_index<span class="token operator">*</span>size<span class="token punctuation">:</span>batch_index<span class="token operator">*</span>size<span class="token operator">+</span>size<span class="token punctuation">]</span>
    batch_inputs <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>size<span class="token punctuation">,</span>sequence_length<span class="token punctuation">,</span> input_feature_count<span class="token punctuation">)</span><span class="token punctuation">)</span>
    batch_targets <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>size<span class="token punctuation">,</span>prediction_length<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        se <span class="token operator">=</span> batch_start_indexes<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
        part <span class="token operator">=</span> signal_amp<span class="token punctuation">[</span>se<span class="token punctuation">:</span>se<span class="token operator">+</span>sequence_length<span class="token punctuation">]</span>
        batch_inputs<span class="token punctuation">[</span>i<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">:</span>sequence_length<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> part
        batch_targets<span class="token punctuation">[</span>i<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> signal_amp<span class="token punctuation">[</span>se<span class="token operator">+</span>sequence_length<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span>

    <span class="token keyword">return</span> batch_inputs<span class="token punctuation">,</span>batch_targets

batch_inputs<span class="token punctuation">,</span>batch_targets <span class="token operator">=</span> get_batch<span class="token punctuation">(</span>train_batch_count<span class="token number">-1</span><span class="token punctuation">,</span>train_indices<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>batch_inputs<span class="token punctuation">.</span>shape<span class="token punctuation">,</span>batch_targets<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

example_inputs <span class="token operator">=</span> batch_inputs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
example_targets <span class="token operator">=</span>  batch_targets<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>example_inputs<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

<span class="token comment">#plot a single example</span>
b_i <span class="token operator">=</span> <span class="token number">1</span>
b_s <span class="token operator">=</span> batch_inputs<span class="token punctuation">[</span>b_i<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">:</span>sequence_length<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span>
plotly<span class="token punctuation">.</span>offline<span class="token punctuation">.</span>iplot<span class="token punctuation">(</span><span class="token punctuation">{</span>
    <span class="token string">"data"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>Scatter<span class="token punctuation">(</span>y<span class="token operator">=</span>b_s<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">"layout"</span><span class="token punctuation">:</span> Layout<span class="token punctuation">(</span>title<span class="token operator">=</span><span class="token string">""</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre>
      </div>
<div class="gatsby-highlight">
      <pre class="language-none"><code>(128, 100, 1) (128, 1)
(100, 1)</code></pre>
      </div>
<div id="87475023-6910-45cc-bcb2-6c88962db2b2" style="height: 525px; width: 100%;" class="plotly-graph-div"></div><script data-my-script="" type="text/javascript">require(["plotly"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL="https://plot.ly";Plotly.newPlot("87475023-6910-45cc-bcb2-6c88962db2b2", [{"type": "scatter", "y": [0.25586661578062775, 0.2113902778682897, 0.1275118204883805, 0.06328061795923293, 0.0025380759035408106, -0.042139754445326714, -0.10724852835645043, -0.14661883556485647, -0.2623907446643743, -0.292931513325702, -0.33224915498115193, -0.41104824477110735, -0.4346793915154579, -0.5333705254046659, -0.5821664718161046, -0.6093779725070855, -0.6481005852724403, -0.7295331653603472, -0.7287415260439547, -0.8040143490229175, -0.8556579784536297, -0.8521535015942178, -0.8682193632268257, -0.9201712034896309, -0.9522706423497216, -0.9356716037774885, -0.9954595265343607, -0.9509569237274775, -0.9852313501079415, -0.9964143379548179, -0.983716834683751, -0.9940044131736233, -0.9935934662936032, -0.9596059778107673, -1.0327593153162633, -0.9379936804318362, -0.9418303022300529, -0.864874000188041, -0.8296578849855012, -0.7827595897627194, -0.7603092238080611, -0.7329860959434612, -0.6795443712962281, -0.638720720811216, -0.6344464917480599, -0.5351437580278402, -0.5069750751946241, -0.43592801418367527, -0.42553010705565747, -0.3260004392940707, -0.2337441453861695, -0.1912857401151467, -0.14310463979031995, -0.08443700533995716, -0.022909731499399386, 0.08680612428794507, 0.1205938365989491, 0.16986562303647462, 0.2207759453286145, 0.33245444640441263, 0.3450980717833889, 0.41158331241583473, 0.5121225114498174, 0.5548016799408272, 0.5847807549267087, 0.6389404755722021, 0.6984125713050864, 0.705760382413495, 0.7732287045798187, 0.7989972621414547, 0.8330600711854514, 0.8750351317908898, 0.8828714219736365, 0.9104599887408784, 0.9090238136663011, 0.989626996181425, 0.9529198495236159, 1.009809262811336, 0.9941091556245714, 1.0003176110163716, 1.016612328322244, 1.0160242423888497, 1.0105604882364612, 0.9705401299558875, 0.949562062482992, 0.9505571284343388, 0.9219776749920697, 0.889598781529184, 0.8647821311630576, 0.795138421281014, 0.7751283722862748, 0.7249610450688796, 0.6806197233982677, 0.6422932807599323, 0.5989253068423827, 0.5409844046117515, 0.49720280800050387, 0.44628772874849854, 0.3779544914735879, 0.3375525617282487]}], {"title": ""}, {"showLink": true, "linkText": "Export to plot.ly"})});</script>
<h2 id="test-training-using-a-single-batch"><a href="#test-training-using-a-single-batch" aria-hidden="true" class="anchor"><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Test training using a single batch</h2>
<p>In the next cell I check if I can train the network on one single batch. Just to check if the optimizer is indeed able to train the network. Successful training should decrease the loss. In the output you will see the loss decreasing (first column)</p>
<div class="gatsby-highlight">
      <pre class="language-python"><code>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>shuffle <span class="token punctuation">(</span>start_indices<span class="token punctuation">)</span>
train_indices <span class="token operator">=</span> start_indices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token builtin">int</span><span class="token punctuation">(</span>train_size<span class="token punctuation">)</span><span class="token punctuation">]</span>
dev_indices<span class="token operator">=</span> start_indices<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>train_size<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token builtin">int</span><span class="token punctuation">(</span>train_size<span class="token operator">+</span>dev_size<span class="token punctuation">)</span><span class="token punctuation">]</span>
test_indices <span class="token operator">=</span> start_indices<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>train_size<span class="token operator">+</span>dev_size<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token builtin">int</span><span class="token punctuation">(</span>train_size<span class="token operator">+</span>dev_size<span class="token operator">+</span>test_size<span class="token punctuation">)</span><span class="token punctuation">]</span>

zero_state_packed <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> get_network_state_size<span class="token punctuation">(</span>hidden_network<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>


init<span class="token operator">=</span>tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">with</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> sess<span class="token punctuation">:</span>
    sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>init<span class="token punctuation">)</span>

    np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>shuffle <span class="token punctuation">(</span>train_indices<span class="token punctuation">)</span>
    
    batch_inputs<span class="token punctuation">,</span>batch_targets <span class="token operator">=</span> get_batch<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> train_indices<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"batch input shape"</span><span class="token punctuation">,</span> batch_inputs<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    <span class="token comment">#v_outputs, v_state = sess.run([outputs,state], feed_dict={inputs: batch_inputs, targets: batch_targets})</span>
    v_predictions<span class="token punctuation">,</span> v_state_unpacked <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token punctuation">[</span>predictions<span class="token punctuation">,</span> state_unpacked_network_out<span class="token punctuation">]</span><span class="token punctuation">,</span> 
                                      feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>
                                          inputs<span class="token punctuation">:</span> batch_inputs<span class="token punctuation">,</span> 
                                          targets<span class="token punctuation">:</span> batch_targets<span class="token punctuation">,</span>
                                          initial_state_packed<span class="token punctuation">:</span> zero_state_packed
                                      <span class="token punctuation">}</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>v_predictions<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>v_predictions<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>batch_targets<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">120</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        v_predictions<span class="token punctuation">,</span> v_outputs<span class="token punctuation">,</span> v_state_unpacked<span class="token punctuation">,</span> v_loss<span class="token punctuation">,</span> v_opt <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>
            <span class="token punctuation">[</span>predictions<span class="token punctuation">,</span> outputs<span class="token punctuation">,</span> state_unpacked_network_out<span class="token punctuation">,</span> loss<span class="token punctuation">,</span> opt<span class="token punctuation">]</span><span class="token punctuation">,</span> 
            feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>
                learning_rate<span class="token punctuation">:</span> <span class="token number">0.02</span><span class="token punctuation">,</span> 
                inputs<span class="token punctuation">:</span> batch_inputs<span class="token punctuation">,</span> 
                targets<span class="token punctuation">:</span> batch_targets<span class="token punctuation">,</span>
                state_unpacked<span class="token punctuation">:</span> v_state_unpacked
            <span class="token punctuation">}</span><span class="token punctuation">)</span> <span class="token comment">#})</span>
        <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">10</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span>v_loss<span class="token punctuation">,</span>v_predictions<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>batch_targets<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
 

    
    
</code></pre>
      </div>
<div class="gatsby-highlight">
      <pre class="language-none"><code>batch input shape (128, 100, 1)
(128, 1)
[ 0.04703456] [-0.66767944]
69.1535 [ 0.04703381] [-0.66767944]
2.39038 [-0.71438432] [-0.66767944]
0.769588 [-0.72163767] [-0.66767944]
0.238517 [-0.71686089] [-0.66767944]
0.133357 [-0.67176348] [-0.66767944]
0.130659 [-0.67786527] [-0.66767944]
0.102174 [-0.66787326] [-0.66767944]
0.0939764 [-0.68473738] [-0.66767944]
0.0897313 [-0.6789692] [-0.66767944]
0.0882396 [-0.6785149] [-0.66767944]
0.0865416 [-0.68145192] [-0.66767944]
0.0851147 [-0.67975515] [-0.66767944]</code></pre>
      </div>
<h2 id="training-and-testing"><a href="#training-and-testing" aria-hidden="true" class="anchor"><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Training and Testing</h2>
<p>Finally we can train and test the network. The training consists of 'epochs' during which all training batches are presented. After presenting a single training batch the network is immediately optimized. After an epoch the loss is calculated over the dev set and printed. </p>
<p>Next a graph is plotted which shows an example of the network predicting a sine wave. The prediction is based on first 'priming' the network by presenting part of a sine. </p>
<p>After completing training on a number of epochs. The last predictions is executed over a longer time period.</p>
<div class="gatsby-highlight">
      <pre class="language-python"><code>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>shuffle <span class="token punctuation">(</span>start_indices<span class="token punctuation">)</span>

<span class="token comment">#create a randomized train, dev and test set</span>
train_indices <span class="token operator">=</span> start_indices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token builtin">int</span><span class="token punctuation">(</span>train_size<span class="token punctuation">)</span><span class="token punctuation">]</span>
dev_indices<span class="token operator">=</span> start_indices<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>train_size<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token builtin">int</span><span class="token punctuation">(</span>train_size<span class="token operator">+</span>dev_size<span class="token punctuation">)</span><span class="token punctuation">]</span>
test_indices <span class="token operator">=</span> start_indices<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>train_size<span class="token operator">+</span>dev_size<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token builtin">int</span><span class="token punctuation">(</span>train_size<span class="token operator">+</span>dev_size<span class="token operator">+</span>test_size<span class="token punctuation">)</span><span class="token punctuation">]</span>


<span class="token comment">#initialization of the network states for a single mini batch, by setting them to zero</span>
<span class="token comment">#You could also initialize by using random states.</span>
batch_zero_state_packed <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> get_network_state_size<span class="token punctuation">(</span>hidden_network<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>


epoch_count <span class="token operator">=</span> <span class="token number">10</span>

<span class="token comment">#Store the performance over the dev set in loss_results</span>
loss_results <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>epoch_count<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">get_loss</span><span class="token punctuation">(</span>set_name<span class="token punctuation">,</span> bsz<span class="token punctuation">,</span> example_set_indices<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Calculate a score over all batches in a set"""</span>
    epoch_loss <span class="token operator">=</span> <span class="token number">0.0</span>
    <span class="token keyword">for</span> example_index <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>bsz<span class="token punctuation">)</span><span class="token punctuation">:</span>
        batch_inputs<span class="token punctuation">,</span>batch_targets <span class="token operator">=</span> get_batch<span class="token punctuation">(</span>example_index<span class="token punctuation">,</span> example_set_indices<span class="token punctuation">)</span>

        batch_loss <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>loss<span class="token punctuation">,</span>feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>
            inputs<span class="token punctuation">:</span>batch_inputs<span class="token punctuation">,</span>
            targets<span class="token punctuation">:</span>batch_targets<span class="token punctuation">,</span>
            initial_state_packed<span class="token punctuation">:</span> batch_zero_state_packed
        <span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> example_index <span class="token operator">%</span> <span class="token number">20</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"  %s results batch %d, loss %s"</span> <span class="token operator">%</span><span class="token punctuation">(</span>  set_name<span class="token punctuation">,</span> example_index<span class="token punctuation">,</span> <span class="token builtin">str</span><span class="token punctuation">(</span>batch_loss<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  

        epoch_loss <span class="token operator">+=</span> batch_loss
    <span class="token keyword">return</span> epoch_loss <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>example_set_indices<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">generate_graph</span><span class="token punctuation">(</span>graph_size<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Use the network to generate a graph"""</span>
    
    <span class="token comment">#The network will be primed using prime_size samples of the original signal</span>
    prime_size <span class="token operator">=</span> <span class="token number">50</span>
    prime_signal_start_i <span class="token operator">=</span> <span class="token number">0</span>
    
    <span class="token comment">#put prime_size samples of the original signal in tmp_singal</span>
    orig_signal <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>graph_size<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    tmp_signal <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>graph_size<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    tmp_signal<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span>prime_size<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> signal_amp<span class="token punctuation">[</span>prime_signal_start_i<span class="token punctuation">:</span><span class="token punctuation">(</span>prime_signal_start_i<span class="token operator">+</span>prime_size<span class="token punctuation">)</span><span class="token punctuation">]</span>
    orig_signal<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span>graph_size<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> signal_amp<span class="token punctuation">[</span>prime_signal_start_i<span class="token punctuation">:</span><span class="token punctuation">(</span>prime_signal_start_i<span class="token operator">+</span>graph_size<span class="token punctuation">)</span><span class="token punctuation">]</span>
    
    <span class="token comment">#create a sequence for a batch_size of 1</span>
    seq <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>sequence_length<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    seq_state_packed <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> get_network_state_size<span class="token punctuation">(</span>hidden_network<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    _state_unpacked <span class="token operator">=</span> <span class="token boolean">None</span>
    <span class="token comment">#generate the graph</span>
    <span class="token keyword">for</span> end <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>prime_size<span class="token punctuation">,</span> graph_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment">#get a sequence to present to the network</span>
        seq<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> tmp_signal<span class="token punctuation">.</span>take<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token punctuation">(</span>end<span class="token operator">-</span>sequence_length<span class="token punctuation">)</span><span class="token punctuation">,</span>end<span class="token punctuation">)</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'wrap'</span><span class="token punctuation">)</span>
        
        <span class="token comment">#get a prediction</span>
        seq_state_packed <span class="token punctuation">,</span> _prediction <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>
            <span class="token punctuation">[</span>state_packed_network_out<span class="token punctuation">,</span> predictions<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
            feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>
                initial_state_packed<span class="token punctuation">:</span> seq_state_packed<span class="token punctuation">,</span>
                inputs<span class="token punctuation">:</span> seq<span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token comment">#put the prediction in the graph</span>
        tmp_signal<span class="token punctuation">[</span>end<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> _prediction
        sys<span class="token punctuation">.</span>stdout<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'.'</span><span class="token punctuation">)</span>
        sys<span class="token punctuation">.</span>stdout<span class="token punctuation">.</span>flush<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">)</span>
    plotly<span class="token punctuation">.</span>offline<span class="token punctuation">.</span>iplot<span class="token punctuation">(</span><span class="token punctuation">{</span>
       <span class="token string">"data"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>Scatter<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">"predicted"</span><span class="token punctuation">,</span>y<span class="token operator">=</span>tmp_signal<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>Scatter<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">"original"</span><span class="token punctuation">,</span>y<span class="token operator">=</span>orig_signal<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token string">"layout"</span><span class="token punctuation">:</span> Layout<span class="token punctuation">(</span>title<span class="token operator">=</span><span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>


init<span class="token operator">=</span>tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">with</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> sess<span class="token punctuation">:</span>
    sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>init<span class="token punctuation">)</span>



    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>epoch_count<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Epoch %d"</span> <span class="token operator">%</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment">#in every epoch go through the training set in a different order</span>
        np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>shuffle <span class="token punctuation">(</span>train_indices<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Train"</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> ti <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>train_batch_count<span class="token punctuation">)</span><span class="token punctuation">:</span>
            batch_inputs<span class="token punctuation">,</span>batch_targets <span class="token operator">=</span> get_batch<span class="token punctuation">(</span>ti<span class="token punctuation">,</span> train_indices<span class="token punctuation">)</span>

            <span class="token comment">#train the network</span>
            <span class="token comment">#I reset the state to zero for each batch. </span>
            batch_train_loss<span class="token punctuation">,</span> _ <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token punctuation">[</span>loss<span class="token punctuation">,</span> opt<span class="token punctuation">]</span><span class="token punctuation">,</span> 
                                           feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>
                                               learning_rate<span class="token punctuation">:</span> <span class="token number">0.00005</span><span class="token punctuation">,</span> 
                                               inputs<span class="token punctuation">:</span> batch_inputs<span class="token punctuation">,</span> 
                                               targets<span class="token punctuation">:</span> batch_targets<span class="token punctuation">,</span>
                                               initial_state_packed<span class="token punctuation">:</span> batch_zero_state_packed
                                           <span class="token punctuation">}</span><span class="token punctuation">)</span>
            sys<span class="token punctuation">.</span>stdout<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'.'</span><span class="token punctuation">)</span>
            sys<span class="token punctuation">.</span>stdout<span class="token punctuation">.</span>flush<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">)</span>
        epoch_train_loss <span class="token operator">=</span> get_loss<span class="token punctuation">(</span><span class="token string">"Train"</span><span class="token punctuation">,</span> train_batch_count<span class="token punctuation">,</span> train_indices<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Training results epoch %d, loss %s"</span> <span class="token operator">%</span><span class="token punctuation">(</span> epoch<span class="token punctuation">,</span> <span class="token builtin">str</span><span class="token punctuation">(</span>epoch_train_loss<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        epoch_dev_loss <span class="token operator">=</span> get_loss<span class="token punctuation">(</span><span class="token string">"Dev"</span><span class="token punctuation">,</span> dev_batch_count<span class="token punctuation">,</span> dev_indices<span class="token punctuation">)</span>    
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Dev results epoch %d, loss %s"</span> <span class="token operator">%</span><span class="token punctuation">(</span> epoch<span class="token punctuation">,</span> <span class="token builtin">str</span><span class="token punctuation">(</span>epoch_dev_loss<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  
        loss_results<span class="token punctuation">[</span>epoch<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> epoch_train_loss
        loss_results<span class="token punctuation">[</span>epoch<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> epoch_dev_loss
        ti <span class="token operator">+=</span> <span class="token number">1</span>
        generate_graph<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
    <span class="token comment">#generate a last long graph</span>
    generate_graph<span class="token punctuation">(</span>graph_size<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span>
    
    plotly<span class="token punctuation">.</span>offline<span class="token punctuation">.</span>iplot<span class="token punctuation">(</span><span class="token punctuation">{</span>
       <span class="token string">"data"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>Scatter<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">"loss train"</span><span class="token punctuation">,</span>y<span class="token operator">=</span>loss_results<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>Scatter<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">"loss dev"</span><span class="token punctuation">,</span>y<span class="token operator">=</span>loss_results<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token string">"layout"</span><span class="token punctuation">:</span> Layout<span class="token punctuation">(</span>title<span class="token operator">=</span><span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>

        
</code></pre>
      </div>
<div class="gatsby-highlight">
      <pre class="language-none"><code>Epoch 0
Train
.........................................................................................................................................................................................................................................
  Train results batch 0, loss 54.9094
  Train results batch 20, loss 52.7554
  Train results batch 40, loss 57.1101
  Train results batch 60, loss 56.6699
  Train results batch 80, loss 52.1481
  Train results batch 100, loss 55.9796
  Train results batch 120, loss 58.3971
  Train results batch 140, loss 44.4456
  Train results batch 160, loss 48.3201
  Train results batch 180, loss 48.1845
  Train results batch 200, loss 55.2113
  Train results batch 220, loss 54.7782
Training results epoch 0, loss 0.420098819824
  Dev results batch 0, loss 51.6062
  Dev results batch 20, loss 53.5696
  Dev results batch 40, loss 50.2322
  Dev results batch 60, loss 51.0714
Dev results epoch 0, loss 0.407184930349
......................................................................................................................................................</code></pre>
      </div>
<div id="5d6021d7-c3eb-412e-be37-8fdf2afc908e" style="height: 525px; width: 100%;" class="plotly-graph-div"></div><script data-my-script="" type="text/javascript">require(["plotly"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL="https://plot.ly";Plotly.newPlot("5d6021d7-c3eb-412e-be37-8fdf2afc908e", [{"type": "scatter", "y": [-0.009999358952767035, 0.0636596725936513, 0.09396539891340987, 0.18736083188739677, 0.24554522107360244, 0.30474662791998464, 0.3540644715650535, 0.427310695217905, 0.5082610045992348, 0.528743319714693, 0.610873715328187, 0.6595808302414805, 0.6714801770744819, 0.7161724630504367, 0.8017361218478947, 0.8227584059757931, 0.8339431865355841, 0.8589156197859245, 0.9032790012741199, 0.9277440963860971, 0.944348827684898, 0.9550259159741353, 0.9939331935171848, 0.9953889438631083, 1.031895777398816, 0.991926769744457, 1.008018984611331, 0.9898874568317324, 0.9660036288267146, 0.9778216806047674, 0.9427574719479263, 0.9160079988143766, 0.903887727996592, 0.9011663035689388, 0.8367907573153219, 0.8260939809053769, 0.7683508266691262, 0.7234202492635545, 0.7121569782970198, 0.6213383920442218, 0.5786361839359868, 0.5380777310192311, 0.46138829067940923, 0.4441318595463302, 0.34964272800620694, 0.3233662082126278, 0.24534658923290942, 0.18524150173515894, 0.12375363227000283, 0.04747565849617937, -0.005601468496024609, -0.013249159790575504, -0.02064664661884308, -0.027528097853064537, -0.03366279602050781, -0.038902245461940765, -0.04317876696586609, -0.04648983106017113, -0.04887910932302475, -0.05041910707950592, -0.05119746923446655, -0.051307279616594315, -0.050840768963098526, -0.04988567531108856, -0.04852321371436119, -0.046827442944049835, -0.04486522451043129, -0.04269647225737572, -0.04037455841898918, -0.03794688731431961, -0.03545522317290306, -0.03293618932366371, -0.030421549454331398, -0.02793857455253601, -0.025510381907224655, -0.02315612882375717, -0.02089136652648449, -0.018728366121649742, -0.01667635701596737, -0.01474183239042759, -0.012928898446261883, -0.011239511892199516, -0.009673808701336384, -0.008230343461036682, -0.006906399969011545, -0.005698183085769415, -0.004601054824888706, -0.003609755542129278, -0.002718555275350809, -0.0019214242929592729, -0.0012121425243094563, -0.0005844623083248734, -3.213959280401468e-05, 0.00045093928929418325, 0.000870705465786159, 0.0012328739976510406, 0.0015429056948050857, 0.0018059489084407687, 0.002026879694312811, 0.0022102422080934048, 0.0023602615110576153, 0.002480857539921999, 0.0025756810791790485, 0.002647999208420515, 0.0027008880861103535, 0.002737038768827915, 0.002758917398750782, 0.002768722828477621, 0.0027684769593179226, 0.0027599320746958256, 0.002744607627391815, 0.0027239364571869373, 0.002699078992009163, 0.002671053633093834, 0.002640808466821909, 0.0026091490872204304, 0.0025766794569790363, 0.0025439318269491196, 0.0025113942101597786, 0.0024794721975922585, 0.002448439598083496, 0.0024185283109545708, 0.002389931585639715, 0.0023628119379281998, 0.002337210811674595, 0.002313238102942705, 0.0022908314131200314, 0.002270056400448084, 0.002250854391604662, 0.0022331909276545048, 0.002217064145952463, 0.0022023399360477924, 0.002188974991440773, 0.002176918089389801, 0.0021660965867340565, 0.00215635122731328, 0.0021476740948855877, 0.002139927353709936, 0.002133057452738285, 0.0021270220167934895, 0.0021216641180217266, 0.0021169697865843773, 0.002112885471433401, 0.002109306864440441, 0.002106253057718277, 0.002103582490235567, 0.0021013296209275723, 0.0020993798971176147, 0.002097737044095993, 0.002096350770443678, 0.0020951833575963974, 0.002094212919473648, 0.0020934613421559334, 0.0020929090678691864, 0.0020925188437104225, 0.0020922659896314144, 0.002092139795422554, 0.002092098817229271, 0.0020921421237289906, 0.002092250157147646, 0.002092416863888502, 0.002092626877129078, 0.002092869020998478, 0.0020931269973516464, 0.0020934082567691803, 0.0020937020890414715, 0.0020939954556524754, 0.002094293013215065, 0.002094594296067953, 0.002094878349453211, 0.002095166128128767, 0.0020954348146915436, 0.002095696981996298, 0.002095945179462433, 0.002096181269735098, 0.0020964015275239944, 0.002096611075103283, 0.0020968103781342506, 0.0020969933830201626, 0.0020971600897610188, 0.002097316086292267, 0.0020974604412913322, 0.002097591757774353, 0.002097709570080042, 0.0020978194661438465, 0.0020979149267077446, 0.00209799874573946, 0.002098080702126026, 0.0020981477573513985, 0.0020982148125767708, 0.002098263707011938, 0.0020983112044632435, 0.002098355907946825, 0.0020983899012207985, 0.002098425291478634, 0.002098450902849436, 0.002098474185913801, 0.002098493278026581, 0.002098511904478073, 0.002098522149026394], "name": "predicted"}, {"type": "scatter", "y": [-0.009999358952767035, 0.0636596725936513, 0.09396539891340987, 0.18736083188739677, 0.24554522107360244, 0.30474662791998464, 0.3540644715650535, 0.427310695217905, 0.5082610045992348, 0.528743319714693, 0.610873715328187, 0.6595808302414805, 0.6714801770744819, 0.7161724630504367, 0.8017361218478947, 0.8227584059757931, 0.8339431865355841, 0.8589156197859245, 0.9032790012741199, 0.9277440963860971, 0.944348827684898, 0.9550259159741353, 0.9939331935171848, 0.9953889438631083, 1.031895777398816, 0.991926769744457, 1.008018984611331, 0.9898874568317324, 0.9660036288267146, 0.9778216806047674, 0.9427574719479263, 0.9160079988143766, 0.903887727996592, 0.9011663035689388, 0.8367907573153219, 0.8260939809053769, 0.7683508266691262, 0.7234202492635545, 0.7121569782970198, 0.6213383920442218, 0.5786361839359868, 0.5380777310192311, 0.46138829067940923, 0.4441318595463302, 0.34964272800620694, 0.3233662082126278, 0.24534658923290942, 0.18524150173515894, 0.12375363227000283, 0.04747565849617937, -0.0037387080934477928, -0.051743377712968094, -0.15214920425224088, -0.19449442529116476, -0.26660097990763254, -0.32123644885610925, -0.38842565077399277, -0.441144767589916, -0.48607544550013165, -0.524011507610602, -0.5891608717435157, -0.6453265897593556, -0.6902171009691433, -0.7271350896313418, -0.7695574187711549, -0.8019483627796674, -0.8705328832225805, -0.8882826334487386, -0.941180390156566, -0.9078491448280709, -0.9832570314642423, -0.942594348092753, -0.9894904989827801, -1.033150433359927, -0.9886850624679566, -1.0280845624475607, -1.0089557387836479, -0.9901244244917171, -0.9947835829309849, -0.9469085583633676, -0.928849321496094, -0.9595811107489216, -0.899135580368624, -0.904911369504552, -0.8489143109698182, -0.7904224335162588, -0.7793467872833741, -0.7288845420182568, -0.6813326718442346, -0.6342428891149459, -0.5838042233620713, -0.5394518302446045, -0.49395160308410146, -0.43786637091879443, -0.3736342591485493, -0.3050754102189696, -0.23006119896148175, -0.15796119062894998, -0.13899400784200322, -0.07349763188343796, -0.022813306341768008, 0.05154018987183014, 0.15715760494770037, 0.20520889719981203, 0.22701288049240798, 0.34376915047710155, 0.39380520967089705, 0.42170607945255223, 0.5051473215112843, 0.517959834594867, 0.5842618115193163, 0.639205485969443, 0.6517609770466205, 0.7524165476525965, 0.7733899011038774, 0.7671879127780509, 0.8378791949103853, 0.8869084817924341, 0.9253955427829345, 0.9474620605814121, 0.9492888026500431, 0.9409248393793384, 0.9925682334015613, 1.0212177683122823, 0.988258219789467, 0.9974993657507019, 0.985505248508194, 0.9691975335965581, 0.9816182076967912, 1.0069189782770906, 0.9517295755478234, 0.9151599032622754, 0.9230691448701079, 0.8647948616525551, 0.8391556216439793, 0.7743724386112338, 0.7572152028785227, 0.7235964806336481, 0.6679369953520177, 0.6561309728447834, 0.5698838129697144, 0.535494580645897, 0.47822109618725667, 0.43056754840990097, 0.3796522505801375, 0.30640282243540146, 0.24888140240620638, 0.16101972528613337, 0.11274049727664075, 0.05557651776347804, 0.007767086457276048, -0.07755460024331498, -0.12614497129964494, -0.19339795292170062, -0.2711600718126285, -0.2776459941637687, -0.3736172256217579, -0.43593804695342714, -0.4830804859023277, -0.5178520557861744, -0.6103658903884167, -0.6575171641143672, -0.7155881313104441, -0.7393348420107445, -0.799837168515808, -0.8146339753743045, -0.8413778152003573, -0.8677364988263171, -0.9256726232512349, -0.9606969095668922, -0.960883549581452, -0.9695173165732712, -0.9964459659204626, -1.0068786370846308, -1.027668291543145, -0.9971305351809371, -1.0037618140427316, -0.9890243909537776, -0.9804558226660108, -0.9673632031655514, -0.9379023272572421, -0.934088180148397, -0.9166649874015851, -0.9189964142899317, -0.8429842068469926, -0.7965800116683697, -0.768901463615821, -0.7248123293996247, -0.7065009887084645, -0.6627206902044985, -0.5784566232989523, -0.5478967746908785, -0.4615929887606986, -0.44421982569590407, -0.37499013908010215, -0.3251221604381255, -0.2665142392093253, -0.20527701245193583, -0.10344417870438943, -0.04104891977859873], "name": "original"}], {"title": ""}, {"showLink": true, "linkText": "Export to plot.ly"})});</script>
<div class="gatsby-highlight">
      <pre class="language-none"><code>Epoch 1
Train
.........................................................................................................................................................................................................................................
  Train results batch 0, loss 21.4379
  Train results batch 20, loss 20.0213
  Train results batch 40, loss 21.2412
  Train results batch 60, loss 19.3035
  Train results batch 80, loss 22.9997
  Train results batch 100, loss 22.1121
  Train results batch 120, loss 19.6073
  Train results batch 140, loss 20.3425
  Train results batch 160, loss 19.6809
  Train results batch 180, loss 25.0082
  Train results batch 200, loss 22.1662
  Train results batch 220, loss 24.211
Training results epoch 1, loss 0.163680443564
  Dev results batch 0, loss 19.6441
  Dev results batch 20, loss 20.6591
  Dev results batch 40, loss 21.2059
  Dev results batch 60, loss 19.5042
Dev results epoch 1, loss 0.15843713808
......................................................................................................................................................</code></pre>
      </div>
<div id="d39a9b9f-b96b-4fed-9b9e-73591307bd4b" style="height: 525px; width: 100%;" class="plotly-graph-div"></div><script data-my-script="" type="text/javascript">require(["plotly"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL="https://plot.ly";Plotly.newPlot("d39a9b9f-b96b-4fed-9b9e-73591307bd4b", [{"type": "scatter", "y": [-0.009999358952767035, 0.0636596725936513, 0.09396539891340987, 0.18736083188739677, 0.24554522107360244, 0.30474662791998464, 0.3540644715650535, 0.427310695217905, 0.5082610045992348, 0.528743319714693, 0.610873715328187, 0.6595808302414805, 0.6714801770744819, 0.7161724630504367, 0.8017361218478947, 0.8227584059757931, 0.8339431865355841, 0.8589156197859245, 0.9032790012741199, 0.9277440963860971, 0.944348827684898, 0.9550259159741353, 0.9939331935171848, 0.9953889438631083, 1.031895777398816, 0.991926769744457, 1.008018984611331, 0.9898874568317324, 0.9660036288267146, 0.9778216806047674, 0.9427574719479263, 0.9160079988143766, 0.903887727996592, 0.9011663035689388, 0.8367907573153219, 0.8260939809053769, 0.7683508266691262, 0.7234202492635545, 0.7121569782970198, 0.6213383920442218, 0.5786361839359868, 0.5380777310192311, 0.46138829067940923, 0.4441318595463302, 0.34964272800620694, 0.3233662082126278, 0.24534658923290942, 0.18524150173515894, 0.12375363227000283, 0.04747565849617937, 0.10860691219568253, 0.07526109367609024, 0.04220758378505707, 0.009749842807650566, -0.021887047216296196, -0.05253436788916588, -0.08205200731754303, -0.11031230539083481, -0.13719366490840912, -0.1625797003507614, -0.1863609403371811, -0.20843838155269623, -0.22872641682624817, -0.24715648591518402, -0.26367834210395813, -0.27826210856437683, -0.2908985912799835, -0.3015992343425751, -0.31039509177207947, -0.3173358142375946, -0.32248803973197937, -0.32593274116516113, -0.32776349782943726, -0.328083336353302, -0.3270025849342346, -0.32463595271110535, -0.321100115776062, -0.31651148200035095, -0.3109845817089081, -0.3046300411224365, -0.297553688287735, -0.2898555099964142, -0.28162938356399536, -0.27296268939971924, -0.26393604278564453, -0.25462377071380615, -0.24509431421756744, -0.23540981113910675, -0.2256273329257965, -0.2157987356185913, -0.20597131550312042, -0.1961877942085266, -0.1864871382713318, -0.1769045740365982, -0.16747188568115234, -0.15821772813796997, -0.14916770160198212, -0.14034463465213776, -0.13176894187927246, -0.1234583631157875, -0.11542849242687225, -0.10769294947385788, -0.10026068985462189, -0.09314226359128952, -0.08634332567453384, -0.07987060397863388, -0.0737282931804657, -0.06791924685239792, -0.062443748116493225, -0.05730133131146431, -0.052492812275886536, -0.04801313579082489, -0.04385992884635925, -0.04003000259399414, -0.03651626408100128, -0.03331027925014496, -0.03040785901248455, -0.027801401913166046, -0.025481538847088814, -0.023438064381480217, -0.02166237123310566, -0.020144645124673843, -0.018874751403927803, -0.017840074375271797, -0.017031937837600708, -0.01643669418990612, -0.016048206016421318, -0.015851028263568878, -0.015836212784051895, -0.01599275879561901, -0.01630650833249092, -0.016770007088780403, -0.017371442168951035, -0.018098585307598114, -0.018940001726150513, -0.019890349358320236, -0.0209345780313015, -0.022066449746489525, -0.023274660110473633, -0.02454676851630211, -0.025879450142383575, -0.02725916914641857, -0.028676766902208328, -0.030125895515084267, -0.03159399703145027, -0.03307799622416496, -0.03456580266356468, -0.036053307354450226, -0.03753243759274483, -0.03899689391255379, -0.04044153541326523, -0.041853904724121094, -0.04323451220989227, -0.04457885026931763, -0.04588273912668228, -0.04714261740446091, -0.048355259001255035, -0.04951776564121246, -0.050627805292606354, -0.05168336629867554, -0.052682846784591675, -0.05362498387694359, -0.05450894311070442, -0.05533408373594284, -0.05610024929046631, -0.05680747330188751, -0.05745607241988182, -0.05804668366909027, -0.05858013033866882, -0.059057481586933136, -0.059479985386133194, -0.0598490834236145, -0.06016644090414047, -0.060433804988861084, -0.060653023421764374, -0.06082611158490181, -0.06095515191555023, -0.061042286455631256, -0.06108982861042023, -0.061100006103515625, -0.061075106263160706, -0.061017464846372604, -0.060929425060749054, -0.060813311487436295, -0.06067142263054848, -0.06050606071949005, -0.0603194460272789, -0.0601138174533844, -0.05989132821559906, -0.05965401604771614, -0.059403952211141586, -0.059143126010894775, -0.05887334421277046, -0.058596476912498474, -0.05831420049071312, -0.0580282062292099, -0.05774001404643059, -0.05745106190443039, -0.057162754237651825, -0.056876372545957565], "name": "predicted"}, {"type": "scatter", "y": [-0.009999358952767035, 0.0636596725936513, 0.09396539891340987, 0.18736083188739677, 0.24554522107360244, 0.30474662791998464, 0.3540644715650535, 0.427310695217905, 0.5082610045992348, 0.528743319714693, 0.610873715328187, 0.6595808302414805, 0.6714801770744819, 0.7161724630504367, 0.8017361218478947, 0.8227584059757931, 0.8339431865355841, 0.8589156197859245, 0.9032790012741199, 0.9277440963860971, 0.944348827684898, 0.9550259159741353, 0.9939331935171848, 0.9953889438631083, 1.031895777398816, 0.991926769744457, 1.008018984611331, 0.9898874568317324, 0.9660036288267146, 0.9778216806047674, 0.9427574719479263, 0.9160079988143766, 0.903887727996592, 0.9011663035689388, 0.8367907573153219, 0.8260939809053769, 0.7683508266691262, 0.7234202492635545, 0.7121569782970198, 0.6213383920442218, 0.5786361839359868, 0.5380777310192311, 0.46138829067940923, 0.4441318595463302, 0.34964272800620694, 0.3233662082126278, 0.24534658923290942, 0.18524150173515894, 0.12375363227000283, 0.04747565849617937, -0.0037387080934477928, -0.051743377712968094, -0.15214920425224088, -0.19449442529116476, -0.26660097990763254, -0.32123644885610925, -0.38842565077399277, -0.441144767589916, -0.48607544550013165, -0.524011507610602, -0.5891608717435157, -0.6453265897593556, -0.6902171009691433, -0.7271350896313418, -0.7695574187711549, -0.8019483627796674, -0.8705328832225805, -0.8882826334487386, -0.941180390156566, -0.9078491448280709, -0.9832570314642423, -0.942594348092753, -0.9894904989827801, -1.033150433359927, -0.9886850624679566, -1.0280845624475607, -1.0089557387836479, -0.9901244244917171, -0.9947835829309849, -0.9469085583633676, -0.928849321496094, -0.9595811107489216, -0.899135580368624, -0.904911369504552, -0.8489143109698182, -0.7904224335162588, -0.7793467872833741, -0.7288845420182568, -0.6813326718442346, -0.6342428891149459, -0.5838042233620713, -0.5394518302446045, -0.49395160308410146, -0.43786637091879443, -0.3736342591485493, -0.3050754102189696, -0.23006119896148175, -0.15796119062894998, -0.13899400784200322, -0.07349763188343796, -0.022813306341768008, 0.05154018987183014, 0.15715760494770037, 0.20520889719981203, 0.22701288049240798, 0.34376915047710155, 0.39380520967089705, 0.42170607945255223, 0.5051473215112843, 0.517959834594867, 0.5842618115193163, 0.639205485969443, 0.6517609770466205, 0.7524165476525965, 0.7733899011038774, 0.7671879127780509, 0.8378791949103853, 0.8869084817924341, 0.9253955427829345, 0.9474620605814121, 0.9492888026500431, 0.9409248393793384, 0.9925682334015613, 1.0212177683122823, 0.988258219789467, 0.9974993657507019, 0.985505248508194, 0.9691975335965581, 0.9816182076967912, 1.0069189782770906, 0.9517295755478234, 0.9151599032622754, 0.9230691448701079, 0.8647948616525551, 0.8391556216439793, 0.7743724386112338, 0.7572152028785227, 0.7235964806336481, 0.6679369953520177, 0.6561309728447834, 0.5698838129697144, 0.535494580645897, 0.47822109618725667, 0.43056754840990097, 0.3796522505801375, 0.30640282243540146, 0.24888140240620638, 0.16101972528613337, 0.11274049727664075, 0.05557651776347804, 0.007767086457276048, -0.07755460024331498, -0.12614497129964494, -0.19339795292170062, -0.2711600718126285, -0.2776459941637687, -0.3736172256217579, -0.43593804695342714, -0.4830804859023277, -0.5178520557861744, -0.6103658903884167, -0.6575171641143672, -0.7155881313104441, -0.7393348420107445, -0.799837168515808, -0.8146339753743045, -0.8413778152003573, -0.8677364988263171, -0.9256726232512349, -0.9606969095668922, -0.960883549581452, -0.9695173165732712, -0.9964459659204626, -1.0068786370846308, -1.027668291543145, -0.9971305351809371, -1.0037618140427316, -0.9890243909537776, -0.9804558226660108, -0.9673632031655514, -0.9379023272572421, -0.934088180148397, -0.9166649874015851, -0.9189964142899317, -0.8429842068469926, -0.7965800116683697, -0.768901463615821, -0.7248123293996247, -0.7065009887084645, -0.6627206902044985, -0.5784566232989523, -0.5478967746908785, -0.4615929887606986, -0.44421982569590407, -0.37499013908010215, -0.3251221604381255, -0.2665142392093253, -0.20527701245193583, -0.10344417870438943, -0.04104891977859873], "name": "original"}], {"title": ""}, {"showLink": true, "linkText": "Export to plot.ly"})});</script>
<div class="gatsby-highlight">
      <pre class="language-none"><code>Epoch 2
Train
.........................................................................................................................................................................................................................................
  Train results batch 0, loss 1.25657
  Train results batch 20, loss 1.24823
  Train results batch 40, loss 1.5213
  Train results batch 60, loss 1.51712
  Train results batch 80, loss 1.37371
  Train results batch 100, loss 1.52443
  Train results batch 120, loss 1.04627
  Train results batch 140, loss 1.12556
  Train results batch 160, loss 1.01674
  Train results batch 180, loss 1.34206
  Train results batch 200, loss 1.23301
  Train results batch 220, loss 1.15482
Training results epoch 2, loss 0.00969723457763
  Dev results batch 0, loss 1.21576
  Dev results batch 20, loss 1.2668
  Dev results batch 40, loss 1.44446
  Dev results batch 60, loss 1.07501
Dev results epoch 2, loss 0.00952362719155
......................................................................................................................................................</code></pre>
      </div>
<div id="eca27cbe-039a-4ab8-b25c-c41205f932fb" style="height: 525px; width: 100%;" class="plotly-graph-div"></div><script data-my-script="" type="text/javascript">require(["plotly"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL="https://plot.ly";Plotly.newPlot("eca27cbe-039a-4ab8-b25c-c41205f932fb", [{"type": "scatter", "y": [-0.009999358952767035, 0.0636596725936513, 0.09396539891340987, 0.18736083188739677, 0.24554522107360244, 0.30474662791998464, 0.3540644715650535, 0.427310695217905, 0.5082610045992348, 0.528743319714693, 0.610873715328187, 0.6595808302414805, 0.6714801770744819, 0.7161724630504367, 0.8017361218478947, 0.8227584059757931, 0.8339431865355841, 0.8589156197859245, 0.9032790012741199, 0.9277440963860971, 0.944348827684898, 0.9550259159741353, 0.9939331935171848, 0.9953889438631083, 1.031895777398816, 0.991926769744457, 1.008018984611331, 0.9898874568317324, 0.9660036288267146, 0.9778216806047674, 0.9427574719479263, 0.9160079988143766, 0.903887727996592, 0.9011663035689388, 0.8367907573153219, 0.8260939809053769, 0.7683508266691262, 0.7234202492635545, 0.7121569782970198, 0.6213383920442218, 0.5786361839359868, 0.5380777310192311, 0.46138829067940923, 0.4441318595463302, 0.34964272800620694, 0.3233662082126278, 0.24534658923290942, 0.18524150173515894, 0.12375363227000283, 0.04747565849617937, -0.047337375581264496, -0.1323918104171753, -0.19982628524303436, -0.2696285843849182, -0.34121155738830566, -0.41370540857315063, -0.4860713481903076, -0.557161808013916, -0.6258109211921692, -0.6909371614456177, -0.7516312599182129, -0.8072094917297363, -0.857224702835083, -0.9014379978179932, -0.9397685527801514, -0.972231924533844, -0.9988845586776733, -1.0197808742523193, -1.0349481105804443, -1.0443816184997559, -1.0480594635009766, -1.0459719896316528, -1.038161277770996, -1.0247597694396973, -1.0060163736343384, -0.9823037981987, -0.9541059732437134, -0.9219832420349121, -0.8865299224853516, -0.848328709602356, -0.8079109191894531, -0.7657309174537659, -0.7221536636352539, -0.6774550080299377, -0.6318315267562866, -0.5854169726371765, -0.538301408290863, -0.4905511140823364, -0.4422259032726288, -0.3933943510055542, -0.34414297342300415, -0.29458296298980713, -0.24485032260417938, -0.19510376453399658, -0.14551779627799988, -0.09627611190080643, -0.04756295680999756, 0.0004443470388650894, 0.04758208990097046, 0.09370473027229309, 0.1386886090040207, 0.18243011832237244, 0.22487300634384155, 0.26594778895378113, 0.30563098192214966, 0.34388554096221924, 0.3806929886341095, 0.416035920381546, 0.44990262389183044, 0.48226937651634216, 0.5130873322486877, 0.5423169732093811, 0.5698810815811157, 0.5956839323043823, 0.619621753692627, 0.6415719985961914, 0.6613832712173462, 0.6789012551307678, 0.6939705610275269, 0.7064360976219177, 0.7161454558372498, 0.7229596972465515, 0.7267566323280334, 0.727437436580658, 0.7249177694320679, 0.7191431522369385, 0.7100691199302673, 0.6976836919784546, 0.6819847822189331, 0.6629875302314758, 0.6407270431518555, 0.6152404546737671, 0.5865824222564697, 0.5548193454742432, 0.5200251340866089, 0.4822683036327362, 0.4416416585445404, 0.39821964502334595, 0.3520863652229309, 0.30332517623901367, 0.2519821226596832, 0.19812420010566711, 0.1417974978685379, 0.08303331583738327, 0.021898994222283363, -0.04155176877975464, -0.1071663573384285, -0.1747402548789978, -0.24392299354076385, -0.3142152726650238, -0.38495078682899475, -0.45530372858047485, -0.5243237614631653, -0.5910114645957947, -0.6544057130813599, -0.7136567831039429, -0.7680808901786804, -0.8171834945678711, -0.8606489896774292, -0.8983054161071777, -0.9300812482833862, -0.9559575319290161, -0.9759361743927002, -0.9900179505348206, -0.9982038736343384, -1.0005098581314087, -0.996994137763977, -0.9877884387969971, -0.9731222987174988, -0.9533342719078064, -0.9288647174835205, -0.9002329111099243, -0.867998480796814, -0.8327232003211975, -0.7949333786964417, -0.7550920844078064, -0.7135846018791199, -0.6707144975662231, -0.6267099380493164, -0.5817360281944275, -0.5359128713607788, -0.4893321096897125, -0.44207435846328735, -0.39422333240509033, -0.34587621688842773, -0.2971504330635071, -0.2481852024793625, -0.19913983345031738, -0.1501885950565338, -0.10151495784521103, -0.053302519023418427, -0.005729049444198608, 0.04104034602642059, 0.08685848116874695, 0.13159865140914917, 0.17515665292739868, 0.2174503654241562, 0.2584182322025299, 0.2980162799358368, 0.3362142741680145], "name": "predicted"}, {"type": "scatter", "y": [-0.009999358952767035, 0.0636596725936513, 0.09396539891340987, 0.18736083188739677, 0.24554522107360244, 0.30474662791998464, 0.3540644715650535, 0.427310695217905, 0.5082610045992348, 0.528743319714693, 0.610873715328187, 0.6595808302414805, 0.6714801770744819, 0.7161724630504367, 0.8017361218478947, 0.8227584059757931, 0.8339431865355841, 0.8589156197859245, 0.9032790012741199, 0.9277440963860971, 0.944348827684898, 0.9550259159741353, 0.9939331935171848, 0.9953889438631083, 1.031895777398816, 0.991926769744457, 1.008018984611331, 0.9898874568317324, 0.9660036288267146, 0.9778216806047674, 0.9427574719479263, 0.9160079988143766, 0.903887727996592, 0.9011663035689388, 0.8367907573153219, 0.8260939809053769, 0.7683508266691262, 0.7234202492635545, 0.7121569782970198, 0.6213383920442218, 0.5786361839359868, 0.5380777310192311, 0.46138829067940923, 0.4441318595463302, 0.34964272800620694, 0.3233662082126278, 0.24534658923290942, 0.18524150173515894, 0.12375363227000283, 0.04747565849617937, -0.0037387080934477928, -0.051743377712968094, -0.15214920425224088, -0.19449442529116476, -0.26660097990763254, -0.32123644885610925, -0.38842565077399277, -0.441144767589916, -0.48607544550013165, -0.524011507610602, -0.5891608717435157, -0.6453265897593556, -0.6902171009691433, -0.7271350896313418, -0.7695574187711549, -0.8019483627796674, -0.8705328832225805, -0.8882826334487386, -0.941180390156566, -0.9078491448280709, -0.9832570314642423, -0.942594348092753, -0.9894904989827801, -1.033150433359927, -0.9886850624679566, -1.0280845624475607, -1.0089557387836479, -0.9901244244917171, -0.9947835829309849, -0.9469085583633676, -0.928849321496094, -0.9595811107489216, -0.899135580368624, -0.904911369504552, -0.8489143109698182, -0.7904224335162588, -0.7793467872833741, -0.7288845420182568, -0.6813326718442346, -0.6342428891149459, -0.5838042233620713, -0.5394518302446045, -0.49395160308410146, -0.43786637091879443, -0.3736342591485493, -0.3050754102189696, -0.23006119896148175, -0.15796119062894998, -0.13899400784200322, -0.07349763188343796, -0.022813306341768008, 0.05154018987183014, 0.15715760494770037, 0.20520889719981203, 0.22701288049240798, 0.34376915047710155, 0.39380520967089705, 0.42170607945255223, 0.5051473215112843, 0.517959834594867, 0.5842618115193163, 0.639205485969443, 0.6517609770466205, 0.7524165476525965, 0.7733899011038774, 0.7671879127780509, 0.8378791949103853, 0.8869084817924341, 0.9253955427829345, 0.9474620605814121, 0.9492888026500431, 0.9409248393793384, 0.9925682334015613, 1.0212177683122823, 0.988258219789467, 0.9974993657507019, 0.985505248508194, 0.9691975335965581, 0.9816182076967912, 1.0069189782770906, 0.9517295755478234, 0.9151599032622754, 0.9230691448701079, 0.8647948616525551, 0.8391556216439793, 0.7743724386112338, 0.7572152028785227, 0.7235964806336481, 0.6679369953520177, 0.6561309728447834, 0.5698838129697144, 0.535494580645897, 0.47822109618725667, 0.43056754840990097, 0.3796522505801375, 0.30640282243540146, 0.24888140240620638, 0.16101972528613337, 0.11274049727664075, 0.05557651776347804, 0.007767086457276048, -0.07755460024331498, -0.12614497129964494, -0.19339795292170062, -0.2711600718126285, -0.2776459941637687, -0.3736172256217579, -0.43593804695342714, -0.4830804859023277, -0.5178520557861744, -0.6103658903884167, -0.6575171641143672, -0.7155881313104441, -0.7393348420107445, -0.799837168515808, -0.8146339753743045, -0.8413778152003573, -0.8677364988263171, -0.9256726232512349, -0.9606969095668922, -0.960883549581452, -0.9695173165732712, -0.9964459659204626, -1.0068786370846308, -1.027668291543145, -0.9971305351809371, -1.0037618140427316, -0.9890243909537776, -0.9804558226660108, -0.9673632031655514, -0.9379023272572421, -0.934088180148397, -0.9166649874015851, -0.9189964142899317, -0.8429842068469926, -0.7965800116683697, -0.768901463615821, -0.7248123293996247, -0.7065009887084645, -0.6627206902044985, -0.5784566232989523, -0.5478967746908785, -0.4615929887606986, -0.44421982569590407, -0.37499013908010215, -0.3251221604381255, -0.2665142392093253, -0.20527701245193583, -0.10344417870438943, -0.04104891977859873], "name": "original"}], {"title": ""}, {"showLink": true, "linkText": "Export to plot.ly"})});</script>
<div class="gatsby-highlight">
      <pre class="language-none"><code>Epoch 3
Train
.........................................................................................................................................................................................................................................
  Train results batch 0, loss 0.179961
  Train results batch 20, loss 0.153622
  Train results batch 40, loss 0.207009
  Train results batch 60, loss 0.189542
  Train results batch 80, loss 0.156345
  Train results batch 100, loss 0.205141
  Train results batch 120, loss 0.145814
  Train results batch 140, loss 0.153639
  Train results batch 160, loss 0.185179
  Train results batch 180, loss 0.170148
  Train results batch 200, loss 0.184466
  Train results batch 220, loss 0.198975
Training results epoch 3, loss 0.00135172683512
  Dev results batch 0, loss 0.182201
  Dev results batch 20, loss 0.171388
  Dev results batch 40, loss 0.174947
  Dev results batch 60, loss 0.157753
Dev results epoch 3, loss 0.00133814723993
......................................................................................................................................................</code></pre>
      </div>
<div id="89ab0cc8-046e-4a5d-921d-b9914eb5d094" style="height: 525px; width: 100%;" class="plotly-graph-div"></div><script data-my-script="" type="text/javascript">require(["plotly"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL="https://plot.ly";Plotly.newPlot("89ab0cc8-046e-4a5d-921d-b9914eb5d094", [{"type": "scatter", "y": [-0.009999358952767035, 0.0636596725936513, 0.09396539891340987, 0.18736083188739677, 0.24554522107360244, 0.30474662791998464, 0.3540644715650535, 0.427310695217905, 0.5082610045992348, 0.528743319714693, 0.610873715328187, 0.6595808302414805, 0.6714801770744819, 0.7161724630504367, 0.8017361218478947, 0.8227584059757931, 0.8339431865355841, 0.8589156197859245, 0.9032790012741199, 0.9277440963860971, 0.944348827684898, 0.9550259159741353, 0.9939331935171848, 0.9953889438631083, 1.031895777398816, 0.991926769744457, 1.008018984611331, 0.9898874568317324, 0.9660036288267146, 0.9778216806047674, 0.9427574719479263, 0.9160079988143766, 0.903887727996592, 0.9011663035689388, 0.8367907573153219, 0.8260939809053769, 0.7683508266691262, 0.7234202492635545, 0.7121569782970198, 0.6213383920442218, 0.5786361839359868, 0.5380777310192311, 0.46138829067940923, 0.4441318595463302, 0.34964272800620694, 0.3233662082126278, 0.24534658923290942, 0.18524150173515894, 0.12375363227000283, 0.04747565849617937, -0.11836187541484833, -0.2104579508304596, -0.2705778181552887, -0.333130419254303, -0.39735138416290283, -0.4622114896774292, -0.5266283750534058, -0.5895310044288635, -0.6499321460723877, -0.706990659236908, -0.7600535750389099, -0.8086715340614319, -0.8525879383087158, -0.8917085528373718, -0.9260598421096802, -0.9557432532310486, -0.9808914661407471, -1.001632571220398, -1.018060564994812, -1.0302177667617798, -1.0380845069885254, -1.0415830612182617, -1.040590763092041, -1.0349674224853516, -1.0245907306671143, -1.0093952417373657, -0.9894078969955444, -0.9647701978683472, -0.9357398748397827, -0.9026743769645691, -0.8659965991973877, -0.8261523246765137, -0.7835692763328552, -0.7386239767074585, -0.6916237473487854, -0.6428011655807495, -0.592320442199707, -0.5402944684028625, -0.48680579662323, -0.4319290518760681, -0.37575164437294006, -0.31839150190353394, -0.26000645756721497, -0.2007972151041031, -0.14100392162799835, -0.0808962732553482, -0.020760612562298775, 0.0391153022646904, 0.09845532476902008, 0.1570061296224594, 0.21454650163650513, 0.2708895802497864, 0.3259124159812927, 0.3794928193092346, 0.43156856298446655, 0.48207181692123413, 0.5309557318687439, 0.5781697034835815, 0.6236541271209717, 0.6673156023025513, 0.7090094089508057, 0.7485655546188354, 0.7857480049133301, 0.820277988910675, 0.8518509864807129, 0.8801442384719849, 0.90482497215271, 0.9255900979042053, 0.9421795606613159, 0.9543901681900024, 0.9620793461799622, 0.9651733636856079, 0.9636602401733398, 0.9575831890106201, 0.9470210671424866, 0.9320859313011169, 0.9128970503807068, 0.8895937204360962, 0.8623107671737671, 0.8311886787414551, 0.7963790893554688, 0.7580352425575256, 0.7163334488868713, 0.671471893787384, 0.6236717700958252, 0.5731618404388428, 0.5202052593231201, 0.46505048871040344, 0.4079492688179016, 0.3491382598876953, 0.28879374265670776, 0.22708389163017273, 0.1641215831041336, 0.09996822476387024, 0.03468579053878784, -0.03171299397945404, -0.09914585947990417, -0.16750827431678772, -0.23657405376434326, -0.3059934377670288, -0.3752748370170593, -0.4438040852546692, -0.510825514793396, -0.5755542516708374, -0.6372364163398743, -0.6952060461044312, -0.7489322423934937, -0.798043966293335, -0.8423298001289368, -0.8817174434661865, -0.9162401556968689, -0.9459975361824036, -0.9711160659790039, -0.9917161464691162, -1.0078846216201782, -1.019657015800476, -1.0270103216171265, -1.0298677682876587, -1.028116226196289, -1.0216343402862549, -1.0103297233581543, -0.9941761493682861, -0.9732444882392883, -0.947719156742096, -0.9178926348686218, -0.8841454982757568, -0.8469074964523315, -0.8066178560256958, -0.7636862397193909, -0.7184664011001587, -0.6712406277656555, -0.6222196817398071, -0.5715527534484863, -0.5193451046943665, -0.46567851305007935, -0.41063499450683594, -0.3543144464492798, -0.29685017466545105, -0.2384156584739685, -0.17922580242156982, -0.1195310652256012, -0.059606172144412994, 0.00026324018836021423, 0.05979476869106293, 0.11872164160013199, 0.17680354416370392, 0.2338329255580902, 0.28963974118232727, 0.3440904915332794, 0.39708584547042847], "name": "predicted"}, {"type": "scatter", "y": [-0.009999358952767035, 0.0636596725936513, 0.09396539891340987, 0.18736083188739677, 0.24554522107360244, 0.30474662791998464, 0.3540644715650535, 0.427310695217905, 0.5082610045992348, 0.528743319714693, 0.610873715328187, 0.6595808302414805, 0.6714801770744819, 0.7161724630504367, 0.8017361218478947, 0.8227584059757931, 0.8339431865355841, 0.8589156197859245, 0.9032790012741199, 0.9277440963860971, 0.944348827684898, 0.9550259159741353, 0.9939331935171848, 0.9953889438631083, 1.031895777398816, 0.991926769744457, 1.008018984611331, 0.9898874568317324, 0.9660036288267146, 0.9778216806047674, 0.9427574719479263, 0.9160079988143766, 0.903887727996592, 0.9011663035689388, 0.8367907573153219, 0.8260939809053769, 0.7683508266691262, 0.7234202492635545, 0.7121569782970198, 0.6213383920442218, 0.5786361839359868, 0.5380777310192311, 0.46138829067940923, 0.4441318595463302, 0.34964272800620694, 0.3233662082126278, 0.24534658923290942, 0.18524150173515894, 0.12375363227000283, 0.04747565849617937, -0.0037387080934477928, -0.051743377712968094, -0.15214920425224088, -0.19449442529116476, -0.26660097990763254, -0.32123644885610925, -0.38842565077399277, -0.441144767589916, -0.48607544550013165, -0.524011507610602, -0.5891608717435157, -0.6453265897593556, -0.6902171009691433, -0.7271350896313418, -0.7695574187711549, -0.8019483627796674, -0.8705328832225805, -0.8882826334487386, -0.941180390156566, -0.9078491448280709, -0.9832570314642423, -0.942594348092753, -0.9894904989827801, -1.033150433359927, -0.9886850624679566, -1.0280845624475607, -1.0089557387836479, -0.9901244244917171, -0.9947835829309849, -0.9469085583633676, -0.928849321496094, -0.9595811107489216, -0.899135580368624, -0.904911369504552, -0.8489143109698182, -0.7904224335162588, -0.7793467872833741, -0.7288845420182568, -0.6813326718442346, -0.6342428891149459, -0.5838042233620713, -0.5394518302446045, -0.49395160308410146, -0.43786637091879443, -0.3736342591485493, -0.3050754102189696, -0.23006119896148175, -0.15796119062894998, -0.13899400784200322, -0.07349763188343796, -0.022813306341768008, 0.05154018987183014, 0.15715760494770037, 0.20520889719981203, 0.22701288049240798, 0.34376915047710155, 0.39380520967089705, 0.42170607945255223, 0.5051473215112843, 0.517959834594867, 0.5842618115193163, 0.639205485969443, 0.6517609770466205, 0.7524165476525965, 0.7733899011038774, 0.7671879127780509, 0.8378791949103853, 0.8869084817924341, 0.9253955427829345, 0.9474620605814121, 0.9492888026500431, 0.9409248393793384, 0.9925682334015613, 1.0212177683122823, 0.988258219789467, 0.9974993657507019, 0.985505248508194, 0.9691975335965581, 0.9816182076967912, 1.0069189782770906, 0.9517295755478234, 0.9151599032622754, 0.9230691448701079, 0.8647948616525551, 0.8391556216439793, 0.7743724386112338, 0.7572152028785227, 0.7235964806336481, 0.6679369953520177, 0.6561309728447834, 0.5698838129697144, 0.535494580645897, 0.47822109618725667, 0.43056754840990097, 0.3796522505801375, 0.30640282243540146, 0.24888140240620638, 0.16101972528613337, 0.11274049727664075, 0.05557651776347804, 0.007767086457276048, -0.07755460024331498, -0.12614497129964494, -0.19339795292170062, -0.2711600718126285, -0.2776459941637687, -0.3736172256217579, -0.43593804695342714, -0.4830804859023277, -0.5178520557861744, -0.6103658903884167, -0.6575171641143672, -0.7155881313104441, -0.7393348420107445, -0.799837168515808, -0.8146339753743045, -0.8413778152003573, -0.8677364988263171, -0.9256726232512349, -0.9606969095668922, -0.960883549581452, -0.9695173165732712, -0.9964459659204626, -1.0068786370846308, -1.027668291543145, -0.9971305351809371, -1.0037618140427316, -0.9890243909537776, -0.9804558226660108, -0.9673632031655514, -0.9379023272572421, -0.934088180148397, -0.9166649874015851, -0.9189964142899317, -0.8429842068469926, -0.7965800116683697, -0.768901463615821, -0.7248123293996247, -0.7065009887084645, -0.6627206902044985, -0.5784566232989523, -0.5478967746908785, -0.4615929887606986, -0.44421982569590407, -0.37499013908010215, -0.3251221604381255, -0.2665142392093253, -0.20527701245193583, -0.10344417870438943, -0.04104891977859873], "name": "original"}], {"title": ""}, {"showLink": true, "linkText": "Export to plot.ly"})});</script>
<div class="gatsby-highlight">
      <pre class="language-none"><code>Epoch 4
Train
.........................................................................................................................................................................................................................................
  Train results batch 0, loss 0.0727791
  Train results batch 20, loss 0.0689376
  Train results batch 40, loss 0.0716537
  Train results batch 60, loss 0.0817372
  Train results batch 80, loss 0.0861643
  Train results batch 100, loss 0.0728834
  Train results batch 120, loss 0.0586975
  Train results batch 140, loss 0.065918
  Train results batch 160, loss 0.0647993
  Train results batch 180, loss 0.0598816
  Train results batch 200, loss 0.0765543
  Train results batch 220, loss 0.0749957
Training results epoch 4, loss 0.000547558254865
  Dev results batch 0, loss 0.0717915
  Dev results batch 20, loss 0.0704993
  Dev results batch 40, loss 0.0613825
  Dev results batch 60, loss 0.0708818
Dev results epoch 4, loss 0.00054083534219
......................................................................................................................................................</code></pre>
      </div>
<div id="ffb3c348-1f58-4a38-bcd5-05ddb4298385" style="height: 525px; width: 100%;" class="plotly-graph-div"></div><script data-my-script="" type="text/javascript">require(["plotly"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL="https://plot.ly";Plotly.newPlot("ffb3c348-1f58-4a38-bcd5-05ddb4298385", [{"type": "scatter", "y": [-0.009999358952767035, 0.0636596725936513, 0.09396539891340987, 0.18736083188739677, 0.24554522107360244, 0.30474662791998464, 0.3540644715650535, 0.427310695217905, 0.5082610045992348, 0.528743319714693, 0.610873715328187, 0.6595808302414805, 0.6714801770744819, 0.7161724630504367, 0.8017361218478947, 0.8227584059757931, 0.8339431865355841, 0.8589156197859245, 0.9032790012741199, 0.9277440963860971, 0.944348827684898, 0.9550259159741353, 0.9939331935171848, 0.9953889438631083, 1.031895777398816, 0.991926769744457, 1.008018984611331, 0.9898874568317324, 0.9660036288267146, 0.9778216806047674, 0.9427574719479263, 0.9160079988143766, 0.903887727996592, 0.9011663035689388, 0.8367907573153219, 0.8260939809053769, 0.7683508266691262, 0.7234202492635545, 0.7121569782970198, 0.6213383920442218, 0.5786361839359868, 0.5380777310192311, 0.46138829067940923, 0.4441318595463302, 0.34964272800620694, 0.3233662082126278, 0.24534658923290942, 0.18524150173515894, 0.12375363227000283, 0.04747565849617937, -0.13251736760139465, -0.2207576483488083, -0.2766819894313812, -0.3349708616733551, -0.3948422074317932, -0.45530396699905396, -0.5153570771217346, -0.5740455389022827, -0.6305102109909058, -0.6840276122093201, -0.7340376973152161, -0.780148983001709, -0.8221283555030823, -0.8598795533180237, -0.89341139793396, -0.92280513048172, -0.948181688785553, -0.969670295715332, -0.9873833060264587, -1.0013952255249023, -1.0117281675338745, -1.0183438062667847, -1.0211433172225952, -1.0199764966964722, -1.0146610736846924, -1.0050135850906372, -0.9908846020698547, -0.9721959233283997, -0.9489693641662598, -0.9213409423828125, -0.8895531296730042, -0.8539313077926636, -0.8148465752601624, -0.772675096988678, -0.7277621030807495, -0.6803986430168152, -0.6308103203773499, -0.5791624188423157, -0.5255725383758545, -0.47013190388679504, -0.4129294753074646, -0.3540731370449066, -0.29370972514152527, -0.23203447461128235, -0.16929474472999573, -0.10578303039073944, -0.04182605445384979, 0.02223263494670391, 0.08604878187179565, 0.14929474890232086, 0.21167197823524475, 0.27291786670684814, 0.33284035325050354, 0.3912566602230072, 0.44805410504341125, 0.5031248927116394, 0.5563919544219971, 0.6077812314033508, 0.6572132110595703, 0.7045738697052002, 0.7496930360794067, 0.7923698425292969, 0.8323301672935486, 0.8692527413368225, 0.9027904868125916, 0.9325827360153198, 0.9582701325416565, 0.9795382022857666, 0.9961339235305786, 1.0078791379928589, 1.0146735906600952, 1.016495943069458, 1.0133945941925049, 1.0054733753204346, 0.9928678870201111, 0.975740373134613, 0.9542497992515564, 0.9285677671432495, 0.8988530039787292, 0.8652647733688354, 0.8279723525047302, 0.787147045135498, 0.7429881691932678, 0.6957244873046875, 0.6456137895584106, 0.5929291844367981, 0.537983238697052, 0.481075257062912, 0.42250731587409973, 0.3625624179840088, 0.30145615339279175, 0.23939071595668793, 0.1765051931142807, 0.11287912726402283, 0.048586685210466385, -0.01635868474841118, -0.08188475668430328, -0.14791589975357056, -0.21427765488624573, -0.28070035576820374, -0.3468030095100403, -0.4121137261390686, -0.47602468729019165, -0.5379052758216858, -0.5971406102180481, -0.6531714200973511, -0.7055335640907288, -0.7538817524909973, -0.7979981899261475, -0.8377822637557983, -0.8732317686080933, -0.9044167995452881, -0.9314497113227844, -0.9544580578804016, -0.9735584855079651, -0.9888359904289246, -1.0003273487091064, -1.0080125331878662, -1.0118110179901123, -1.0115907192230225, -1.007185459136963, -0.998423159122467, -0.9851621985435486, -0.9673260450363159, -0.9449333548545837, -0.9181125164031982, -0.8870972990989685, -0.8522050976753235, -0.8138007521629333, -0.7722581624984741, -0.7279235124588013, -0.681091845035553, -0.6319953203201294, -0.5808061957359314, -0.5276481509208679, -0.47261735796928406, -0.41580528020858765, -0.3573205769062042, -0.2973077595233917, -0.23595887422561646, -0.17351600527763367, -0.11026670038700104, -0.04653269425034523, 0.017346369102597237, 0.08102935552597046, 0.1441900134086609, 0.20652934908866882, 0.26778626441955566, 0.3277421295642853, 0.38622206449508667], "name": "predicted"}, {"type": "scatter", "y": [-0.009999358952767035, 0.0636596725936513, 0.09396539891340987, 0.18736083188739677, 0.24554522107360244, 0.30474662791998464, 0.3540644715650535, 0.427310695217905, 0.5082610045992348, 0.528743319714693, 0.610873715328187, 0.6595808302414805, 0.6714801770744819, 0.7161724630504367, 0.8017361218478947, 0.8227584059757931, 0.8339431865355841, 0.8589156197859245, 0.9032790012741199, 0.9277440963860971, 0.944348827684898, 0.9550259159741353, 0.9939331935171848, 0.9953889438631083, 1.031895777398816, 0.991926769744457, 1.008018984611331, 0.9898874568317324, 0.9660036288267146, 0.9778216806047674, 0.9427574719479263, 0.9160079988143766, 0.903887727996592, 0.9011663035689388, 0.8367907573153219, 0.8260939809053769, 0.7683508266691262, 0.7234202492635545, 0.7121569782970198, 0.6213383920442218, 0.5786361839359868, 0.5380777310192311, 0.46138829067940923, 0.4441318595463302, 0.34964272800620694, 0.3233662082126278, 0.24534658923290942, 0.18524150173515894, 0.12375363227000283, 0.04747565849617937, -0.0037387080934477928, -0.051743377712968094, -0.15214920425224088, -0.19449442529116476, -0.26660097990763254, -0.32123644885610925, -0.38842565077399277, -0.441144767589916, -0.48607544550013165, -0.524011507610602, -0.5891608717435157, -0.6453265897593556, -0.6902171009691433, -0.7271350896313418, -0.7695574187711549, -0.8019483627796674, -0.8705328832225805, -0.8882826334487386, -0.941180390156566, -0.9078491448280709, -0.9832570314642423, -0.942594348092753, -0.9894904989827801, -1.033150433359927, -0.9886850624679566, -1.0280845624475607, -1.0089557387836479, -0.9901244244917171, -0.9947835829309849, -0.9469085583633676, -0.928849321496094, -0.9595811107489216, -0.899135580368624, -0.904911369504552, -0.8489143109698182, -0.7904224335162588, -0.7793467872833741, -0.7288845420182568, -0.6813326718442346, -0.6342428891149459, -0.5838042233620713, -0.5394518302446045, -0.49395160308410146, -0.43786637091879443, -0.3736342591485493, -0.3050754102189696, -0.23006119896148175, -0.15796119062894998, -0.13899400784200322, -0.07349763188343796, -0.022813306341768008, 0.05154018987183014, 0.15715760494770037, 0.20520889719981203, 0.22701288049240798, 0.34376915047710155, 0.39380520967089705, 0.42170607945255223, 0.5051473215112843, 0.517959834594867, 0.5842618115193163, 0.639205485969443, 0.6517609770466205, 0.7524165476525965, 0.7733899011038774, 0.7671879127780509, 0.8378791949103853, 0.8869084817924341, 0.9253955427829345, 0.9474620605814121, 0.9492888026500431, 0.9409248393793384, 0.9925682334015613, 1.0212177683122823, 0.988258219789467, 0.9974993657507019, 0.985505248508194, 0.9691975335965581, 0.9816182076967912, 1.0069189782770906, 0.9517295755478234, 0.9151599032622754, 0.9230691448701079, 0.8647948616525551, 0.8391556216439793, 0.7743724386112338, 0.7572152028785227, 0.7235964806336481, 0.6679369953520177, 0.6561309728447834, 0.5698838129697144, 0.535494580645897, 0.47822109618725667, 0.43056754840990097, 0.3796522505801375, 0.30640282243540146, 0.24888140240620638, 0.16101972528613337, 0.11274049727664075, 0.05557651776347804, 0.007767086457276048, -0.07755460024331498, -0.12614497129964494, -0.19339795292170062, -0.2711600718126285, -0.2776459941637687, -0.3736172256217579, -0.43593804695342714, -0.4830804859023277, -0.5178520557861744, -0.6103658903884167, -0.6575171641143672, -0.7155881313104441, -0.7393348420107445, -0.799837168515808, -0.8146339753743045, -0.8413778152003573, -0.8677364988263171, -0.9256726232512349, -0.9606969095668922, -0.960883549581452, -0.9695173165732712, -0.9964459659204626, -1.0068786370846308, -1.027668291543145, -0.9971305351809371, -1.0037618140427316, -0.9890243909537776, -0.9804558226660108, -0.9673632031655514, -0.9379023272572421, -0.934088180148397, -0.9166649874015851, -0.9189964142899317, -0.8429842068469926, -0.7965800116683697, -0.768901463615821, -0.7248123293996247, -0.7065009887084645, -0.6627206902044985, -0.5784566232989523, -0.5478967746908785, -0.4615929887606986, -0.44421982569590407, -0.37499013908010215, -0.3251221604381255, -0.2665142392093253, -0.20527701245193583, -0.10344417870438943, -0.04104891977859873], "name": "original"}], {"title": ""}, {"showLink": true, "linkText": "Export to plot.ly"})});</script>
<div class="gatsby-highlight">
      <pre class="language-none"><code>Epoch 5
Train
.........................................................................................................................................................................................................................................
  Train results batch 0, loss 0.0688844
  Train results batch 20, loss 0.0541076
  Train results batch 40, loss 0.065995
  Train results batch 60, loss 0.056871
  Train results batch 80, loss 0.0703863
  Train results batch 100, loss 0.0622354
  Train results batch 120, loss 0.0632361
  Train results batch 140, loss 0.0497587
  Train results batch 160, loss 0.0681106
  Train results batch 180, loss 0.0735378
  Train results batch 200, loss 0.0551927
  Train results batch 220, loss 0.0586691
Training results epoch 5, loss 0.000470599653114
  Dev results batch 0, loss 0.0599357
  Dev results batch 20, loss 0.060271
  Dev results batch 40, loss 0.0517052
  Dev results batch 60, loss 0.0637929
Dev results epoch 5, loss 0.000465033017603
......................................................................................................................................................</code></pre>
      </div>
<div id="ddc11add-8893-4793-9b84-4af1e9e3cdc3" style="height: 525px; width: 100%;" class="plotly-graph-div"></div><script data-my-script="" type="text/javascript">require(["plotly"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL="https://plot.ly";Plotly.newPlot("ddc11add-8893-4793-9b84-4af1e9e3cdc3", [{"type": "scatter", "y": [-0.009999358952767035, 0.0636596725936513, 0.09396539891340987, 0.18736083188739677, 0.24554522107360244, 0.30474662791998464, 0.3540644715650535, 0.427310695217905, 0.5082610045992348, 0.528743319714693, 0.610873715328187, 0.6595808302414805, 0.6714801770744819, 0.7161724630504367, 0.8017361218478947, 0.8227584059757931, 0.8339431865355841, 0.8589156197859245, 0.9032790012741199, 0.9277440963860971, 0.944348827684898, 0.9550259159741353, 0.9939331935171848, 0.9953889438631083, 1.031895777398816, 0.991926769744457, 1.008018984611331, 0.9898874568317324, 0.9660036288267146, 0.9778216806047674, 0.9427574719479263, 0.9160079988143766, 0.903887727996592, 0.9011663035689388, 0.8367907573153219, 0.8260939809053769, 0.7683508266691262, 0.7234202492635545, 0.7121569782970198, 0.6213383920442218, 0.5786361839359868, 0.5380777310192311, 0.46138829067940923, 0.4441318595463302, 0.34964272800620694, 0.3233662082126278, 0.24534658923290942, 0.18524150173515894, 0.12375363227000283, 0.04747565849617937, -0.13690879940986633, -0.2249486744403839, -0.280184805393219, -0.33767834305763245, -0.39662474393844604, -0.456028550863266, -0.5149097442626953, -0.5723498463630676, -0.6275380849838257, -0.6798036694526672, -0.7286356091499329, -0.7736813426017761, -0.8147368431091309, -0.851721465587616, -0.8846520781517029, -0.9136110544204712, -0.9387174844741821, -0.9600995182991028, -0.977871298789978, -0.992112398147583, -1.002853512763977, -1.0100675821304321, -1.0136665105819702, -1.0135055780410767, -1.0093988180160522, -1.0011436939239502, -0.9885542392730713, -0.9714982509613037, -0.9499298930168152, -0.9239117503166199, -0.893617570400238, -0.8593158721923828, -0.8213387727737427, -0.7800423502922058, -0.7357676029205322, -0.6888121962547302, -0.6394157409667969, -0.5877569317817688, -0.5339655876159668, -0.478141188621521, -0.4203779697418213, -0.36078786849975586, -0.2995217442512512, -0.23678243160247803, -0.17282909154891968, -0.10797323286533356, -0.042565129697322845, 0.023022033274173737, 0.08841176331043243, 0.15324169397354126, 0.21717943251132965, 0.279929518699646, 0.3412727117538452, 0.4009994864463806, 0.45897817611694336, 0.5150837898254395, 0.5692270398139954, 0.6213245391845703, 0.671290397644043, 0.7190054059028625, 0.7642954587936401, 0.806958019733429, 0.8467202186584473, 0.8832655549049377, 0.9162584543228149, 0.9453554749488831, 0.9702204465866089, 0.9905673861503601, 1.0061755180358887, 1.0168989896774292, 1.0226686000823975, 1.0234898328781128, 1.019432544708252, 1.0106158256530762, 0.9971840977668762, 0.9793023467063904, 0.9571284055709839, 0.9308277368545532, 0.9005506038665771, 0.8664466738700867, 0.8286744356155396, 0.7873944044113159, 0.7427966594696045, 0.6951009035110474, 0.6445592045783997, 0.5914406180381775, 0.5360562801361084, 0.47870662808418274, 0.41969648003578186, 0.35931479930877686, 0.29778510332107544, 0.23532025516033173, 0.1720729023218155, 0.10813994705677032, 0.04361627995967865, -0.021460339426994324, -0.08699017763137817, -0.152870312333107, -0.2189013659954071, -0.2847960889339447, -0.3501684069633484, -0.41455692052841187, -0.4773792028427124, -0.5380463600158691, -0.5959967374801636, -0.6507282257080078, -0.701831042766571, -0.7490079402923584, -0.7920765280723572, -0.8309609889984131, -0.8656735420227051, -0.8962898254394531, -0.9229236841201782, -0.9457026720046997, -0.9647438526153564, -0.9801357388496399, -0.9919214248657227, -1.0000889301300049, -1.0045665502548218, -1.0052262544631958, -1.0018976926803589, -0.994391679763794, -0.982531726360321, -0.9661913514137268, -0.9453259706497192, -0.9199952483177185, -0.890366792678833, -0.8567030429840088, -0.8193297386169434, -0.7785990238189697, -0.7348507642745972, -0.6883845925331116, -0.6394432783126831, -0.5882108807563782, -0.5348219871520996, -0.47938108444213867, -0.4219846725463867, -0.3627459704875946, -0.30181464552879333, -0.23939061164855957, -0.1757289320230484, -0.11113609373569489, -0.0459575429558754, 0.019438080489635468, 0.08467791229486465, 0.14940212666988373, 0.21327902376651764, 0.276015967130661, 0.3373659551143646, 0.3971298038959503], "name": "predicted"}, {"type": "scatter", "y": [-0.009999358952767035, 0.0636596725936513, 0.09396539891340987, 0.18736083188739677, 0.24554522107360244, 0.30474662791998464, 0.3540644715650535, 0.427310695217905, 0.5082610045992348, 0.528743319714693, 0.610873715328187, 0.6595808302414805, 0.6714801770744819, 0.7161724630504367, 0.8017361218478947, 0.8227584059757931, 0.8339431865355841, 0.8589156197859245, 0.9032790012741199, 0.9277440963860971, 0.944348827684898, 0.9550259159741353, 0.9939331935171848, 0.9953889438631083, 1.031895777398816, 0.991926769744457, 1.008018984611331, 0.9898874568317324, 0.9660036288267146, 0.9778216806047674, 0.9427574719479263, 0.9160079988143766, 0.903887727996592, 0.9011663035689388, 0.8367907573153219, 0.8260939809053769, 0.7683508266691262, 0.7234202492635545, 0.7121569782970198, 0.6213383920442218, 0.5786361839359868, 0.5380777310192311, 0.46138829067940923, 0.4441318595463302, 0.34964272800620694, 0.3233662082126278, 0.24534658923290942, 0.18524150173515894, 0.12375363227000283, 0.04747565849617937, -0.0037387080934477928, -0.051743377712968094, -0.15214920425224088, -0.19449442529116476, -0.26660097990763254, -0.32123644885610925, -0.38842565077399277, -0.441144767589916, -0.48607544550013165, -0.524011507610602, -0.5891608717435157, -0.6453265897593556, -0.6902171009691433, -0.7271350896313418, -0.7695574187711549, -0.8019483627796674, -0.8705328832225805, -0.8882826334487386, -0.941180390156566, -0.9078491448280709, -0.9832570314642423, -0.942594348092753, -0.9894904989827801, -1.033150433359927, -0.9886850624679566, -1.0280845624475607, -1.0089557387836479, -0.9901244244917171, -0.9947835829309849, -0.9469085583633676, -0.928849321496094, -0.9595811107489216, -0.899135580368624, -0.904911369504552, -0.8489143109698182, -0.7904224335162588, -0.7793467872833741, -0.7288845420182568, -0.6813326718442346, -0.6342428891149459, -0.5838042233620713, -0.5394518302446045, -0.49395160308410146, -0.43786637091879443, -0.3736342591485493, -0.3050754102189696, -0.23006119896148175, -0.15796119062894998, -0.13899400784200322, -0.07349763188343796, -0.022813306341768008, 0.05154018987183014, 0.15715760494770037, 0.20520889719981203, 0.22701288049240798, 0.34376915047710155, 0.39380520967089705, 0.42170607945255223, 0.5051473215112843, 0.517959834594867, 0.5842618115193163, 0.639205485969443, 0.6517609770466205, 0.7524165476525965, 0.7733899011038774, 0.7671879127780509, 0.8378791949103853, 0.8869084817924341, 0.9253955427829345, 0.9474620605814121, 0.9492888026500431, 0.9409248393793384, 0.9925682334015613, 1.0212177683122823, 0.988258219789467, 0.9974993657507019, 0.985505248508194, 0.9691975335965581, 0.9816182076967912, 1.0069189782770906, 0.9517295755478234, 0.9151599032622754, 0.9230691448701079, 0.8647948616525551, 0.8391556216439793, 0.7743724386112338, 0.7572152028785227, 0.7235964806336481, 0.6679369953520177, 0.6561309728447834, 0.5698838129697144, 0.535494580645897, 0.47822109618725667, 0.43056754840990097, 0.3796522505801375, 0.30640282243540146, 0.24888140240620638, 0.16101972528613337, 0.11274049727664075, 0.05557651776347804, 0.007767086457276048, -0.07755460024331498, -0.12614497129964494, -0.19339795292170062, -0.2711600718126285, -0.2776459941637687, -0.3736172256217579, -0.43593804695342714, -0.4830804859023277, -0.5178520557861744, -0.6103658903884167, -0.6575171641143672, -0.7155881313104441, -0.7393348420107445, -0.799837168515808, -0.8146339753743045, -0.8413778152003573, -0.8677364988263171, -0.9256726232512349, -0.9606969095668922, -0.960883549581452, -0.9695173165732712, -0.9964459659204626, -1.0068786370846308, -1.027668291543145, -0.9971305351809371, -1.0037618140427316, -0.9890243909537776, -0.9804558226660108, -0.9673632031655514, -0.9379023272572421, -0.934088180148397, -0.9166649874015851, -0.9189964142899317, -0.8429842068469926, -0.7965800116683697, -0.768901463615821, -0.7248123293996247, -0.7065009887084645, -0.6627206902044985, -0.5784566232989523, -0.5478967746908785, -0.4615929887606986, -0.44421982569590407, -0.37499013908010215, -0.3251221604381255, -0.2665142392093253, -0.20527701245193583, -0.10344417870438943, -0.04104891977859873], "name": "original"}], {"title": ""}, {"showLink": true, "linkText": "Export to plot.ly"})});</script>
<div class="gatsby-highlight">
      <pre class="language-none"><code>Epoch 6
Train
.........................................................................................................................................................................................................................................
  Train results batch 0, loss 0.053541
  Train results batch 20, loss 0.0699349
  Train results batch 40, loss 0.0553604
  Train results batch 60, loss 0.0620093
  Train results batch 80, loss 0.0647623
  Train results batch 100, loss 0.0518999
  Train results batch 120, loss 0.0632549
  Train results batch 140, loss 0.0673768
  Train results batch 160, loss 0.0645557
  Train results batch 180, loss 0.0533836
  Train results batch 200, loss 0.0603966
  Train results batch 220, loss 0.0555538
Training results epoch 6, loss 0.000448670988889
  Dev results batch 0, loss 0.0567565
  Dev results batch 20, loss 0.0563003
  Dev results batch 40, loss 0.0496434
  Dev results batch 60, loss 0.0620466
Dev results epoch 6, loss 0.000444287580372
......................................................................................................................................................</code></pre>
      </div>
<div id="1e5c37bf-9dc7-45cd-852b-469b8c3c6a23" style="height: 525px; width: 100%;" class="plotly-graph-div"></div><script data-my-script="" type="text/javascript">require(["plotly"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL="https://plot.ly";Plotly.newPlot("1e5c37bf-9dc7-45cd-852b-469b8c3c6a23", [{"type": "scatter", "y": [-0.009999358952767035, 0.0636596725936513, 0.09396539891340987, 0.18736083188739677, 0.24554522107360244, 0.30474662791998464, 0.3540644715650535, 0.427310695217905, 0.5082610045992348, 0.528743319714693, 0.610873715328187, 0.6595808302414805, 0.6714801770744819, 0.7161724630504367, 0.8017361218478947, 0.8227584059757931, 0.8339431865355841, 0.8589156197859245, 0.9032790012741199, 0.9277440963860971, 0.944348827684898, 0.9550259159741353, 0.9939331935171848, 0.9953889438631083, 1.031895777398816, 0.991926769744457, 1.008018984611331, 0.9898874568317324, 0.9660036288267146, 0.9778216806047674, 0.9427574719479263, 0.9160079988143766, 0.903887727996592, 0.9011663035689388, 0.8367907573153219, 0.8260939809053769, 0.7683508266691262, 0.7234202492635545, 0.7121569782970198, 0.6213383920442218, 0.5786361839359868, 0.5380777310192311, 0.46138829067940923, 0.4441318595463302, 0.34964272800620694, 0.3233662082126278, 0.24534658923290942, 0.18524150173515894, 0.12375363227000283, 0.04747565849617937, -0.13954263925552368, -0.22841617465019226, -0.28380000591278076, -0.3413461148738861, -0.4002281427383423, -0.4594370722770691, -0.5179942846298218, -0.5749959945678711, -0.6296560168266296, -0.6813346147537231, -0.7295522093772888, -0.7739859223365784, -0.8144554495811462, -0.8508988618850708, -0.8833444714546204, -0.9118818640708923, -0.9366330504417419, -0.9577274322509766, -0.9752786755561829, -0.9893664717674255, -1.000022530555725, -1.0072214603424072, -1.0108773708343506, -1.010848045349121, -1.0069479942321777, -0.9989715218544006, -0.9867259860038757, -0.9700654745101929, -0.9489263892173767, -0.9233492016792297, -0.8934848308563232, -0.8595808148384094, -0.8219518065452576, -0.7809407711029053, -0.7368807196617126, -0.6900660991668701, -0.6407342553138733, -0.5890641808509827, -0.5351858139038086, -0.4791994094848633, -0.4211992919445038, -0.3612988293170929, -0.29965147376060486, -0.23646476864814758, -0.17200586199760437, -0.10659700632095337, -0.04060259461402893, 0.025588005781173706, 0.09158018231391907, 0.15699318051338196, 0.22147580981254578, 0.2847151756286621, 0.3464774191379547, 0.4065381586551666, 0.4647550582885742, 0.5209928750991821, 0.5751555562019348, 0.627154529094696, 0.6769015789031982, 0.7242773771286011, 0.7691099047660828, 0.8112041354179382, 0.8502973318099976, 0.886089026927948, 0.9182642102241516, 0.9465042948722839, 0.9705001711845398, 0.9899936318397522, 1.0047898292541504, 1.014765739440918, 1.0198692083358765, 1.0201174020767212, 1.0155853033065796, 1.0063931941986084, 0.9926804304122925, 0.9746050238609314, 0.9523148536682129, 0.925963819026947, 0.8956896662712097, 0.8616290092468262, 0.8239262104034424, 0.7827277183532715, 0.7382087707519531, 0.6905748844146729, 0.6400637030601501, 0.5869308710098267, 0.5314765572547913, 0.4739922881126404, 0.4147782325744629, 0.35412198305130005, 0.2922497093677521, 0.2293817698955536, 0.16568315029144287, 0.10126727819442749, 0.03625207766890526, -0.029298800975084305, -0.09525386989116669, -0.16147683560848236, -0.22773481905460358, -0.29371020197868347, -0.3589932918548584, -0.4231119751930237, -0.4854845404624939, -0.5455374121665955, -0.6027365326881409, -0.6566154956817627, -0.706804096698761, -0.7530432343482971, -0.795184314250946, -0.8331782817840576, -0.8670563697814941, -0.8969069123268127, -0.9228499531745911, -0.9450138807296753, -0.9635152816772461, -0.9784384369850159, -0.9898235201835632, -0.9976547360420227, -1.0018575191497803, -1.002301573753357, -0.9988139271736145, -0.9912027716636658, -0.9792872667312622, -0.9629341959953308, -0.9420902729034424, -0.9168031811714172, -0.8872284293174744, -0.8536142706871033, -0.816273033618927, -0.7755444645881653, -0.7317582964897156, -0.6852051019668579, -0.6361205577850342, -0.584683358669281, -0.5310249924659729, -0.47524866461753845, -0.41745150089263916, -0.3577510118484497, -0.29630330204963684, -0.23331840336322784, -0.169064000248909, -0.10386128723621368, -0.0380723811686039, 0.0279169250279665, 0.09371663630008698, 0.15895061194896698, 0.22327232360839844, 0.2863755226135254, 0.3480019271373749, 0.4079422950744629], "name": "predicted"}, {"type": "scatter", "y": [-0.009999358952767035, 0.0636596725936513, 0.09396539891340987, 0.18736083188739677, 0.24554522107360244, 0.30474662791998464, 0.3540644715650535, 0.427310695217905, 0.5082610045992348, 0.528743319714693, 0.610873715328187, 0.6595808302414805, 0.6714801770744819, 0.7161724630504367, 0.8017361218478947, 0.8227584059757931, 0.8339431865355841, 0.8589156197859245, 0.9032790012741199, 0.9277440963860971, 0.944348827684898, 0.9550259159741353, 0.9939331935171848, 0.9953889438631083, 1.031895777398816, 0.991926769744457, 1.008018984611331, 0.9898874568317324, 0.9660036288267146, 0.9778216806047674, 0.9427574719479263, 0.9160079988143766, 0.903887727996592, 0.9011663035689388, 0.8367907573153219, 0.8260939809053769, 0.7683508266691262, 0.7234202492635545, 0.7121569782970198, 0.6213383920442218, 0.5786361839359868, 0.5380777310192311, 0.46138829067940923, 0.4441318595463302, 0.34964272800620694, 0.3233662082126278, 0.24534658923290942, 0.18524150173515894, 0.12375363227000283, 0.04747565849617937, -0.0037387080934477928, -0.051743377712968094, -0.15214920425224088, -0.19449442529116476, -0.26660097990763254, -0.32123644885610925, -0.38842565077399277, -0.441144767589916, -0.48607544550013165, -0.524011507610602, -0.5891608717435157, -0.6453265897593556, -0.6902171009691433, -0.7271350896313418, -0.7695574187711549, -0.8019483627796674, -0.8705328832225805, -0.8882826334487386, -0.941180390156566, -0.9078491448280709, -0.9832570314642423, -0.942594348092753, -0.9894904989827801, -1.033150433359927, -0.9886850624679566, -1.0280845624475607, -1.0089557387836479, -0.9901244244917171, -0.9947835829309849, -0.9469085583633676, -0.928849321496094, -0.9595811107489216, -0.899135580368624, -0.904911369504552, -0.8489143109698182, -0.7904224335162588, -0.7793467872833741, -0.7288845420182568, -0.6813326718442346, -0.6342428891149459, -0.5838042233620713, -0.5394518302446045, -0.49395160308410146, -0.43786637091879443, -0.3736342591485493, -0.3050754102189696, -0.23006119896148175, -0.15796119062894998, -0.13899400784200322, -0.07349763188343796, -0.022813306341768008, 0.05154018987183014, 0.15715760494770037, 0.20520889719981203, 0.22701288049240798, 0.34376915047710155, 0.39380520967089705, 0.42170607945255223, 0.5051473215112843, 0.517959834594867, 0.5842618115193163, 0.639205485969443, 0.6517609770466205, 0.7524165476525965, 0.7733899011038774, 0.7671879127780509, 0.8378791949103853, 0.8869084817924341, 0.9253955427829345, 0.9474620605814121, 0.9492888026500431, 0.9409248393793384, 0.9925682334015613, 1.0212177683122823, 0.988258219789467, 0.9974993657507019, 0.985505248508194, 0.9691975335965581, 0.9816182076967912, 1.0069189782770906, 0.9517295755478234, 0.9151599032622754, 0.9230691448701079, 0.8647948616525551, 0.8391556216439793, 0.7743724386112338, 0.7572152028785227, 0.7235964806336481, 0.6679369953520177, 0.6561309728447834, 0.5698838129697144, 0.535494580645897, 0.47822109618725667, 0.43056754840990097, 0.3796522505801375, 0.30640282243540146, 0.24888140240620638, 0.16101972528613337, 0.11274049727664075, 0.05557651776347804, 0.007767086457276048, -0.07755460024331498, -0.12614497129964494, -0.19339795292170062, -0.2711600718126285, -0.2776459941637687, -0.3736172256217579, -0.43593804695342714, -0.4830804859023277, -0.5178520557861744, -0.6103658903884167, -0.6575171641143672, -0.7155881313104441, -0.7393348420107445, -0.799837168515808, -0.8146339753743045, -0.8413778152003573, -0.8677364988263171, -0.9256726232512349, -0.9606969095668922, -0.960883549581452, -0.9695173165732712, -0.9964459659204626, -1.0068786370846308, -1.027668291543145, -0.9971305351809371, -1.0037618140427316, -0.9890243909537776, -0.9804558226660108, -0.9673632031655514, -0.9379023272572421, -0.934088180148397, -0.9166649874015851, -0.9189964142899317, -0.8429842068469926, -0.7965800116683697, -0.768901463615821, -0.7248123293996247, -0.7065009887084645, -0.6627206902044985, -0.5784566232989523, -0.5478967746908785, -0.4615929887606986, -0.44421982569590407, -0.37499013908010215, -0.3251221604381255, -0.2665142392093253, -0.20527701245193583, -0.10344417870438943, -0.04104891977859873], "name": "original"}], {"title": ""}, {"showLink": true, "linkText": "Export to plot.ly"})});</script>
<div class="gatsby-highlight">
      <pre class="language-none"><code>Epoch 7
Train
.........................................................................................................................................................................................................................................
  Train results batch 0, loss 0.0564441
  Train results batch 20, loss 0.0662476
  Train results batch 40, loss 0.0497547
  Train results batch 60, loss 0.0620312
  Train results batch 80, loss 0.0595999
  Train results batch 100, loss 0.0605202
  Train results batch 120, loss 0.0603222
  Train results batch 140, loss 0.0491505
  Train results batch 160, loss 0.0579644
  Train results batch 180, loss 0.0600865
  Train results batch 200, loss 0.0482739
  Train results batch 220, loss 0.0515458
Training results epoch 7, loss 0.000437071640663
  Dev results batch 0, loss 0.0552906
  Dev results batch 20, loss 0.0541909
  Dev results batch 40, loss 0.0487828
  Dev results batch 60, loss 0.061333
Dev results epoch 7, loss 0.000433660682277
......................................................................................................................................................</code></pre>
      </div>
<div id="28c46c08-2797-4af1-997e-801ba2ff8ec9" style="height: 525px; width: 100%;" class="plotly-graph-div"></div><script data-my-script="" type="text/javascript">require(["plotly"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL="https://plot.ly";Plotly.newPlot("28c46c08-2797-4af1-997e-801ba2ff8ec9", [{"type": "scatter", "y": [-0.009999358952767035, 0.0636596725936513, 0.09396539891340987, 0.18736083188739677, 0.24554522107360244, 0.30474662791998464, 0.3540644715650535, 0.427310695217905, 0.5082610045992348, 0.528743319714693, 0.610873715328187, 0.6595808302414805, 0.6714801770744819, 0.7161724630504367, 0.8017361218478947, 0.8227584059757931, 0.8339431865355841, 0.8589156197859245, 0.9032790012741199, 0.9277440963860971, 0.944348827684898, 0.9550259159741353, 0.9939331935171848, 0.9953889438631083, 1.031895777398816, 0.991926769744457, 1.008018984611331, 0.9898874568317324, 0.9660036288267146, 0.9778216806047674, 0.9427574719479263, 0.9160079988143766, 0.903887727996592, 0.9011663035689388, 0.8367907573153219, 0.8260939809053769, 0.7683508266691262, 0.7234202492635545, 0.7121569782970198, 0.6213383920442218, 0.5786361839359868, 0.5380777310192311, 0.46138829067940923, 0.4441318595463302, 0.34964272800620694, 0.3233662082126278, 0.24534658923290942, 0.18524150173515894, 0.12375363227000283, 0.04747565849617937, -0.1418675184249878, -0.23148909211158752, -0.2870100736618042, -0.3446209132671356, -0.40347811579704285, -0.4625629186630249, -0.5208979249000549, -0.57759028673172, -0.6318722367286682, -0.6831268668174744, -0.7308977246284485, -0.7748836874961853, -0.8149221539497375, -0.8509641885757446, -0.8830471634864807, -0.9112652540206909, -0.9357427954673767, -0.9566090703010559, -0.973976731300354, -0.9879239201545715, -0.9984814524650574, -1.0056240558624268, -1.0092658996582031, -1.0092662572860718, -1.0054408311843872, -0.9975844025611877, -0.9855020642280579, -0.9690448045730591, -0.9481423497200012, -0.9228261709213257, -0.8932366967201233, -0.8596102595329285, -0.8222509026527405, -0.7814930081367493, -0.7376627326011658, -0.6910491585731506, -0.6418852210044861, -0.5903468728065491, -0.536561131477356, -0.48062455654144287, -0.4226277470588684, -0.3626805245876312, -0.3009333908557892, -0.2375921905040741, -0.17292475700378418, -0.10725639760494232, -0.040957972407341, 0.025572624057531357, 0.0919288769364357, 0.15771698951721191, 0.2225712239742279, 0.28616398572921753, 0.3482479453086853, 0.4085848927497864, 0.46702131628990173, 0.5234115719795227, 0.5776517987251282, 0.6296480298042297, 0.6793095469474792, 0.7265174388885498, 0.771102249622345, 0.8128753900527954, 0.8515843749046326, 0.8869420289993286, 0.9186500906944275, 0.9464083909988403, 0.9699276685714722, 0.9889686703681946, 1.003353238105774, 1.0129727125167847, 1.0177843570709229, 1.0178120136260986, 1.0131317377090454, 1.0038622617721558, 0.9901387691497803, 0.9721127152442932, 0.9499238729476929, 0.9237172603607178, 0.8936205506324768, 0.8597593307495117, 0.8222662210464478, 0.7812752723693848, 0.7369483709335327, 0.6894774436950684, 0.639087438583374, 0.5860223770141602, 0.5305732488632202, 0.47302520275115967, 0.4136759638786316, 0.3528147041797638, 0.29067230224609375, 0.22747889161109924, 0.16341222822666168, 0.09860178828239441, 0.03318477049469948, -0.03275362774729729, -0.09905906021595001, -0.16557207703590393, -0.2320374995470047, -0.29811984300613403, -0.3633973002433777, -0.4273937940597534, -0.4895305037498474, -0.5492467284202576, -0.6060274243354797, -0.6594296097755432, -0.7091079354286194, -0.7548267245292664, -0.7964575886726379, -0.8339666128158569, -0.8673965334892273, -0.8968417048454285, -0.9224254488945007, -0.9442769885063171, -0.9625108242034912, -0.9772103428840637, -0.9884130358695984, -0.9961017966270447, -1.0002009868621826, -1.0005801916122437, -0.9970675110816956, -0.9894703030586243, -0.9776079058647156, -0.9613448977470398, -0.9406235814094543, -0.9154861569404602, -0.8860802054405212, -0.8526447415351868, -0.8154836893081665, -0.77492755651474, -0.7312988638877869, -0.6848810911178589, -0.635904848575592, -0.5845439434051514, -0.5309256911277771, -0.47514858841896057, -0.4173077344894409, -0.35751670598983765, -0.29593056440353394, -0.23275907337665558, -0.16827234625816345, -0.10279570519924164, -0.036698561161756516, 0.02962421625852585, 0.09577159583568573, 0.16135495901107788, 0.22601434588432312, 0.28943032026290894, 0.3513314127922058, 0.41149669885635376], "name": "predicted"}, {"type": "scatter", "y": [-0.009999358952767035, 0.0636596725936513, 0.09396539891340987, 0.18736083188739677, 0.24554522107360244, 0.30474662791998464, 0.3540644715650535, 0.427310695217905, 0.5082610045992348, 0.528743319714693, 0.610873715328187, 0.6595808302414805, 0.6714801770744819, 0.7161724630504367, 0.8017361218478947, 0.8227584059757931, 0.8339431865355841, 0.8589156197859245, 0.9032790012741199, 0.9277440963860971, 0.944348827684898, 0.9550259159741353, 0.9939331935171848, 0.9953889438631083, 1.031895777398816, 0.991926769744457, 1.008018984611331, 0.9898874568317324, 0.9660036288267146, 0.9778216806047674, 0.9427574719479263, 0.9160079988143766, 0.903887727996592, 0.9011663035689388, 0.8367907573153219, 0.8260939809053769, 0.7683508266691262, 0.7234202492635545, 0.7121569782970198, 0.6213383920442218, 0.5786361839359868, 0.5380777310192311, 0.46138829067940923, 0.4441318595463302, 0.34964272800620694, 0.3233662082126278, 0.24534658923290942, 0.18524150173515894, 0.12375363227000283, 0.04747565849617937, -0.0037387080934477928, -0.051743377712968094, -0.15214920425224088, -0.19449442529116476, -0.26660097990763254, -0.32123644885610925, -0.38842565077399277, -0.441144767589916, -0.48607544550013165, -0.524011507610602, -0.5891608717435157, -0.6453265897593556, -0.6902171009691433, -0.7271350896313418, -0.7695574187711549, -0.8019483627796674, -0.8705328832225805, -0.8882826334487386, -0.941180390156566, -0.9078491448280709, -0.9832570314642423, -0.942594348092753, -0.9894904989827801, -1.033150433359927, -0.9886850624679566, -1.0280845624475607, -1.0089557387836479, -0.9901244244917171, -0.9947835829309849, -0.9469085583633676, -0.928849321496094, -0.9595811107489216, -0.899135580368624, -0.904911369504552, -0.8489143109698182, -0.7904224335162588, -0.7793467872833741, -0.7288845420182568, -0.6813326718442346, -0.6342428891149459, -0.5838042233620713, -0.5394518302446045, -0.49395160308410146, -0.43786637091879443, -0.3736342591485493, -0.3050754102189696, -0.23006119896148175, -0.15796119062894998, -0.13899400784200322, -0.07349763188343796, -0.022813306341768008, 0.05154018987183014, 0.15715760494770037, 0.20520889719981203, 0.22701288049240798, 0.34376915047710155, 0.39380520967089705, 0.42170607945255223, 0.5051473215112843, 0.517959834594867, 0.5842618115193163, 0.639205485969443, 0.6517609770466205, 0.7524165476525965, 0.7733899011038774, 0.7671879127780509, 0.8378791949103853, 0.8869084817924341, 0.9253955427829345, 0.9474620605814121, 0.9492888026500431, 0.9409248393793384, 0.9925682334015613, 1.0212177683122823, 0.988258219789467, 0.9974993657507019, 0.985505248508194, 0.9691975335965581, 0.9816182076967912, 1.0069189782770906, 0.9517295755478234, 0.9151599032622754, 0.9230691448701079, 0.8647948616525551, 0.8391556216439793, 0.7743724386112338, 0.7572152028785227, 0.7235964806336481, 0.6679369953520177, 0.6561309728447834, 0.5698838129697144, 0.535494580645897, 0.47822109618725667, 0.43056754840990097, 0.3796522505801375, 0.30640282243540146, 0.24888140240620638, 0.16101972528613337, 0.11274049727664075, 0.05557651776347804, 0.007767086457276048, -0.07755460024331498, -0.12614497129964494, -0.19339795292170062, -0.2711600718126285, -0.2776459941637687, -0.3736172256217579, -0.43593804695342714, -0.4830804859023277, -0.5178520557861744, -0.6103658903884167, -0.6575171641143672, -0.7155881313104441, -0.7393348420107445, -0.799837168515808, -0.8146339753743045, -0.8413778152003573, -0.8677364988263171, -0.9256726232512349, -0.9606969095668922, -0.960883549581452, -0.9695173165732712, -0.9964459659204626, -1.0068786370846308, -1.027668291543145, -0.9971305351809371, -1.0037618140427316, -0.9890243909537776, -0.9804558226660108, -0.9673632031655514, -0.9379023272572421, -0.934088180148397, -0.9166649874015851, -0.9189964142899317, -0.8429842068469926, -0.7965800116683697, -0.768901463615821, -0.7248123293996247, -0.7065009887084645, -0.6627206902044985, -0.5784566232989523, -0.5478967746908785, -0.4615929887606986, -0.44421982569590407, -0.37499013908010215, -0.3251221604381255, -0.2665142392093253, -0.20527701245193583, -0.10344417870438943, -0.04104891977859873], "name": "original"}], {"title": ""}, {"showLink": true, "linkText": "Export to plot.ly"})});</script>
<div class="gatsby-highlight">
      <pre class="language-none"><code>Epoch 8
Train
.........................................................................................................................................................................................................................................
  Train results batch 0, loss 0.058103
  Train results batch 20, loss 0.0501114
  Train results batch 40, loss 0.0478091
  Train results batch 60, loss 0.0674866
  Train results batch 80, loss 0.0530147
  Train results batch 100, loss 0.0548249
  Train results batch 120, loss 0.0628589
  Train results batch 140, loss 0.0645167
  Train results batch 160, loss 0.0632368
  Train results batch 180, loss 0.0476007
  Train results batch 200, loss 0.0471682
  Train results batch 220, loss 0.0493235
Training results epoch 8, loss 0.00043170396977
  Dev results batch 0, loss 0.055131
  Dev results batch 20, loss 0.0531145
  Dev results batch 40, loss 0.0483831
  Dev results batch 60, loss 0.0610029
Dev results epoch 8, loss 0.000428519506533
......................................................................................................................................................</code></pre>
      </div>
<div id="132605b0-1eb5-44b2-a362-c59fd4013051" style="height: 525px; width: 100%;" class="plotly-graph-div"></div><script data-my-script="" type="text/javascript">require(["plotly"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL="https://plot.ly";Plotly.newPlot("132605b0-1eb5-44b2-a362-c59fd4013051", [{"type": "scatter", "y": [-0.009999358952767035, 0.0636596725936513, 0.09396539891340987, 0.18736083188739677, 0.24554522107360244, 0.30474662791998464, 0.3540644715650535, 0.427310695217905, 0.5082610045992348, 0.528743319714693, 0.610873715328187, 0.6595808302414805, 0.6714801770744819, 0.7161724630504367, 0.8017361218478947, 0.8227584059757931, 0.8339431865355841, 0.8589156197859245, 0.9032790012741199, 0.9277440963860971, 0.944348827684898, 0.9550259159741353, 0.9939331935171848, 0.9953889438631083, 1.031895777398816, 0.991926769744457, 1.008018984611331, 0.9898874568317324, 0.9660036288267146, 0.9778216806047674, 0.9427574719479263, 0.9160079988143766, 0.903887727996592, 0.9011663035689388, 0.8367907573153219, 0.8260939809053769, 0.7683508266691262, 0.7234202492635545, 0.7121569782970198, 0.6213383920442218, 0.5786361839359868, 0.5380777310192311, 0.46138829067940923, 0.4441318595463302, 0.34964272800620694, 0.3233662082126278, 0.24534658923290942, 0.18524150173515894, 0.12375363227000283, 0.04747565849617937, -0.14460188150405884, -0.2348237931728363, -0.2904691696166992, -0.34815433621406555, -0.4070209562778473, -0.4660416841506958, -0.5242389440536499, -0.580727219581604, -0.6347522139549255, -0.6857133507728577, -0.733171820640564, -0.7768416404724121, -0.8165733814239502, -0.8523277640342712, -0.8841477036476135, -0.9121310114860535, -0.9364017844200134, -0.9570876955986023, -0.9742980599403381, -0.988107442855835, -0.9985419511795044, -1.0055714845657349, -1.0091063976287842, -1.009002447128296, -1.0050735473632812, -0.9971141815185547, -0.9849315881729126, -0.9683793187141418, -0.9473904371261597, -0.9220006465911865, -0.8923532962799072, -0.858686089515686, -0.8213027119636536, -0.7805348038673401, -0.7367041110992432, -0.6900940537452698, -0.6409322619438171, -0.589387834072113, -0.5355817675590515, -0.47960543632507324, -0.4215444028377533, -0.36150476336479187, -0.29963451623916626, -0.23613864183425903, -0.17128583788871765, -0.10540395975112915, -0.03886867314577103, 0.027914904057979584, 0.09453298896551132, 0.16058212518692017, 0.22568680346012115, 0.2895086705684662, 0.35179194808006287, 0.4122879207134247, 0.47083547711372375, 0.5272812843322754, 0.5815150737762451, 0.6334387063980103, 0.6829580068588257, 0.7299526929855347, 0.7742542624473572, 0.8156775236129761, 0.8539761304855347, 0.8888726830482483, 0.9200813174247742, 0.9473171830177307, 0.9703071713447571, 0.9888283610343933, 1.002718448638916, 1.0118811130523682, 1.0162841081619263, 1.0159560441970825, 1.010977029800415, 1.0014642477035522, 0.9875497221946716, 0.9693797826766968, 0.9470869302749634, 0.9208081960678101, 0.890663206577301, 0.8567680716514587, 0.8192464113235474, 0.7782226204872131, 0.7338488698005676, 0.686308741569519, 0.635818600654602, 0.5826152563095093, 0.526984691619873, 0.46920886635780334, 0.4095846712589264, 0.3484037518501282, 0.28590139746665955, 0.22231537103652954, 0.1578327864408493, 0.09259644895792007, 0.026758676394820213, -0.03957769274711609, -0.10623762011528015, -0.17304091155529022, -0.23971176147460938, -0.30589625239372253, -0.37115952372550964, -0.43502023816108704, -0.49690189957618713, -0.5562549829483032, -0.6125824451446533, -0.6654640436172485, -0.7145791053771973, -0.7597143650054932, -0.8007617592811584, -0.8377038836479187, -0.8705934286117554, -0.8995311260223389, -0.9246422052383423, -0.9460542798042297, -0.9638770818710327, -0.9781872034072876, -0.9890143871307373, -0.9963327646255493, -1.000058889389038, -1.0000561475753784, -0.996147871017456, -0.9881422519683838, -0.9758623838424683, -0.9591803550720215, -0.9380496144294739, -0.9125233292579651, -0.8827593326568604, -0.849003791809082, -0.8115629553794861, -0.770764946937561, -0.726925790309906, -0.6803197860717773, -0.6311673521995544, -0.5796319246292114, -0.52583247423172, -0.4698610305786133, -0.4118082821369171, -0.3517872989177704, -0.2899540364742279, -0.22652219235897064, -0.1617671698331833, -0.09602117538452148, -0.029660912230610847, 0.03691112995147705, 0.10328590869903564, 0.16906750202178955, 0.23388877511024475, 0.2974235713481903, 0.35939425230026245, 0.41957417130470276], "name": "predicted"}, {"type": "scatter", "y": [-0.009999358952767035, 0.0636596725936513, 0.09396539891340987, 0.18736083188739677, 0.24554522107360244, 0.30474662791998464, 0.3540644715650535, 0.427310695217905, 0.5082610045992348, 0.528743319714693, 0.610873715328187, 0.6595808302414805, 0.6714801770744819, 0.7161724630504367, 0.8017361218478947, 0.8227584059757931, 0.8339431865355841, 0.8589156197859245, 0.9032790012741199, 0.9277440963860971, 0.944348827684898, 0.9550259159741353, 0.9939331935171848, 0.9953889438631083, 1.031895777398816, 0.991926769744457, 1.008018984611331, 0.9898874568317324, 0.9660036288267146, 0.9778216806047674, 0.9427574719479263, 0.9160079988143766, 0.903887727996592, 0.9011663035689388, 0.8367907573153219, 0.8260939809053769, 0.7683508266691262, 0.7234202492635545, 0.7121569782970198, 0.6213383920442218, 0.5786361839359868, 0.5380777310192311, 0.46138829067940923, 0.4441318595463302, 0.34964272800620694, 0.3233662082126278, 0.24534658923290942, 0.18524150173515894, 0.12375363227000283, 0.04747565849617937, -0.0037387080934477928, -0.051743377712968094, -0.15214920425224088, -0.19449442529116476, -0.26660097990763254, -0.32123644885610925, -0.38842565077399277, -0.441144767589916, -0.48607544550013165, -0.524011507610602, -0.5891608717435157, -0.6453265897593556, -0.6902171009691433, -0.7271350896313418, -0.7695574187711549, -0.8019483627796674, -0.8705328832225805, -0.8882826334487386, -0.941180390156566, -0.9078491448280709, -0.9832570314642423, -0.942594348092753, -0.9894904989827801, -1.033150433359927, -0.9886850624679566, -1.0280845624475607, -1.0089557387836479, -0.9901244244917171, -0.9947835829309849, -0.9469085583633676, -0.928849321496094, -0.9595811107489216, -0.899135580368624, -0.904911369504552, -0.8489143109698182, -0.7904224335162588, -0.7793467872833741, -0.7288845420182568, -0.6813326718442346, -0.6342428891149459, -0.5838042233620713, -0.5394518302446045, -0.49395160308410146, -0.43786637091879443, -0.3736342591485493, -0.3050754102189696, -0.23006119896148175, -0.15796119062894998, -0.13899400784200322, -0.07349763188343796, -0.022813306341768008, 0.05154018987183014, 0.15715760494770037, 0.20520889719981203, 0.22701288049240798, 0.34376915047710155, 0.39380520967089705, 0.42170607945255223, 0.5051473215112843, 0.517959834594867, 0.5842618115193163, 0.639205485969443, 0.6517609770466205, 0.7524165476525965, 0.7733899011038774, 0.7671879127780509, 0.8378791949103853, 0.8869084817924341, 0.9253955427829345, 0.9474620605814121, 0.9492888026500431, 0.9409248393793384, 0.9925682334015613, 1.0212177683122823, 0.988258219789467, 0.9974993657507019, 0.985505248508194, 0.9691975335965581, 0.9816182076967912, 1.0069189782770906, 0.9517295755478234, 0.9151599032622754, 0.9230691448701079, 0.8647948616525551, 0.8391556216439793, 0.7743724386112338, 0.7572152028785227, 0.7235964806336481, 0.6679369953520177, 0.6561309728447834, 0.5698838129697144, 0.535494580645897, 0.47822109618725667, 0.43056754840990097, 0.3796522505801375, 0.30640282243540146, 0.24888140240620638, 0.16101972528613337, 0.11274049727664075, 0.05557651776347804, 0.007767086457276048, -0.07755460024331498, -0.12614497129964494, -0.19339795292170062, -0.2711600718126285, -0.2776459941637687, -0.3736172256217579, -0.43593804695342714, -0.4830804859023277, -0.5178520557861744, -0.6103658903884167, -0.6575171641143672, -0.7155881313104441, -0.7393348420107445, -0.799837168515808, -0.8146339753743045, -0.8413778152003573, -0.8677364988263171, -0.9256726232512349, -0.9606969095668922, -0.960883549581452, -0.9695173165732712, -0.9964459659204626, -1.0068786370846308, -1.027668291543145, -0.9971305351809371, -1.0037618140427316, -0.9890243909537776, -0.9804558226660108, -0.9673632031655514, -0.9379023272572421, -0.934088180148397, -0.9166649874015851, -0.9189964142899317, -0.8429842068469926, -0.7965800116683697, -0.768901463615821, -0.7248123293996247, -0.7065009887084645, -0.6627206902044985, -0.5784566232989523, -0.5478967746908785, -0.4615929887606986, -0.44421982569590407, -0.37499013908010215, -0.3251221604381255, -0.2665142392093253, -0.20527701245193583, -0.10344417870438943, -0.04104891977859873], "name": "original"}], {"title": ""}, {"showLink": true, "linkText": "Export to plot.ly"})});</script>
<div class="gatsby-highlight">
      <pre class="language-none"><code>Epoch 9
Train
.........................................................................................................................................................................................................................................
  Train results batch 0, loss 0.0510024
  Train results batch 20, loss 0.0479287
  Train results batch 40, loss 0.0584473
  Train results batch 60, loss 0.0485359
  Train results batch 80, loss 0.0615271
  Train results batch 100, loss 0.0570304
  Train results batch 120, loss 0.0464874
  Train results batch 140, loss 0.0617962
  Train results batch 160, loss 0.0486729
  Train results batch 180, loss 0.0585998
  Train results batch 200, loss 0.045459
  Train results batch 220, loss 0.0659634
Training results epoch 9, loss 0.000429875803059
  Dev results batch 0, loss 0.0545206
  Dev results batch 20, loss 0.0513194
  Dev results batch 40, loss 0.0483249
  Dev results batch 60, loss 0.0622594
Dev results epoch 9, loss 0.000427906684893
......................................................................................................................................................</code></pre>
      </div>
<div id="cf40cf3b-cdc4-4ed4-852b-86ea123bb95f" style="height: 525px; width: 100%;" class="plotly-graph-div"></div><script data-my-script="" type="text/javascript">require(["plotly"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL="https://plot.ly";Plotly.newPlot("cf40cf3b-cdc4-4ed4-852b-86ea123bb95f", [{"type": "scatter", "y": [-0.009999358952767035, 0.0636596725936513, 0.09396539891340987, 0.18736083188739677, 0.24554522107360244, 0.30474662791998464, 0.3540644715650535, 0.427310695217905, 0.5082610045992348, 0.528743319714693, 0.610873715328187, 0.6595808302414805, 0.6714801770744819, 0.7161724630504367, 0.8017361218478947, 0.8227584059757931, 0.8339431865355841, 0.8589156197859245, 0.9032790012741199, 0.9277440963860971, 0.944348827684898, 0.9550259159741353, 0.9939331935171848, 0.9953889438631083, 1.031895777398816, 0.991926769744457, 1.008018984611331, 0.9898874568317324, 0.9660036288267146, 0.9778216806047674, 0.9427574719479263, 0.9160079988143766, 0.903887727996592, 0.9011663035689388, 0.8367907573153219, 0.8260939809053769, 0.7683508266691262, 0.7234202492635545, 0.7121569782970198, 0.6213383920442218, 0.5786361839359868, 0.5380777310192311, 0.46138829067940923, 0.4441318595463302, 0.34964272800620694, 0.3233662082126278, 0.24534658923290942, 0.18524150173515894, 0.12375363227000283, 0.04747565849617937, -0.14270515739917755, -0.23368464410305023, -0.28937485814094543, -0.347047358751297, -0.40585362911224365, -0.4647759199142456, -0.5228486657142639, -0.5792010426521301, -0.6330925822257996, -0.6839351058006287, -0.731298565864563, -0.7749040126800537, -0.814604640007019, -0.850361704826355, -0.8822172284126282, -0.9102660417556763, -0.9346293210983276, -0.9554308652877808, -0.972777247428894, -0.9867396354675293, -0.9973416328430176, -1.0045515298843384, -1.0082783699035645, -1.0083777904510498, -1.0046641826629639, -0.9969332218170166, -0.9849926233291626, -0.9686970710754395, -0.9479800462722778, -0.9228765964508057, -0.8935279846191406, -0.8601699471473694, -0.8231033086776733, -0.7826565504074097, -0.7391493320465088, -0.6928628087043762, -0.6440213322639465, -0.5927913784980774, -0.5392893552780151, -0.483600914478302, -0.4258041977882385, -0.36599621176719666, -0.3043150305747986, -0.24095582962036133, -0.1761784553527832, -0.11030478775501251, -0.04370749741792679, 0.023207683116197586, 0.09002181887626648, 0.15632343292236328, 0.22172552347183228, 0.2858771085739136, 0.34850841760635376, 0.40935659408569336, 0.4682479202747345, 0.5250170230865479, 0.5795451998710632, 0.6317276954650879, 0.6814691424369812, 0.7286495566368103, 0.7731044292449951, 0.8146557807922363, 0.8530665636062622, 0.8880693316459656, 0.9193906784057617, 0.9467569589614868, 0.9699054956436157, 0.9886229038238525, 1.002753734588623, 1.0122066736221313, 1.0169519186019897, 1.017020344734192, 1.0124903917312622, 1.0034782886505127, 0.9901138544082642, 0.9725404977798462, 0.9508875012397766, 0.9252869486808777, 0.8958529829978943, 0.862694263458252, 0.825924277305603, 0.7856553196907043, 0.7420254349708557, 0.6952019929885864, 0.6453854441642761, 0.5927984118461609, 0.5377137064933777, 0.4804058074951172, 0.42116862535476685, 0.3602955937385559, 0.2980290949344635, 0.23461684584617615, 0.1702595204114914, 0.1051132082939148, 0.03934219479560852, -0.02694217674434185, -0.09356150776147842, -0.16033872961997986, -0.22700729966163635, -0.2932279109954834, -0.35858288407325745, -0.4226074516773224, -0.48473840951919556, -0.5444324612617493, -0.601193368434906, -0.6545946598052979, -0.7043044567108154, -0.7500960826873779, -0.7918457388877869, -0.8295215368270874, -0.8631640076637268, -0.8928650617599487, -0.9187436699867249, -0.9409255385398865, -0.9595215320587158, -0.9746127128601074, -0.9862350225448608, -0.9943720102310181, -0.9989491701126099, -0.9998384714126587, -0.996869683265686, -0.9898524284362793, -0.9786049723625183, -0.9629892110824585, -0.9429416060447693, -0.9184954166412354, -0.8897883892059326, -0.857049822807312, -0.8205747604370117, -0.780687689781189, -0.737706184387207, -0.6919118165969849, -0.6435324549674988, -0.5927385091781616, -0.5396512150764465, -0.48436063528060913, -0.4269481599330902, -0.3675117492675781, -0.3061887323856354, -0.2431715428829193, -0.17871515452861786, -0.1131359338760376, -0.04680001735687256, 0.01989240013062954, 0.08652772754430771, 0.15269841253757477, 0.21802030503749847, 0.28214573860168457, 0.3447739779949188, 0.4056546688079834], "name": "predicted"}, {"type": "scatter", "y": [-0.009999358952767035, 0.0636596725936513, 0.09396539891340987, 0.18736083188739677, 0.24554522107360244, 0.30474662791998464, 0.3540644715650535, 0.427310695217905, 0.5082610045992348, 0.528743319714693, 0.610873715328187, 0.6595808302414805, 0.6714801770744819, 0.7161724630504367, 0.8017361218478947, 0.8227584059757931, 0.8339431865355841, 0.8589156197859245, 0.9032790012741199, 0.9277440963860971, 0.944348827684898, 0.9550259159741353, 0.9939331935171848, 0.9953889438631083, 1.031895777398816, 0.991926769744457, 1.008018984611331, 0.9898874568317324, 0.9660036288267146, 0.9778216806047674, 0.9427574719479263, 0.9160079988143766, 0.903887727996592, 0.9011663035689388, 0.8367907573153219, 0.8260939809053769, 0.7683508266691262, 0.7234202492635545, 0.7121569782970198, 0.6213383920442218, 0.5786361839359868, 0.5380777310192311, 0.46138829067940923, 0.4441318595463302, 0.34964272800620694, 0.3233662082126278, 0.24534658923290942, 0.18524150173515894, 0.12375363227000283, 0.04747565849617937, -0.0037387080934477928, -0.051743377712968094, -0.15214920425224088, -0.19449442529116476, -0.26660097990763254, -0.32123644885610925, -0.38842565077399277, -0.441144767589916, -0.48607544550013165, -0.524011507610602, -0.5891608717435157, -0.6453265897593556, -0.6902171009691433, -0.7271350896313418, -0.7695574187711549, -0.8019483627796674, -0.8705328832225805, -0.8882826334487386, -0.941180390156566, -0.9078491448280709, -0.9832570314642423, -0.942594348092753, -0.9894904989827801, -1.033150433359927, -0.9886850624679566, -1.0280845624475607, -1.0089557387836479, -0.9901244244917171, -0.9947835829309849, -0.9469085583633676, -0.928849321496094, -0.9595811107489216, -0.899135580368624, -0.904911369504552, -0.8489143109698182, -0.7904224335162588, -0.7793467872833741, -0.7288845420182568, -0.6813326718442346, -0.6342428891149459, -0.5838042233620713, -0.5394518302446045, -0.49395160308410146, -0.43786637091879443, -0.3736342591485493, -0.3050754102189696, -0.23006119896148175, -0.15796119062894998, -0.13899400784200322, -0.07349763188343796, -0.022813306341768008, 0.05154018987183014, 0.15715760494770037, 0.20520889719981203, 0.22701288049240798, 0.34376915047710155, 0.39380520967089705, 0.42170607945255223, 0.5051473215112843, 0.517959834594867, 0.5842618115193163, 0.639205485969443, 0.6517609770466205, 0.7524165476525965, 0.7733899011038774, 0.7671879127780509, 0.8378791949103853, 0.8869084817924341, 0.9253955427829345, 0.9474620605814121, 0.9492888026500431, 0.9409248393793384, 0.9925682334015613, 1.0212177683122823, 0.988258219789467, 0.9974993657507019, 0.985505248508194, 0.9691975335965581, 0.9816182076967912, 1.0069189782770906, 0.9517295755478234, 0.9151599032622754, 0.9230691448701079, 0.8647948616525551, 0.8391556216439793, 0.7743724386112338, 0.7572152028785227, 0.7235964806336481, 0.6679369953520177, 0.6561309728447834, 0.5698838129697144, 0.535494580645897, 0.47822109618725667, 0.43056754840990097, 0.3796522505801375, 0.30640282243540146, 0.24888140240620638, 0.16101972528613337, 0.11274049727664075, 0.05557651776347804, 0.007767086457276048, -0.07755460024331498, -0.12614497129964494, -0.19339795292170062, -0.2711600718126285, -0.2776459941637687, -0.3736172256217579, -0.43593804695342714, -0.4830804859023277, -0.5178520557861744, -0.6103658903884167, -0.6575171641143672, -0.7155881313104441, -0.7393348420107445, -0.799837168515808, -0.8146339753743045, -0.8413778152003573, -0.8677364988263171, -0.9256726232512349, -0.9606969095668922, -0.960883549581452, -0.9695173165732712, -0.9964459659204626, -1.0068786370846308, -1.027668291543145, -0.9971305351809371, -1.0037618140427316, -0.9890243909537776, -0.9804558226660108, -0.9673632031655514, -0.9379023272572421, -0.934088180148397, -0.9166649874015851, -0.9189964142899317, -0.8429842068469926, -0.7965800116683697, -0.768901463615821, -0.7248123293996247, -0.7065009887084645, -0.6627206902044985, -0.5784566232989523, -0.5478967746908785, -0.4615929887606986, -0.44421982569590407, -0.37499013908010215, -0.3251221604381255, -0.2665142392093253, -0.20527701245193583, -0.10344417870438943, -0.04104891977859873], "name": "original"}], {"title": ""}, {"showLink": true, "linkText": "Export to plot.ly"})});</script>
<div class="gatsby-highlight">
      <pre class="language-none"><code>......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................</code></pre>
      </div>
<div id="fd13cde7-4cfe-44dd-a3ab-d9109014d589" style="height: 525px; width: 100%;" class="plotly-graph-div"></div><script data-my-script="" type="text/javascript">require(["plotly"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL="https://plot.ly";Plotly.newPlot("fd13cde7-4cfe-44dd-a3ab-d9109014d589", [{"type": "scatter", "y": [-0.009999358952767035, 0.0636596725936513, 0.09396539891340987, 0.18736083188739677, 0.24554522107360244, 0.30474662791998464, 0.3540644715650535, 0.427310695217905, 0.5082610045992348, 0.528743319714693, 0.610873715328187, 0.6595808302414805, 0.6714801770744819, 0.7161724630504367, 0.8017361218478947, 0.8227584059757931, 0.8339431865355841, 0.8589156197859245, 0.9032790012741199, 0.9277440963860971, 0.944348827684898, 0.9550259159741353, 0.9939331935171848, 0.9953889438631083, 1.031895777398816, 0.991926769744457, 1.008018984611331, 0.9898874568317324, 0.9660036288267146, 0.9778216806047674, 0.9427574719479263, 0.9160079988143766, 0.903887727996592, 0.9011663035689388, 0.8367907573153219, 0.8260939809053769, 0.7683508266691262, 0.7234202492635545, 0.7121569782970198, 0.6213383920442218, 0.5786361839359868, 0.5380777310192311, 0.46138829067940923, 0.4441318595463302, 0.34964272800620694, 0.3233662082126278, 0.24534658923290942, 0.18524150173515894, 0.12375363227000283, 0.04747565849617937, -0.14270515739917755, -0.23368464410305023, -0.28937485814094543, -0.347047358751297, -0.40585362911224365, -0.4647759199142456, -0.5228486657142639, -0.5792010426521301, -0.6330925822257996, -0.6839351058006287, -0.731298565864563, -0.7749040126800537, -0.814604640007019, -0.850361704826355, -0.8822172284126282, -0.9102660417556763, -0.9346293210983276, -0.9554308652877808, -0.972777247428894, -0.9867396354675293, -0.9973416328430176, -1.0045515298843384, -1.0082783699035645, -1.0083777904510498, -1.0046641826629639, -0.9969332218170166, -0.9849926233291626, -0.9686970710754395, -0.9479800462722778, -0.9228765964508057, -0.8935279846191406, -0.8601699471473694, -0.8231033086776733, -0.7826565504074097, -0.7391493320465088, -0.6928628087043762, -0.6440213322639465, -0.5927913784980774, -0.5392893552780151, -0.483600914478302, -0.4258041977882385, -0.36599621176719666, -0.3043150305747986, -0.24095582962036133, -0.1761784553527832, -0.11030478775501251, -0.04370749741792679, 0.023207683116197586, 0.09002181887626648, 0.15632343292236328, 0.22172552347183228, 0.2858771085739136, 0.34850841760635376, 0.40935659408569336, 0.4682479202747345, 0.5250170230865479, 0.5795451998710632, 0.6317276954650879, 0.6814691424369812, 0.7286495566368103, 0.7731044292449951, 0.8146557807922363, 0.8530665636062622, 0.8880693316459656, 0.9193906784057617, 0.9467569589614868, 0.9699054956436157, 0.9886229038238525, 1.002753734588623, 1.0122066736221313, 1.0169519186019897, 1.017020344734192, 1.0124903917312622, 1.0034782886505127, 0.9901138544082642, 0.9725404977798462, 0.9508875012397766, 0.9252869486808777, 0.8958529829978943, 0.862694263458252, 0.825924277305603, 0.7856553196907043, 0.7420254349708557, 0.6952019929885864, 0.6453854441642761, 0.5927984118461609, 0.5377137064933777, 0.4804058074951172, 0.42116862535476685, 0.3602955937385559, 0.2980290949344635, 0.23461684584617615, 0.1702595204114914, 0.1051132082939148, 0.03934219479560852, -0.02694217674434185, -0.09356150776147842, -0.16033872961997986, -0.22700729966163635, -0.2932279109954834, -0.35858288407325745, -0.4226074516773224, -0.48473840951919556, -0.5444324612617493, -0.601193368434906, -0.6545946598052979, -0.7043044567108154, -0.7500960826873779, -0.7918457388877869, -0.8295215368270874, -0.8631640076637268, -0.8928650617599487, -0.9187436699867249, -0.9409255385398865, -0.9595215320587158, -0.9746127128601074, -0.9862350225448608, -0.9943720102310181, -0.9989491701126099, -0.9998384714126587, -0.996869683265686, -0.9898524284362793, -0.9786049723625183, -0.9629892110824585, -0.9429416060447693, -0.9184954166412354, -0.8897883892059326, -0.857049822807312, -0.8205747604370117, -0.780687689781189, -0.737706184387207, -0.6919118165969849, -0.6435324549674988, -0.5927385091781616, -0.5396512150764465, -0.48436063528060913, -0.4269481599330902, -0.3675117492675781, -0.3061887323856354, -0.2431715428829193, -0.17871515452861786, -0.1131359338760376, -0.04680001735687256, 0.01989240013062954, 0.08652772754430771, 0.15269841253757477, 0.21802030503749847, 0.28214573860168457, 0.3447739779949188, 0.4056546688079834, 0.4645880162715912, 0.5214183330535889, 0.5760230422019958, 0.6282978653907776, 0.6781388521194458, 0.7254251837730408, 0.7700062990188599, 0.8116924166679382, 0.8502544164657593, 0.8854308128356934, 0.9169420003890991, 0.9445096254348755, 0.9678766131401062, 0.9868267774581909, 1.0011996030807495, 1.0108973979949951, 1.0158885717391968, 1.0161999464035034, 1.011907935142517, 1.0031235218048096, 0.9899787306785583, 0.9726122617721558, 0.9511603116989136, 0.9257498979568481, 0.896498441696167, 0.8635154366493225, 0.8269096612930298, 0.7867992520332336, 0.7433199286460876, 0.6966357231140137, 0.6469429135322571, 0.5944730639457703, 0.5394879579544067, 0.4822695255279541, 0.4231087267398834, 0.36228930950164795, 0.3000754117965698, 0.2367023378610611, 0.1723698526620865, 0.10724639892578125, 0.04147717356681824, -0.024799777194857597, -0.09143102169036865, -0.15822188556194305, -0.2249140739440918, -0.29117000102996826, -0.3565692603588104, -0.42062294483184814, -0.4827996492385864, -0.542563796043396, -0.5994152426719666, -0.652923047542572, -0.7027510404586792, -0.74866783618927, -0.7905463576316833, -0.8283513784408569, -0.8621212244033813, -0.8919461965560913, -0.9179449677467346, -0.9402426481246948, -0.9589513540267944, -0.974152684211731, -0.9858847856521606, -0.9941326379776001, -0.9988231658935547, -0.9998304843902588, -0.9969851970672607, -0.9900968074798584, -0.9789837598800659, -0.9635053873062134, -0.9435955286026001, -0.9192847013473511, -0.8907070755958557, -0.858089804649353, -0.8217261433601379, -0.7819403409957886, -0.7390508651733398, -0.6933402419090271, -0.6450384855270386, -0.5943174362182617, -0.5413001179695129, -0.4860765337944031, -0.4287283718585968, -0.3693530559539795, -0.3080860674381256, -0.24511778354644775, -0.18070173263549805, -0.11515229940414429, -0.04883449524641037, 0.017852438613772392, 0.08449485152959824, 0.15068493783473969, 0.2160370945930481, 0.2802031636238098, 0.3428801894187927, 0.40381669998168945, 0.4628112316131592, 0.5197070240974426, 0.5743807554244995, 0.626727819442749, 0.6766442060470581, 0.7240104675292969, 0.7686765193939209, 0.8104543685913086, 0.8491154313087463, 0.8843994140625, 0.9160268306732178, 0.9437190294265747, 0.9672178626060486, 0.9863060712814331, 1.0008203983306885, 1.0106621980667114, 1.0157971382141113, 1.0162506103515625, 1.012097954750061, 1.0034493207931519, 0.9904356598854065, 0.9731963276863098, 0.9518671631813049, 0.9265761375427246, 0.8974401950836182, 0.8645694851875305, 0.8280726671218872, 0.7880674600601196, 0.7446886897087097, 0.6980994343757629, 0.6484952569007874, 0.5961064100265503, 0.5411936044692993, 0.484039306640625, 0.4249335527420044, 0.3641607165336609, 0.3019859194755554, 0.23864485323429108, 0.17433902621269226, 0.10923774540424347, 0.043486177921295166, -0.02277749590575695, -0.08940033614635468, -0.15618973970413208, -0.2228895127773285, -0.28916433453559875, -0.3545966148376465, -0.41869884729385376, -0.48094066977500916, -0.5407859086990356, -0.5977325439453125, -0.6513475775718689, -0.7012916207313538, -0.7473297119140625, -0.7893321514129639, -0.8272606134414673, -0.8611522912979126, -0.8910955190658569, -0.9172089695930481, -0.9396172761917114, -0.9584338665008545, -0.9737412333488464, -0.9855787754058838, -0.9939330816268921, -0.998733639717102, -0.9998552799224854, -0.9971297979354858, -0.9903675317764282, -0.9793850183486938, -0.9640409350395203, -0.9442659020423889, -0.9200875759124756, -0.891636848449707, -0.8591381311416626, -0.8228839039802551, -0.7831974625587463, -0.7403978109359741, -0.6947693824768066, -0.6465436220169067, -0.5958942174911499, -0.5429453253746033, -0.48778748512268066, -0.43050283193588257, -0.37118738889694214, -0.30997520685195923, -0.2470552623271942, -0.18267904222011566, -0.11715883016586304, -0.05085867643356323, 0.015823161229491234, 0.08247300982475281, 0.14868265390396118, 0.21406565606594086, 0.27827247977256775, 0.3409986197948456, 0.4019913077354431, 0.46104735136032104, 0.5180090665817261, 0.5727518796920776, 0.6251711249351501, 0.6751630902290344, 0.7226090431213379, 0.7673599720001221, 0.8092284798622131, 0.8479881882667542, 0.8833787441253662, 0.9151216149330139, 0.9429373741149902, 0.9665672779083252, 0.9857921600341797, 1.0004475116729736, 1.0104321241378784, 1.0157101154327393, 1.0163052082061768, 1.0122911930084229, 1.0037773847579956, 0.9908944368362427, 0.9737813472747803, 0.9525747299194336, 0.9274023175239563, 0.898381769657135, 0.8656230568885803, 0.8292349576950073, 0.7893343567848206, 0.746056079864502, 0.6995616555213928, 0.6500459909439087, 0.5977380871772766, 0.5428979992866516, 0.48580747842788696, 0.4267567992210388, 0.3660305142402649, 0.3038947582244873, 0.24058613181114197, 0.1763070523738861, 0.11122758686542511, 0.04549376666545868, -0.02075628750026226, -0.08737082034349442, -0.15415874123573303, -0.22086554765701294, -0.28715917468070984, -0.3526240587234497, -0.41677427291870117, -0.4790806174278259, -0.5390064716339111, -0.59604811668396, -0.6497699022293091, -0.6998293399810791, -0.7459887266159058, -0.7881148457527161, -0.826167106628418, -0.8601804971694946, -0.8902420997619629, -0.9164699912071228, -0.938989520072937, -0.9579138159751892, -0.9733270406723022, -0.9852699041366577, -0.993730902671814, -0.9986412525177002, -0.9998769760131836, -0.9972714185714722, -0.9906344413757324, -0.9797828197479248, -0.9645726680755615, -0.9449326992034912, -0.9208866357803345, -0.8925629258155823, -0.8601835370063782, -0.824038565158844, -0.7844516634941101, -0.7417423725128174, -0.6961963176727295, -0.648046612739563, -0.5974688529968262, -0.5445882678031921, -0.4894965887069702, -0.43227511644363403, -0.3730199337005615, -0.3118628263473511, -0.24899154901504517, -0.18465526401996613, -0.11916472017765045, -0.052882492542266846, 0.013793708756566048, 0.08045070618391037, 0.14667952060699463, 0.21209323406219482, 0.2763403654098511, 0.33911561965942383, 0.40016424655914307, 0.45928168296813965, 0.5163090229034424, 0.5711209774017334, 0.6236122846603394, 0.6736798286437988, 0.7212051153182983, 0.7660403251647949, 0.8079999685287476, 0.8468577861785889, 0.8823549747467041, 0.9142128229141235, 0.9421520829200745, 0.9659126996994019, 0.9852742552757263, 1.0000702142715454, 1.0101978778839111, 1.015618920326233, 1.0163555145263672, 1.0124801397323608, 1.0041011571884155, 0.9913492798805237, 0.9743627905845642, 0.953278660774231, 0.9282251596450806, 0.8993199467658997, 0.8666731119155884, 0.8303937911987305, 0.7905980944633484, 0.7474203109741211, 0.7010209560394287, 0.6515939235687256, 0.5993673205375671, 0.544600248336792, 0.4875738024711609, 0.42857837677001953, 0.36789917945861816, 0.305802583694458, 0.2425263375043869, 0.17827415466308594, 0.11321690678596497, 0.04750099778175354, -0.01873566024005413, -0.0853416696190834, -0.15212756395339966, -0.21884150803089142, -0.28515326976776123, -0.35065019130706787, -0.41484811902046204, -0.4772184193134308, -0.5372243523597717, -0.5943605303764343, -0.6481888294219971, -0.6983638405799866, -0.7446444034576416, -0.7868940234184265, -0.8250699639320374, -0.8592049479484558, -0.8893852233886719, -0.9157277941703796, -0.9383583068847656, -0.9573904275894165, -0.9729095101356506, -0.9849579334259033, -0.9935256242752075, -0.9985454082489014, -0.9998950958251953, -0.9974091053009033, -0.990897536277771, -0.9801764488220215, -0.9651004076004028, -0.9455952644348145, -0.921681821346283, -0.8934853076934814, -0.8612251281738281, -0.8251901268959045, -0.7857028245925903, -0.7430841326713562, -0.6976206302642822, -0.6495471000671387, -0.599041223526001, -0.5462291240692139, -0.4912036061286926, -0.4340457618236542, -0.3748502731323242, -0.313748836517334, -0.25092631578445435, -0.18663017451763153, -0.12116959691047668, -0.054905690252780914, 0.01176450215280056, 0.07842810451984406, 0.1446758508682251, 0.21011963486671448, 0.2744070589542389, 0.3372311294078827, 0.39833545684814453, 0.4575142562389374, 0.5146070122718811, 0.569487988948822, 0.6220515370368958, 0.672194242477417, 0.7197988033294678, 0.7647185921669006, 0.8067685961723328, 0.8457244038581848, 0.8813278079032898, 0.9133005738258362, 0.9413628578186035, 0.9652541279792786, 0.9847521781921387, 0.9996888637542725, 1.00995934009552, 1.0155234336853027, 1.016401767730713, 1.012665033340454, 1.0044211149215698, 0.9918000102043152, 0.9749403595924377, 0.9539788961410522, 0.9290441870689392, 0.900254487991333, 0.8677198886871338, 0.8315494060516357, 0.7918587923049927, 0.7487816214561462, 0.7024775743484497, 0.6531392335891724, 0.6009941101074219, 0.5463002324104309, 0.489338219165802, 0.43039846420288086, 0.369766503572464, 0.30770933628082275, 0.24446570873260498, 0.18024061620235443, 0.11520546674728394, 0.04950757324695587, -0.016715286299586296, -0.08331280946731567, -0.15009644627571106, -0.21681691706180573, -0.28314661979675293, -0.34867510199546814, -0.41292017698287964, -0.4753541350364685, -0.5354395508766174, -0.5926698446273804, -0.6466044783592224, -0.6968945860862732, -0.7432959675788879, -0.7856692671775818, -0.8239688873291016, -0.8582257628440857, -0.8885246515274048, -0.914982259273529, -0.9377236366271973, -0.9568638801574707, -0.9724888801574707, -0.9846426248550415, -0.9933168888092041, -0.9984461069107056, -0.9999096393585205, -0.9975428581237793, -0.9911566972732544, -0.9805660247802734, -0.9656239151954651, -0.9462535977363586, -0.9224730134010315, -0.894403874874115, -0.8622632026672363, -0.8263382911682129, -0.78695148229599, -0.7444233894348145, -0.6990423798561096, -0.6510456204414368, -0.6006115078926086, -0.5478682518005371, -0.4929085969924927, -0.43581438064575195, -0.3766792118549347, -0.31563329696655273, -0.2528597414493561, -0.18860413134098053, -0.12317383289337158, -0.05692870169878006, 0.00973520241677761, 0.07640516757965088, 0.14267148077487946, 0.20814508199691772, 0.27247247099876404, 0.3353450298309326, 0.3965049088001251, 0.45574483275413513, 0.5129030346870422, 0.5678529143333435, 0.6204881072044373, 0.6707062125205994, 0.7183900475502014, 0.7633939981460571, 0.805534303188324, 0.8445879220962524, 0.8802972435951233, 0.9123845100402832, 0.9405698180198669, 0.9645912051200867, 0.9842257499694824, 0.9993031024932861, 1.0097163915634155, 1.0154235363006592, 1.0164433717727661, 1.0128456354141235, 1.0047370195388794, 0.9922469854354858, 0.9755141139030457, 0.9546754360198975, 0.9298598170280457, 0.9011855125427246, 0.868763267993927, 0.8327017426490784, 0.7931162118911743, 0.7501398921012878, 0.7039313912391663, 0.6546821594238281, 0.6026186943054199, 0.547998309135437, 0.49110108613967896, 0.43221694231033325, 0.3716323971748352, 0.3096148371696472, 0.24640412628650665, 0.18220636248588562, 0.11719343066215515, 0.051513537764549255, -0.01469532959163189, -0.08128366619348526, -0.14806509017944336, -0.21479201316833496, -0.2811392545700073, -0.3466988503932953, -0.41099071502685547, -0.4734876751899719, -0.5336521863937378, -0.5909762978553772, -0.6450166702270508, -0.6954218149185181, -0.7419440746307373, -0.7844408750534058, -0.822864294052124, -0.857243001461029, -0.8876606822013855, -0.9142330288887024, -0.937085747718811, -0.9563339948654175, -0.9720650315284729, -0.9843242168426514, -0.9931049346923828, -0.9983434677124023, -0.9999208450317383, -0.9976731538772583, -0.9914119243621826, -0.9809516072273254, -0.9661434888839722, -0.9469079375267029, -0.9232602715492249, -0.8953188061714172, -0.8632979393005371, -0.8274834156036377, -0.788196861743927, -0.7457599639892578, -0.7004621028900146, -0.6525416374206543, -0.6021795868873596, -0.5495049953460693, -0.49461162090301514, -0.43758106231689453, -0.37850630283355713, -0.3175159990787506, -0.25479182600975037, -0.19057686626911163, -0.12517735362052917, -0.05895125865936279, 0.007706062868237495, 0.07438188791275024, 0.14066627621650696, 0.20616944134235382, 0.2705363929271698, 0.33345723152160645, 0.39467257261276245, 0.4539735019207001, 0.511197030544281, 0.5662155747413635, 0.6189228296279907, 0.6692160367965698, 0.7169787883758545, 0.7620666027069092, 0.8042972683906555, 0.843448281288147, 0.8792634606361389, 0.9114649891853333, 0.9397728443145752, 0.9639245271682739, 0.9836953282356262, 0.998913049697876, 1.0094690322875977, 1.0153193473815918, 1.0164809226989746, 1.0130221843719482, 1.0050487518310547, 0.9926900863647461, 0.9760841131210327, 0.9553683996200562, 0.930671751499176, 0.9021131992340088, 0.869803249835968, 0.8338509798049927, 0.7943707704544067, 0.7514953017234802, 0.7053822875022888, 0.6562223434448242, 0.604240894317627, 0.5496939420700073, 0.4928618371486664, 0.4340340793132782, 0.37349703907966614, 0.31151944398880005, 0.24834184348583221, 0.18417100608348846, 0.11918090283870697, 0.05351932346820831, -0.01267567090690136, -0.07925499975681305, -0.14603394269943237, -0.2127668410539627, -0.27913111448287964, -0.3447214365005493, -0.4090595245361328, -0.47161900997161865, -0.5318621397018433, -0.5892795324325562, -0.6434256434440613, -0.6939454078674316, -0.7405882477760315, -0.7832086086273193, -0.8217560052871704, -0.8562566041946411, -0.8867930173873901, -0.9134805202484131, -0.9364446401596069, -0.9558008909225464, -0.9716379046440125, -0.9840025901794434, -0.9928897619247437, -0.9982373714447021, -0.99992835521698, -0.9977996349334717, -0.9916634559631348, -0.9813330769538879, -0.9666587710380554, -0.9475582838058472, -0.924043595790863, -0.8962298631668091, -0.8643291592597961, -0.8286252021789551, -0.7894396781921387, -0.747093915939331, -0.7018791437149048, -0.654035747051239, -0.603745698928833, -0.5511399507522583, -0.49631279706954956, -0.4393458068370819, -0.3803315758705139, -0.31939730048179626, -0.25672227144241333, -0.19254878163337708, -0.1271800696849823, -0.06097356975078583, 0.005676692351698875, 0.07235803455114365, 0.1386602520942688, 0.20419254899024963, 0.2685990631580353, 0.3315681219100952, 0.3928385376930237, 0.45220014452934265, 0.5094889402389526, 0.5645762085914612, 0.617355227470398, 0.6677234172821045, 0.7155650854110718, 0.7607367038726807, 0.8030572533607483, 0.8423057794570923, 0.8782262206077576, 0.9105418920516968, 0.9389720559120178, 0.9632537961006165, 0.9831604957580566, 0.9985186457633972, 1.009217381477356, 1.0152108669281006, 1.0165141820907593, 1.0131945610046387, 1.0053566694259644, 0.9931290745735168, 0.9766503572463989, 0.9560577273368835, 0.9314804673194885, 0.9030376076698303, 0.8708402514457703, 0.8349968194961548, 0.7956221103668213, 0.7528476715087891, 0.7068305611610413, 0.6577602028846741, 0.6058605909347534, 0.5513879656791687, 0.49462080001831055, 0.435849666595459, 0.37536048889160156, 0.3134228587150574, 0.2502785623073578, 0.18613535165786743, 0.12116782367229462, 0.055524617433547974, -0.010656280443072319, -0.07722651213407516, -0.1440024971961975, -0.21074116230010986, -0.27712225914001465, -0.3427428603172302, -0.40712642669677734, -0.46974804997444153, -0.5300695300102234, -0.5875797867774963, -0.6418310403823853, -0.6924652457237244, -0.7392287254333496, -0.7819726467132568, -0.8206436038017273, -0.8552663326263428, -0.8859219551086426, -0.912724494934082, -0.9357998967170715, -0.9552644491195679, -0.9712077379226685, -0.9836776256561279, -0.9926711320877075, -0.9981279373168945, -0.9999322891235352, -0.9979225397109985, -0.9919109344482422, -0.98171067237854, -0.967170000076294, -0.948204517364502, -0.9248227477073669, -0.8971371650695801, -0.8653568625450134, -0.8297639489173889, -0.7906792759895325, -0.7484251856803894, -0.7032939195632935, -0.6555273532867432, -0.6053096652030945, -0.5527726411819458, -0.49801206588745117, -0.44110891222953796, -0.3821551203727722, -0.3212769031524658, -0.2586517035961151, -0.194519504904747, -0.12918223440647125, -0.06299541145563126, 0.0036474037915468216, 0.07033399492502213, 0.1366536021232605, 0.20221483707427979, 0.26666024327278137, 0.3296770453453064, 0.3910025954246521, 0.4504249691963196, 0.5077787041664124, 0.5629345774650574, 0.6157853007316589, 0.6662284135818481, 0.7141488790512085, 0.7594040632247925, 0.8018144965171814, 0.8411598801612854, 0.877185583114624, 0.9096149802207947, 0.9381676316261292, 0.9625787138938904, 0.982621431350708, 0.9981199502944946, 1.0089614391326904, 1.0150978565216064, 1.0165431499481201, 1.0133627653121948, 1.0056604146957397, 0.9935644865036011, 0.9772127866744995, 0.9567432403564453, 0.9322852492332458, 0.9039584398269653, 0.8718734979629517, 0.8361392617225647, 0.796870231628418, 0.7541971206665039, 0.7082757949829102, 0.6592952013015747, 0.6074782609939575], "name": "predicted"}, {"type": "scatter", "y": [-0.009999358952767035, 0.0636596725936513, 0.09396539891340987, 0.18736083188739677, 0.24554522107360244, 0.30474662791998464, 0.3540644715650535, 0.427310695217905, 0.5082610045992348, 0.528743319714693, 0.610873715328187, 0.6595808302414805, 0.6714801770744819, 0.7161724630504367, 0.8017361218478947, 0.8227584059757931, 0.8339431865355841, 0.8589156197859245, 0.9032790012741199, 0.9277440963860971, 0.944348827684898, 0.9550259159741353, 0.9939331935171848, 0.9953889438631083, 1.031895777398816, 0.991926769744457, 1.008018984611331, 0.9898874568317324, 0.9660036288267146, 0.9778216806047674, 0.9427574719479263, 0.9160079988143766, 0.903887727996592, 0.9011663035689388, 0.8367907573153219, 0.8260939809053769, 0.7683508266691262, 0.7234202492635545, 0.7121569782970198, 0.6213383920442218, 0.5786361839359868, 0.5380777310192311, 0.46138829067940923, 0.4441318595463302, 0.34964272800620694, 0.3233662082126278, 0.24534658923290942, 0.18524150173515894, 0.12375363227000283, 0.04747565849617937, -0.0037387080934477928, -0.051743377712968094, -0.15214920425224088, -0.19449442529116476, -0.26660097990763254, -0.32123644885610925, -0.38842565077399277, -0.441144767589916, -0.48607544550013165, -0.524011507610602, -0.5891608717435157, -0.6453265897593556, -0.6902171009691433, -0.7271350896313418, -0.7695574187711549, -0.8019483627796674, -0.8705328832225805, -0.8882826334487386, -0.941180390156566, -0.9078491448280709, -0.9832570314642423, -0.942594348092753, -0.9894904989827801, -1.033150433359927, -0.9886850624679566, -1.0280845624475607, -1.0089557387836479, -0.9901244244917171, -0.9947835829309849, -0.9469085583633676, -0.928849321496094, -0.9595811107489216, -0.899135580368624, -0.904911369504552, -0.8489143109698182, -0.7904224335162588, -0.7793467872833741, -0.7288845420182568, -0.6813326718442346, -0.6342428891149459, -0.5838042233620713, -0.5394518302446045, -0.49395160308410146, -0.43786637091879443, -0.3736342591485493, -0.3050754102189696, -0.23006119896148175, -0.15796119062894998, -0.13899400784200322, -0.07349763188343796, -0.022813306341768008, 0.05154018987183014, 0.15715760494770037, 0.20520889719981203, 0.22701288049240798, 0.34376915047710155, 0.39380520967089705, 0.42170607945255223, 0.5051473215112843, 0.517959834594867, 0.5842618115193163, 0.639205485969443, 0.6517609770466205, 0.7524165476525965, 0.7733899011038774, 0.7671879127780509, 0.8378791949103853, 0.8869084817924341, 0.9253955427829345, 0.9474620605814121, 0.9492888026500431, 0.9409248393793384, 0.9925682334015613, 1.0212177683122823, 0.988258219789467, 0.9974993657507019, 0.985505248508194, 0.9691975335965581, 0.9816182076967912, 1.0069189782770906, 0.9517295755478234, 0.9151599032622754, 0.9230691448701079, 0.8647948616525551, 0.8391556216439793, 0.7743724386112338, 0.7572152028785227, 0.7235964806336481, 0.6679369953520177, 0.6561309728447834, 0.5698838129697144, 0.535494580645897, 0.47822109618725667, 0.43056754840990097, 0.3796522505801375, 0.30640282243540146, 0.24888140240620638, 0.16101972528613337, 0.11274049727664075, 0.05557651776347804, 0.007767086457276048, -0.07755460024331498, -0.12614497129964494, -0.19339795292170062, -0.2711600718126285, -0.2776459941637687, -0.3736172256217579, -0.43593804695342714, -0.4830804859023277, -0.5178520557861744, -0.6103658903884167, -0.6575171641143672, -0.7155881313104441, -0.7393348420107445, -0.799837168515808, -0.8146339753743045, -0.8413778152003573, -0.8677364988263171, -0.9256726232512349, -0.9606969095668922, -0.960883549581452, -0.9695173165732712, -0.9964459659204626, -1.0068786370846308, -1.027668291543145, -0.9971305351809371, -1.0037618140427316, -0.9890243909537776, -0.9804558226660108, -0.9673632031655514, -0.9379023272572421, -0.934088180148397, -0.9166649874015851, -0.9189964142899317, -0.8429842068469926, -0.7965800116683697, -0.768901463615821, -0.7248123293996247, -0.7065009887084645, -0.6627206902044985, -0.5784566232989523, -0.5478967746908785, -0.4615929887606986, -0.44421982569590407, -0.37499013908010215, -0.3251221604381255, -0.2665142392093253, -0.20527701245193583, -0.10344417870438943, -0.04104891977859873, -0.014295787230804618, 0.07877813404198541, 0.12008119145186724, 0.20195151310001322, 0.19943805575744072, 0.31579098044307435, 0.3389383558319193, 0.44483148949855866, 0.46094071467345643, 0.5461219070449542, 0.5583702565689818, 0.6517574020294392, 0.6835725761606786, 0.7033919641357133, 0.7616116033850876, 0.793269209820952, 0.850526377683836, 0.8702191216418065, 0.8963142665036119, 0.9480087183757869, 0.9658322242311266, 0.965728855484959, 0.9552886420582565, 1.009911048390976, 0.9599555612070212, 0.9384181853734762, 0.9620204370552552, 0.9762121807341281, 0.9674990184490031, 0.9797922292045916, 0.9583407670017142, 0.9177376412944372, 0.884204502152081, 0.8953922997454626, 0.8250341349854714, 0.7873391639955621, 0.7723361615948774, 0.753941461053737, 0.6490043815478378, 0.6222555270017242, 0.5691437909799054, 0.527293267766338, 0.5061132107407212, 0.43249230520228266, 0.36843862143995454, 0.30074457642376334, 0.2623233229560387, 0.1735769588094051, 0.16794388802654395, 0.06136239114921771, 0.011243251807838145, -0.08687318312280887, -0.12425551724082626, -0.18359764845740184, -0.286965740898845, -0.2839093680741585, -0.3974235159102908, -0.45313656983755385, -0.44221550263184733, -0.5483555614175254, -0.6042364962169491, -0.6537402312365962, -0.6948145963665731, -0.73814867706013, -0.7554088180907429, -0.821513440217209, -0.8453331802872212, -0.8750222628831029, -0.9193616234472021, -0.9445253607359784, -0.9319109432950128, -0.9576428186600859, -0.9816592341265201, -1.0057569781449658, -1.0421661677066543, -1.0068744019415232, -1.013827296186875, -0.9904197297401905, -1.0046795052178161, -0.9849450270816512, -0.9134858184428556, -0.9336092162122831, -0.8929240555635648, -0.8557762829118988, -0.8531160327787302, -0.8107033361941218, -0.7765981449725297, -0.731827648930893, -0.6878313605574721, -0.6344444301385131, -0.6001364910249991, -0.5472556903574349, -0.46918050490022734, -0.4179067586838576, -0.3987534794523012, -0.31857854612745895, -0.24569119381989607, -0.2376462115584244, -0.13750124990389284, -0.052369024904391576, -0.005525716108625668, 0.06330380293596981, 0.11974063095600848, 0.18396885179840944, 0.2634552114273171, 0.31032822320266307, 0.3775383363722705, 0.4042288631122052, 0.4722947309396425, 0.5326339834107028, 0.5835908353480422, 0.6317673447953871, 0.6644018971815173, 0.6961837760559256, 0.7671359759397369, 0.807406074502865, 0.8236896085778004, 0.8654400769186593, 0.889763358681592, 0.9513633302821403, 0.9850265171554226, 0.9902874016775833, 1.0378581198218206, 0.9692268992670788, 0.9647883388725478, 0.999067990719999, 0.9800729365659656, 1.0215353107967833, 0.9515970688568111, 0.975639874041288, 0.916518665881306, 0.9334271899017014, 0.9171435827914521, 0.8923946133610402, 0.8590150263287917, 0.8015012721935336, 0.757232433056858, 0.7398423535345267, 0.6814521707770927, 0.6686452847194243, 0.5708947042150191, 0.5242191358267104, 0.48012452306329334, 0.44331485192199505, 0.3776870875161292, 0.2942556857219252, 0.2548129475261059, 0.19203588185896936, 0.1197027359930042, 0.04073018644379744, 0.00325021821709221, -0.098058236879079, -0.11183060581106014, -0.21499956756195407, -0.29384652642301007, -0.3020414250773188, -0.3429511588246692, -0.43911359211608947, -0.5077273869983197, -0.5497348670961157, -0.6109880263696533, -0.6315490386211278, -0.6877881709370871, -0.7920389936203348, -0.7490659733218974, -0.8095407534838209, -0.8572087697562507, -0.9025681042991982, -0.9104167394714002, -0.9365170789449601, -0.9865964121571721, -0.9172802389060665, -0.9874689153956787, -1.0270464617938093, -1.010425846728927, -1.0025382418101674, -1.0061801180156158, -0.9866730854180761, -0.9667298990268961, -0.959228051824227, -0.9205680927440738, -0.9024026864162575, -0.9092124126949721, -0.8914674037968324, -0.8217552168004579, -0.8147859464654839, -0.7631129122032865, -0.716005280629734, -0.6766147502298929, -0.6622042252786768, -0.59416678868582, -0.49541517954658637, -0.499022505107533, -0.4038537899888186, -0.3835040860659026, -0.30430694850519513, -0.2752508172661917, -0.19012775569186252, -0.14777502883590604, -0.046693548323724625, 0.006834141101711506, 0.07535538805377073, 0.11982125394735588, 0.22148862547467593, 0.24296049344557094, 0.28159070125695546, 0.38512198095151284, 0.4193915909047361, 0.47182349885902775, 0.5532183537926714, 0.5815745996682162, 0.6178132523805759, 0.6809586102443982, 0.7248426151244712, 0.7503434673720812, 0.7906032499182177, 0.7923897557043593, 0.8701311730227432, 0.9028115726099403, 0.9560870773013926, 0.9395108152053077, 0.9723531347731215, 0.9625802633850115, 0.994497953216637, 1.0066056750637637, 0.9886029325640016, 1.0153535175235424, 0.976764480262158, 0.9727332671157737, 0.9849133686341576, 0.9579802653001507, 0.9333183643641018, 0.8819520206234546, 0.892825973299433, 0.8167209185435051, 0.7928508788718144, 0.7890923732759523, 0.7194942472075255, 0.7080437935877234, 0.6619190409927057, 0.6147084411932086, 0.5372897744493671, 0.45583020885949926, 0.45029517481211223, 0.3694576835240727, 0.29313664344126056, 0.22496272337952203, 0.19149106352206322, 0.1310856808525609, 0.08643336693007223, 0.024729948137679317, -0.09078056840089134, -0.1180799233347238, -0.1908619163687677, -0.26327659562868533, -0.33091341938468516, -0.3799712866641005, -0.4299277694311706, -0.47217891864456457, -0.5477058856410649, -0.6070946387908837, -0.6384471191358374, -0.6697151624821788, -0.7326587124761927, -0.780876408165527, -0.7948999650985803, -0.8673078141359395, -0.8763932403511998, -0.9610747486561285, -0.8903644635014971, -0.98312419232589, -0.9578976450987237, -0.981717024302326, -0.9672197872824188, -1.007221389312445, -0.9868139214743681, -0.9858072649244711, -0.9989724235356287, -1.0190298289726751, -0.969367713963924, -0.9409093069758682, -0.9265070476824591, -0.8869904294496557, -0.8855360053495561, -0.8519348810889587, -0.8160893565214707, -0.7605920932315919, -0.7549311252485174, -0.6728749752233568, -0.6276845533639275, -0.5791069329022396, -0.5455958910291019, -0.48052221090429614, -0.41481916319376055, -0.3648337956656226, -0.30911142065256825, -0.21278909703481982, -0.1961932689437774, -0.14401100032994224, -0.054114760523670494, 0.007498893910480035, 0.031131399309096933, 0.14058380890019204, 0.20222903763928723, 0.26217729823523267, 0.3455160305470806, 0.3721054502317444, 0.4521937173179805, 0.4838253248582296, 0.5408361182657758, 0.5981361602986408, 0.6250080365178263, 0.6590953244289783, 0.7258507772734651, 0.8110594660344395, 0.7914789784578066, 0.8053112346888595, 0.8957296956485096, 0.9054756545147988, 0.9274733138263411, 0.9463655610323978, 0.9678799230976853, 0.9897513312542021, 0.9843798802636148, 0.9796699157235454, 0.9782437128755087, 1.0049768586559904, 1.025621051329909, 0.974662514513343, 0.9393278983643367, 0.9679148266325017, 0.9221639754574951, 0.9080251344921789, 0.8400469076466311, 0.8653369273348335, 0.8213599205980713, 0.7553581980170392, 0.6963001707421883, 0.6779362533675288, 0.6388305939666635, 0.5866515402513922, 0.5355627384742497, 0.4830539137258818, 0.4439745513774055, 0.3837167654286333, 0.27374502665863254, 0.22375911172753324, 0.17713612594245712, 0.13560559044568654, 0.055897563611364845, -0.025039566307157732, -0.05287284885821174, -0.08530780205858286, -0.2039174493599344, -0.22705773864761114, -0.34820810390322837, -0.3846387315503561, -0.4533976366596316, -0.48684770457874355, -0.5565000638313461, -0.6020829715604039, -0.6278586455922663, -0.6933436589115893, -0.7400331654105672, -0.7288004992554871, -0.8136355618422089, -0.8237754598515847, -0.900849118778551, -0.9050728941810126, -0.91542134014629, -0.9609535015809532, -0.9789757277089052, -0.9950733479850521, -0.9608239403825576, -1.0018954205258015, -0.9978176639843784, -0.9905764796994785, -1.013365846393599, -0.990538235059092, -0.9655207828027641, -0.9467451509538439, -0.88808542729832, -0.8618325904235582, -0.875893192814291, -0.8170282589814193, -0.8443694588101366, -0.7717785540274928, -0.6986754651153696, -0.7088530147710765, -0.6627067191874392, -0.5741450029230915, -0.5210915239540634, -0.4821098177446098, -0.41181536085470977, -0.3644590206667578, -0.2975746465958, -0.25488950964150936, -0.1759242460353199, -0.15537699732792526, -0.07311295414779961, 0.010300749820318948, 0.07331941024313679, 0.13700397843315465, 0.20627493440425376, 0.20736220599682373, 0.3105888139052605, 0.38250727349148705, 0.41223643747115696, 0.5091238137554251, 0.5425408532482557, 0.6189408060583667, 0.6505101292526647, 0.6807921220069558, 0.7453835007326365, 0.7729695302792963, 0.7861254808808821, 0.8520643972808829, 0.8942028051127654, 0.9188400233090682, 0.9277215346880768, 0.9634145390749397, 0.9805792398658955, 0.9694064631999972, 0.9712566259295984, 1.0234368536750982, 0.9958299980871314, 0.9978910621585924, 0.9736662529493643, 1.0009746460363191, 0.9707858841433672, 0.965336597612631, 0.8779477299720793, 0.9098082932611138, 0.8743548456436759, 0.8208019901248673, 0.8089084076451738, 0.783504206621479, 0.7082801803365147, 0.6820167327780572, 0.6434828962376223, 0.5991426175802962, 0.5736778715146434, 0.4969496677497485, 0.42896592842424924, 0.39684557806107984, 0.33064071587834726, 0.2425829233886185, 0.1720667288134628, 0.10630759832763279, 0.09559744076800568, 0.001411615080550252, -0.11215658787396954, -0.17449220468833698, -0.21431950953028636, -0.22194860643223213, -0.32007586565531326, -0.4133809302381406, -0.42411664054600257, -0.4684091937827552, -0.5414545856051733, -0.6239156130251304, -0.6417115677356892, -0.6924821896875668, -0.7421389462440876, -0.7975006575955248, -0.8262212280612641, -0.8247382442081787, -0.8889962847022227, -0.8949948753877144, -0.9082583955272568, -0.9285303722602126, -0.9364673112717812, -0.9948122114998945, -1.0021917210548514, -0.9833730255105879, -1.0101535733562355, -0.9889184811765052, -0.981529068340277, -0.9802393011108819, -0.9669115977238153, -0.9680026754550288, -0.9452842855975844, -0.9103998763145765, -0.8663390021634219, -0.8409490627209675, -0.8002790068177634, -0.8066519089403844, -0.7237223672251031, -0.6840448020268344, -0.6324887621337407, -0.595923339322427, -0.5235092656562993, -0.4968259901472895, -0.4329193112954973, -0.3642436462972879, -0.3051335160389075, -0.23928241284446972, -0.16535419018769593, -0.1089563535989511, -0.053360823623563425, 0.018213941366724398, 0.10533888313303211, 0.09687658600528484, 0.17164850524127195, 0.22074392706563925, 0.3270693067309027, 0.37929449311740904, 0.46730723937480156, 0.45987023438052893, 0.5315769813086229, 0.5893268810287627, 0.6321511159959233, 0.697774734375711, 0.7121682087687913, 0.7857616024164175, 0.7937304413764017, 0.8721829211736689, 0.8912175049708719, 0.9041578127352193, 0.9644716150722575, 0.9616201635100835, 0.9663235845038947, 0.990001455602749, 1.004464320534742, 0.9839161449248397, 1.0188898169379705, 1.029098057809125, 0.9731044430124492, 1.000021429902005, 0.966682618152726, 0.9361215757504099, 0.9242043173432136, 0.8909917120992444, 0.8599171067947626, 0.8883148510037145, 0.8145216786284908, 0.7627436681080456, 0.7228564347021664, 0.6829336153822555, 0.6374773823304233, 0.5818429748131887, 0.5280184093636692, 0.47280684862476496, 0.43011754499973387, 0.3691591501718484, 0.2876229269618483, 0.23850858824424448, 0.17998992148517606, 0.12022687882614858, 0.07740643941921226, -0.02304668862720141, -0.07267074123453449, -0.1357871446940126, -0.18658091450614817, -0.2529380731796695, -0.33311502051771014, -0.3496361654920795, -0.448543679490954, -0.46037397198092794, -0.5504386114453172, -0.5727423184893257, -0.6339376992364432, -0.7124221623402254, -0.7230490779313611, -0.7965783363358825, -0.8336373192622851, -0.8833702121686393, -0.8714637144087038, -0.9389056830166841, -0.9398947306614576, -0.9479251543477358, -1.0002417007168813, -0.9247468653340163, -0.9869799479172269, -0.9950546932331401, -0.9798193839208197, -0.9881696858255663, -0.9745514347102743, -0.9754441926366718, -0.9893145578190212, -0.9639254870899846, -0.9513056902969883, -0.9413271318282612, -0.8521033581532144, -0.8556233731431813, -0.7875031973765985, -0.7877951009998359, -0.7099569536372239, -0.6511550813494216, -0.6636892174198264, -0.5873962124051676, -0.5414160289405718, -0.47433287537735064, -0.445738371238944, -0.3528634098341932, -0.2992402424190568, -0.21599976354989553, -0.19031753928557107, -0.1539050346919415, -0.09378422669678968, -0.011662813613119879, 0.08389753920928215, 0.11738294181425585, 0.15826842792937879, 0.2219137162101131, 0.31313757029341627, 0.3999402865915137, 0.41412764396658047, 0.4844610518714936, 0.536778992233629, 0.6019035478007638, 0.6351872661033521, 0.667399911503969, 0.7809084871980175, 0.7722416655579626, 0.8182998721471769, 0.8336554049150394, 0.8897452878522185, 0.908785464724211, 0.9128155601715818, 0.949090623283675, 0.9562192664804702, 0.9914157958012333, 1.0112116371967843, 0.9935123610769732, 0.9929045614140145, 1.038867354310762, 0.9954828313599787, 0.9679509032630352, 0.9845153353409729, 0.923263968282899, 0.9551141018041001, 0.9666793685893023, 0.8635875235494844, 0.8504295390915665, 0.7558158671370429, 0.7951465602544171, 0.7133621322455096, 0.6659744394433895, 0.5934337764683928, 0.5752665387102879, 0.5109653564164036, 0.49421886712684804, 0.4339203946551435, 0.3741394052983156, 0.28011513288089374, 0.23814213563315578, 0.15904947578741407, 0.11369607879148133, 0.04827414918545453, 0.013239543237273962, -0.03689777488503653, -0.12392649573572183, -0.18293093413094516, -0.24892972040478584, -0.3023112321488935, -0.40519875310856807, -0.4562058742822817, -0.4678656989759555, -0.5586099290494094, -0.5763338791982973, -0.6351200114068335, -0.6821480499343263, -0.6948065653685401, -0.7903737651203333, -0.8130985699106767, -0.817659625867472, -0.8523996638821593, -0.8939073034481548, -0.9232671160355393, -0.954190582456538, -0.9510953802740941, -1.0135444435783867, -0.975985930278572, -1.0378784887414805, -0.9914435588081003, -0.9825889504941969, -1.002766924401087, -0.9973043451719161, -0.9528916551500519, -0.9216724517921702, -0.9171639652071998, -0.8831139425905358, -0.9066205097805673, -0.8516601570825475, -0.8168726587024154, -0.7868253499777452, -0.6900943152877789, -0.6846209884382639, -0.6243797786013198, -0.6177964564982266, -0.5093952271320391, -0.4648227749984756, -0.41795070175519594, -0.38427659617965887, -0.3065450849023503, -0.27867054410634856, -0.19677204729979236, -0.15062772385436363, -0.05856755280833635, 0.014552774791359364, 0.06923972427802011, 0.11905257701380974, 0.21476977539817543, 0.23365673284608687, 0.30089313799436396, 0.37509822922798847, 0.407433840921814, 0.49229696644513926, 0.5473659709719215, 0.5827829350515666, 0.6195335476202688, 0.6831062241690943, 0.7342289360366866, 0.755105394619009, 0.8117086197717525, 0.8404723098261578, 0.8765951700748704, 0.9054696446615053, 0.9170490401023947, 0.9569427557155721, 0.96452743866303, 0.9905931479484404, 1.0035288394031092, 1.0109085701495821, 0.9742105071640592, 1.0101723206314295, 1.0333987925359858, 0.9909304335245791, 1.0074449511940526, 0.9457615085061316, 0.9445562113000437, 0.9168628851179021, 0.8827629490123261, 0.8259176845524461, 0.789155144825064, 0.7752474520652558, 0.7365949102001058, 0.7017970017605182, 0.6365845252928035, 0.6163869681026471, 0.559128288289626, 0.47045833909574614, 0.42582372035748844, 0.3714659382343797, 0.31879483765396455, 0.23238091191116722, 0.1888095881079829, 0.08949397122341124, 0.10845438345222447, -0.029453605549609855, -0.04091961037964169, -0.14012825021790146, -0.2156974551622148, -0.2619382764339229, -0.32064926730966464, -0.3723518856276549, -0.44335507052521755, -0.4841421033290865, -0.49953965645573173, -0.5718750054449947, -0.637526851796195, -0.656985893188981, -0.747432397595722, -0.7504646746358287, -0.8189634486847895, -0.8506603053313627, -0.879978436642826, -0.8746053338153057, -0.9274057581227241, -0.9351219704311968, -0.9389625787844237, -0.9940045200281284, -0.9862695472859095, -1.0201060895035645, -0.9992596239423911, -0.9898291342936199, -1.0095470030889173, -1.0134226439396095, -0.9560671286768571, -0.9355104202124493, -0.9231279909810497, -0.9246488981846931, -0.8581357861506494, -0.8271943542848372, -0.7996100931151767, -0.7781257281662797, -0.707604008904239, -0.6542503347848228, -0.6059767677046944, -0.5869141638178202, -0.5108480058795409, -0.4626809492263522, -0.4142364056057339, -0.35996602761879704, -0.34534131809469476, -0.2706436425641511, -0.1790558404511132, -0.14998124355721829, -0.05343827186497813], "name": "original"}], {"title": ""}, {"showLink": true, "linkText": "Export to plot.ly"})});</script>
<div id="cd2f3e78-2bb6-44a4-8ec1-afdf27d7a15c" style="height: 525px; width: 100%;" class="plotly-graph-div"></div><script data-my-script="" type="text/javascript">require(["plotly"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL="https://plot.ly";Plotly.newPlot("cd2f3e78-2bb6-44a4-8ec1-afdf27d7a15c", [{"type": "scatter", "y": [0.4200988198237621, 0.16368044356354444, 0.009697234577631123, 0.0013517268351158666, 0.0005475582548653147, 0.0004705996531143977, 0.0004486709888885767, 0.00043707164066344545, 0.00043170396977004305, 0.00042987580305907055], "name": "loss train"}, {"type": "scatter", "y": [0.4071849303489721, 0.15843713807968904, 0.009523627191546064, 0.0013381472399292352, 0.0005408353421895701, 0.0004650330176028762, 0.00044428758037234846, 0.00043366068227697986, 0.00042851950653343096, 0.00042790668489328784], "name": "loss dev"}], {"title": ""}, {"showLink": true, "linkText": "Export to plot.ly"})});</script>
<h2 id="conclusion-next-steps"><a href="#conclusion-next-steps" aria-hidden="true" class="anchor"><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Conclusion, next steps</h2>
<p>When playing around with the parameters I found out that often the network performed better on the dev set than the train set! Clearly overlapping dev and train sets are nonsensical. Also the network seems to optimize on predicting the amplitude but not frequency. Probably the frequency can be better predicted by training on more then only one value (last_output).</p>
<p>This example gave me a good overview of some TensorFlow features. More generally there are so many hyper parameters to choose when building a network architecture:</p>
<ul>
<li>basic parameters: network size, learning rate, drop-out, optimization method</li>
<li>how to choose initial state</li>
<li>predict one sample, or multiple samples</li>
<li>loss function</li>
</ul>
<p>It would be interesting to automatically tune the hyper-parameters as well. Maybe using genetic networks?</p>
<p>I am planning to use the approach in this article to process sampled sound waves. Things that cross my mind:</p>
<ul>
<li>
<p>Apply on raw audio</p>
<ul>
<li>Sample microphone via WebAudo, send the samples to the notebook via WebSocket, analyze and feed the result back</li>
</ul>
</li>
<li>Implement a phase vocodor, instead of raw audio, input the frequency features</li>
<li>Achieve something like <a href="https://deepmind.com/blog/wavenet-generative-model-raw-audio/">this</a></li>
<li>Process a MIDI file</li>
<li>Generate text</li>
<li>Train on multi-feature sequence (eg. audio and corresponding text)</li>
</ul>
<p>Stay tuned....</p></div></section><div class="post-meta" data-reactid="53"><div class="post-tag-container" data-reactid="54"><a style="text-decoration:none;" href="/tags/lstm" data-reactid="55"><button type="button" class="md-chip post-preview-tags" data-reactid="56"><span class="md-chip-text" data-reactid="57">LSTM</span></button></a><a style="text-decoration:none;" href="/tags/artificial-intelligence" data-reactid="58"><button type="button" class="md-chip post-preview-tags" data-reactid="59"><span class="md-chip-text" data-reactid="60">Artificial Intelligence</span></button></a><a style="text-decoration:none;" href="/tags/jupyter" data-reactid="61"><button type="button" class="md-chip post-preview-tags" data-reactid="62"><span class="md-chip-text" data-reactid="63">Jupyter</span></button></a><a style="text-decoration:none;" href="/tags/tensorflow" data-reactid="64"><button type="button" class="md-chip post-preview-tags" data-reactid="65"><span class="md-chip-text" data-reactid="66">Tensorflow</span></button></a></div><div class="social-links" data-reactid="67"><div role="button" tabindex="0" class="SocialMediaShareButton SocialMediaShareButton--reddit" data-reactid="68"><div style="width:36px;height:36px;" data-reactid="69"><svg viewBox="0 0 64 64" fill="white" width="36" height="36" class="social-icon social-icon--reddit " data-reactid="70"><g data-reactid="71"><circle cx="32" cy="32" r="31" fill="#5f99cf" data-reactid="72"></circle></g><g data-reactid="73"><path d="m 52.8165,31.942362 c 0,-2.4803 -2.0264,-4.4965 -4.5169,-4.4965 -1.2155,0 -2.3171,0.4862 -3.128,1.2682 -3.077,-2.0247 -7.2403,-3.3133 -11.8507,-3.4782 l 2.5211,-7.9373 6.8272,1.5997 -0.0102,0.0986 c 0,2.0281 1.6575,3.6771 3.6958,3.6771 2.0366,0 3.6924,-1.649 3.6924,-3.6771 0,-2.0281 -1.6575,-3.6788 -3.6924,-3.6788 -1.564,0 -2.8968,0.9758 -3.4357,2.3443 l -7.3593,-1.7255 c -0.3213,-0.0782 -0.6477,0.1071 -0.748,0.4233 L 32,25.212062 c -4.8246,0.0578 -9.1953,1.3566 -12.41,3.4425 -0.8058,-0.7446 -1.8751,-1.2104 -3.0583,-1.2104 -2.4905,0 -4.5152,2.0179 -4.5152,4.4982 0,1.649 0.9061,3.0787 2.2389,3.8607 -0.0884,0.4794 -0.1462,0.9639 -0.1462,1.4569 0,6.6487 8.1736,12.0581 18.2223,12.0581 10.0487,0 18.224,-5.4094 18.224,-12.0581 0,-0.4658 -0.0493,-0.9248 -0.1275,-1.377 1.4144,-0.7599 2.3885,-2.2304 2.3885,-3.9406 z m -29.2808,3.0872 c 0,-1.4756 1.207,-2.6775 2.6894,-2.6775 1.4824,0 2.6877,1.2019 2.6877,2.6775 0,1.4756 -1.2053,2.6758 -2.6877,2.6758 -1.4824,0 -2.6894,-1.2002 -2.6894,-2.6758 z m 15.4037,7.9373 c -1.3549,1.3481 -3.4816,2.0043 -6.5008,2.0043 l -0.0221,-0.0051 -0.0221,0.0051 c -3.0209,0 -5.1476,-0.6562 -6.5008,-2.0043 -0.2465,-0.2448 -0.2465,-0.6443 0,-0.8891 0.2465,-0.2465 0.6477,-0.2465 0.8942,0 1.105,1.0999 2.9393,1.6337 5.6066,1.6337 l 0.0221,0.0051 0.0221,-0.0051 c 2.6673,0 4.5016,-0.5355 5.6066,-1.6354 0.2465,-0.2465 0.6477,-0.2448 0.8942,0 0.2465,0.2465 0.2465,0.6443 0,0.8908 z m -0.3213,-5.2615 c -1.4824,0 -2.6877,-1.2002 -2.6877,-2.6758 0,-1.4756 1.2053,-2.6775 2.6877,-2.6775 1.4824,0 2.6877,1.2019 2.6877,2.6775 0,1.4756 -1.2053,2.6758 -2.6877,2.6758 z" data-reactid="74"></path></g></svg></div><div class="SocialMediaShareCount" data-reactid="75"><div class="share-count" data-reactid="76"></div></div></div><div role="button" tabindex="0" class="SocialMediaShareButton SocialMediaShareButton--twitter" data-reactid="77"><div style="width:36px;height:36px;" data-reactid="78"><svg viewBox="0 0 64 64" fill="white" width="36" height="36" class="social-icon social-icon--twitter " data-reactid="79"><g data-reactid="80"><circle cx="32" cy="32" r="31" fill="#00aced" data-reactid="81"></circle></g><g data-reactid="82"><path d="M48,22.1c-1.2,0.5-2.4,0.9-3.8,1c1.4-0.8,2.4-2.1,2.9-3.6c-1.3,0.8-2.7,1.3-4.2,1.6 C41.7,19.8,40,19,38.2,19c-3.6,0-6.6,2.9-6.6,6.6c0,0.5,0.1,1,0.2,1.5c-5.5-0.3-10.3-2.9-13.5-6.9c-0.6,1-0.9,2.1-0.9,3.3 c0,2.3,1.2,4.3,2.9,5.5c-1.1,0-2.1-0.3-3-0.8c0,0,0,0.1,0,0.1c0,3.2,2.3,5.8,5.3,6.4c-0.6,0.1-1.1,0.2-1.7,0.2c-0.4,0-0.8,0-1.2-0.1 c0.8,2.6,3.3,4.5,6.1,4.6c-2.2,1.8-5.1,2.8-8.2,2.8c-0.5,0-1.1,0-1.6-0.1c2.9,1.9,6.4,2.9,10.1,2.9c12.1,0,18.7-10,18.7-18.7 c0-0.3,0-0.6,0-0.8C46,24.5,47.1,23.4,48,22.1z" data-reactid="83"></path></g></svg></div></div><div role="button" tabindex="0" class="SocialMediaShareButton SocialMediaShareButton--googlePlus" data-reactid="84"><div style="width:36px;height:36px;" data-reactid="85"><svg viewBox="0 0 64 64" fill="white" width="36" height="36" class="social-icon social-icon--google " data-reactid="86"><g data-reactid="87"><circle cx="32" cy="32" r="31" fill="#dd4b39" data-reactid="88"></circle></g><g data-reactid="89"><path d="M25.3,30.1v3.8h6.3c-0.3,1.6-1.9,4.8-6.3,4.8c-3.8,0-6.9-3.1-6.9-7s3.1-7,6.9-7c2.2,0,3.6,0.9,4.4,1.7l3-2.9c-1.9-1.8-4.4-2.9-7.4-2.9c-6.1,0-11.1,5-11.1,11.1s5,11.1,11.1,11.1c6.4,0,10.7-4.5,10.7-10.9c0-0.7-0.1-1.3-0.2-1.8H25.3L25.3,30.1z M49.8,28.9h-3.2v-3.2h-3.2v3.2h-3.2v3.2h3.2v3.2h3.2v-3.2h3.2" data-reactid="90"></path></g></svg></div><div class="SocialMediaShareCount" data-reactid="91"><div class="share-count" data-reactid="92"></div></div></div><div role="button" tabindex="0" class="SocialMediaShareButton SocialMediaShareButton--facebook" data-reactid="93"><div style="width:36px;height:36px;" data-reactid="94"><svg viewBox="0 0 64 64" fill="white" width="36" height="36" class="social-icon social-icon--facebook " data-reactid="95"><g data-reactid="96"><circle cx="32" cy="32" r="31" fill="#3b5998" data-reactid="97"></circle></g><g data-reactid="98"><path d="M34.1,47V33.3h4.6l0.7-5.3h-5.3v-3.4c0-1.5,0.4-2.6,2.6-2.6l2.8,0v-4.8c-0.5-0.1-2.2-0.2-4.1-0.2 c-4.1,0-6.9,2.5-6.9,7V28H24v5.3h4.6V47H34.1z" data-reactid="99"></path></g></svg></div><div class="SocialMediaShareCount" data-reactid="100"><div class="share-count" data-reactid="101"></div></div></div><div role="button" tabindex="0" class="SocialMediaShareButton SocialMediaShareButton--linkedin" data-reactid="102"><div style="width:36px;height:36px;" data-reactid="103"><svg viewBox="0 0 64 64" fill="white" width="36" height="36" class="social-icon social-icon--linkedin " data-reactid="104"><g data-reactid="105"><circle cx="32" cy="32" r="31" fill="#007fb1" data-reactid="106"></circle></g><g data-reactid="107"><path d="M20.4,44h5.4V26.6h-5.4V44z M23.1,18c-1.7,0-3.1,1.4-3.1,3.1c0,1.7,1.4,3.1,3.1,3.1 c1.7,0,3.1-1.4,3.1-3.1C26.2,19.4,24.8,18,23.1,18z M39.5,26.2c-2.6,0-4.4,1.4-5.1,2.8h-0.1v-2.4h-5.2V44h5.4v-8.6 c0-2.3,0.4-4.5,3.2-4.5c2.8,0,2.8,2.6,2.8,4.6V44H46v-9.5C46,29.8,45,26.2,39.5,26.2z" data-reactid="108"></path></g></svg></div><div class="SocialMediaShareCount" data-reactid="109"><div class="share-count" data-reactid="110"></div></div></div><div role="button" tabindex="0" class="SocialMediaShareButton SocialMediaShareButton--telegram" data-reactid="111"><div style="width:36px;height:36px;" data-reactid="112"><svg viewBox="0 0 64 64" fill="white" width="36" height="36" class="social-icon social-icon--telegram " data-reactid="113"><g data-reactid="114"><circle cx="32" cy="32" r="31" fill="#37aee2" data-reactid="115"></circle></g><g data-reactid="116"><path d="m45.90873,15.44335c-0.6901,-0.0281 -1.37668,0.14048 -1.96142,0.41265c-0.84989,0.32661 -8.63939,3.33986 -16.5237,6.39174c-3.9685,1.53296 -7.93349,3.06593 -10.98537,4.24067c-3.05012,1.1765 -5.34694,2.05098 -5.4681,2.09312c-0.80775,0.28096 -1.89996,0.63566 -2.82712,1.72788c-0.23354,0.27218 -0.46884,0.62161 -0.58825,1.10275c-0.11941,0.48114 -0.06673,1.09222 0.16682,1.5716c0.46533,0.96052 1.25376,1.35737 2.18443,1.71383c3.09051,0.99037 6.28638,1.93508 8.93263,2.8236c0.97632,3.44171 1.91401,6.89571 2.84116,10.34268c0.30554,0.69185 0.97105,0.94823 1.65764,0.95525l-0.00351,0.03512c0,0 0.53908,0.05268 1.06412,-0.07375c0.52679,-0.12292 1.18879,-0.42846 1.79109,-0.99212c0.662,-0.62161 2.45836,-2.38812 3.47683,-3.38552l7.6736,5.66477l0.06146,0.03512c0,0 0.84989,0.59703 2.09312,0.68132c0.62161,0.04214 1.4399,-0.07726 2.14229,-0.59176c0.70766,-0.51626 1.1765,-1.34683 1.396,-2.29506c0.65673,-2.86224 5.00979,-23.57745 5.75257,-27.00686l-0.02107,0.08077c0.51977,-1.93157 0.32837,-3.70159 -0.87096,-4.74991c-0.60054,-0.52152 -1.2924,-0.7498 -1.98425,-0.77965l0,0.00176zm-0.2072,3.29069c0.04741,0.0439 0.0439,0.0439 0.00351,0.04741c-0.01229,-0.00351 0.14048,0.2072 -0.15804,1.32576l-0.01229,0.04214l-0.00878,0.03863c-0.75858,3.50668 -5.15554,24.40802 -5.74203,26.96472c-0.08077,0.34417 -0.11414,0.31959 -0.09482,0.29852c-0.1756,-0.02634 -0.50045,-0.16506 -0.52679,-0.1756l-13.13468,-9.70175c4.4988,-4.33199 9.09945,-8.25307 13.744,-12.43229c0.8218,-0.41265 0.68483,-1.68573 -0.29852,-1.70681c-1.04305,0.24584 -1.92279,0.99564 -2.8798,1.47502c-5.49971,3.2626 -11.11882,6.13186 -16.55882,9.49279c-2.792,-0.97105 -5.57873,-1.77704 -8.15298,-2.57601c2.2336,-0.89555 4.00889,-1.55579 5.75608,-2.23009c3.05188,-1.1765 7.01687,-2.7042 10.98537,-4.24067c7.94051,-3.06944 15.92667,-6.16346 16.62028,-6.43037l0.05619,-0.02283l0.05268,-0.02283c0.19316,-0.0878 0.30378,-0.09658 0.35471,-0.10009c0,0 -0.01756,-0.05795 -0.00351,-0.04566l-0.00176,0zm-20.91715,22.0638l2.16687,1.60145c-0.93418,0.91311 -1.81743,1.77353 -2.45485,2.38812l0.28798,-3.98957" data-reactid="117"></path></g></svg></div></div></div></div></div><div class="md-paper md-paper--1 md-card md-background--card md-grid md-cell md-cell--12 user-info" data-reactid="118"><div class="md-card-title" data-reactid="119"><div class="md-inline-block md-avatar md-avatar--default md-avatar--card" data-reactid="120"><img src="/logos/dinne.jpg" role="presentation" class="md-avatar-img" data-reactid="121"/></div><div class="md-card-title--title-block md-card-title--one-line" data-reactid="122"><h2 class="md-card-title--title md-text" data-reactid="123">Dinne Bosman</h2><h3 class="md-card-title--title md-text--secondary" data-reactid="124">Author</h3></div><button type="button" class="md-btn md-btn--icon md-pointer--hover md-inline-block md-collapser md-collapser--card" data-reactid="125"><div class="md-ink-container" data-reactid="126"></div><i class="md-icon material-icons md-text--inherit" data-reactid="127">keyboard_arrow_down</i></button></div><!-- react-empty: 128 --></div><div class="md-paper md-paper--1 md-card md-background--card md-grid md-cell md-cell--12" data-reactid="129"><div class="md-card-title" data-reactid="130"><div class="md-inline-block md-avatar md-avatar--default md-avatar--card" data-reactid="131"><div class="md-avatar-content" data-reactid="132"><i class="md-icon material-icons" data-reactid="133">comment</i></div></div><h2 class="md-card-title--title md-text" data-reactid="134">Comments</h2><button type="button" class="md-btn md-btn--icon md-pointer--hover md-inline-block md-collapser md-collapser--card" data-reactid="135"><div class="md-ink-container" data-reactid="136"></div><i class="md-icon material-icons md-text--inherit" data-reactid="137">keyboard_arrow_down</i></button></div><!-- react-empty: 138 --><!-- react-empty: 139 --></div></div><div class="post-suggestions md-grid md-cell--12" data-reactid="140"><a class="post-suggestion" href="/lstm-neural-network-for-sequence-learning" data-reactid="141"><i class="md-icon material-icons secondary-color arrow-nav" data-reactid="142">arrow_back</i><div class="headline-container hide-on-mobile" data-reactid="143"><h2 class="md-body-2 secondary-color" data-reactid="144">Previous</h2><h6 class="md-headline secondary-color" data-reactid="145">LSTM neural network for sequence learning</h6></div></a><a class="post-suggestion" href="/lstm-neural-network-for-sequence-learning" data-reactid="146"><div class="headline-container" data-reactid="147"><h2 class="md-body-2 secondary-color" data-reactid="148">Next</h2><h6 class="md-headline secondary-color" data-reactid="149">LSTM neural network for sequence learning</h6></div><i class="md-icon material-icons secondary-color arrow-nav" data-reactid="150">arrow_forward</i></a></div></div></div></div><footer class="footer" data-reactid="151"><div class="user-links" data-reactid="152"><a href="https://github.com/dwjbosman" class="md-btn md-btn--flat md-btn--text md-pointer--hover md-text--theme-secondary md-ink--secondary md-inline-block" data-reactid="153"><div class="md-ink-container" data-reactid="154"></div><div class="md-icon-separator" data-reactid="155"><i class="md-icon fa fa-github md-text--inherit" data-reactid="156"></i><span class="md-icon-text" data-reactid="157">GitHub</span></div></a><a href="https://www.linkedin.com/in/dwjbosman" class="md-btn md-btn--flat md-btn--text md-pointer--hover md-text--theme-secondary md-ink--secondary md-inline-block" data-reactid="158"><div class="md-ink-container" data-reactid="159"></div><div class="md-icon-separator" data-reactid="160"><i class="md-icon fa fa-linkedin md-text--inherit" data-reactid="161"></i><span class="md-icon-text" data-reactid="162">Linkedin</span></div></a><a href="https://www.twitter.com/dwjbosman" class="md-btn md-btn--flat md-btn--text md-pointer--hover md-text--theme-secondary md-ink--secondary md-inline-block" data-reactid="163"><div class="md-ink-container" data-reactid="164"></div><div class="md-icon-separator" data-reactid="165"><i class="md-icon fa fa-twitter md-text--inherit" data-reactid="166"></i><span class="md-icon-text" data-reactid="167">Twitter</span></div></a><a href="mailto:dinne.bosman@the-future-group.com" class="md-btn md-btn--flat md-btn--text md-pointer--hover md-text--theme-secondary md-ink--secondary md-inline-block" data-reactid="168"><div class="md-ink-container" data-reactid="169"></div><div class="md-icon-separator" data-reactid="170"><i class="md-icon fa fa-envelope md-text--inherit" data-reactid="171"></i><span class="md-icon-text" data-reactid="172">Email</span></div></a></div><div class="notice-container" data-reactid="173"><div class="copyright" data-reactid="174"><h4 data-reactid="175">Copyright © 2017. Dinne Bosman</h4></div><div class="rss" data-reactid="176"><a href="/rss.xml" data-reactid="177"><button type="button" class="md-btn md-btn--flat md-btn--text md-pointer--hover md-text--theme-secondary md-ink--secondary md-inline-block" data-reactid="178"><div class="md-ink-container" data-reactid="179"></div><div class="md-icon-separator" data-reactid="180"><i class="md-icon fa fa-rss md-text--inherit" data-reactid="181"></i><span class="md-icon-text" data-reactid="182">Subscribe</span></div></button></a></div><div class="based-on" data-reactid="183"><h4 data-reactid="184"><!-- react-text: 185 -->Based on<!-- /react-text --><!-- react-text: 186 --> <!-- /react-text --><a href="https://github.com/Vagr9K/gatsby-material-starter" data-reactid="187">Gatsby Material Starter</a><!-- react-text: 188 -->.<!-- /react-text --></h4></div></div></footer></main></div></div><script>
  
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-47311644-4', 'auto');
  </script><script>
          window.twttr = (function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0],
    t = window.twttr || {};
  if (d.getElementById(id)) return t;
  js = d.createElement(s);
  js.id = id;
  js.src = "https://platform.twitter.com/widgets.js";
  fjs.parentNode.insertBefore(js, fjs);

  t._e = [];
  t.ready = function(f) {
    t._e.push(f);
  };

  return t;
}(document, "script", "twitter-wjs"));
      </script></body></html>